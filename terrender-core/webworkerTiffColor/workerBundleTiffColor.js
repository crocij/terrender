/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "../node_modules/@petamoriken/float16/src/dataView.js":
/*!************************************************************!*\
  !*** ../node_modules/@petamoriken/float16/src/dataView.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getFloat16\": () => (/* binding */ getFloat16),\n/* harmony export */   \"setFloat16\": () => (/* binding */ setFloat16)\n/* harmony export */ });\n/* harmony import */ var _is__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./is */ \"../node_modules/@petamoriken/float16/src/is.js\");\n/* harmony import */ var _lib__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib */ \"../node_modules/@petamoriken/float16/src/lib.js\");\n\n\n\n/**\n * returns an unsigned 16-bit float at the specified byte offset from the start of the DataView.\n * @param {DataView} dataView\n * @param {nunmber} byteOffset\n * @param {*} opts\n */\nfunction getFloat16(dataView, byteOffset, ...opts) {\n    if(!(0,_is__WEBPACK_IMPORTED_MODULE_0__.isDataView)(dataView))\n        throw new TypeError(\"First argument to getFloat16 function must be a DataView\");\n\n    return (0,_lib__WEBPACK_IMPORTED_MODULE_1__.convertToNumber)( dataView.getUint16(byteOffset, ...opts) );\n}\n\n/**\n * stores an unsigned 16-bit float value at the specified byte offset from the start of the DataView.\n * @param {DataView} dataView\n * @param {number} byteOffset\n * @param {number} value\n * @param {*} opts\n */\nfunction setFloat16(dataView, byteOffset, value, ...opts) {\n    if(!(0,_is__WEBPACK_IMPORTED_MODULE_0__.isDataView)(dataView))\n        throw new TypeError(\"First argument to setFloat16 function must be a DataView\");\n\n    dataView.setUint16(byteOffset, (0,_lib__WEBPACK_IMPORTED_MODULE_1__.roundToFloat16Bits)(value), ...opts);\n}\n\n\n//# sourceURL=webpack:///../node_modules/@petamoriken/float16/src/dataView.js?");

/***/ }),

/***/ "../node_modules/@petamoriken/float16/src/is.js":
/*!******************************************************!*\
  !*** ../node_modules/@petamoriken/float16/src/is.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isArrayBuffer\": () => (/* reexport safe */ lodash_es_isArrayBuffer__WEBPACK_IMPORTED_MODULE_0__.default),\n/* harmony export */   \"isDataView\": () => (/* binding */ isDataView),\n/* harmony export */   \"isStringNumberKey\": () => (/* binding */ isStringNumberKey)\n/* harmony export */ });\n/* harmony import */ var _spec__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./spec */ \"../node_modules/@petamoriken/float16/src/spec.js\");\n/* harmony import */ var lodash_es_isArrayBuffer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! lodash-es/isArrayBuffer */ \"../node_modules/lodash-es/isArrayBuffer.js\");\n\n\n\n\n\nfunction isDataView(view) {\n    return view instanceof DataView;\n}\n\nfunction isStringNumberKey(key) {\n    return typeof key === \"string\" && key === (0,_spec__WEBPACK_IMPORTED_MODULE_1__.ToInteger)(key) + \"\";\n}\n\n\n//# sourceURL=webpack:///../node_modules/@petamoriken/float16/src/is.js?");

/***/ }),

/***/ "../node_modules/@petamoriken/float16/src/lib.js":
/*!*******************************************************!*\
  !*** ../node_modules/@petamoriken/float16/src/lib.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"roundToFloat16Bits\": () => (/* binding */ roundToFloat16Bits),\n/* harmony export */   \"convertToNumber\": () => (/* binding */ convertToNumber)\n/* harmony export */ });\n// algorithm: ftp://ftp.fox-toolkit.org/pub/fasthalffloatconversion.pdf\n\nconst buffer = new ArrayBuffer(4);\nconst floatView = new Float32Array(buffer);\nconst uint32View = new Uint32Array(buffer);\n\n\nconst baseTable = new Uint32Array(512);\nconst shiftTable = new Uint32Array(512);\n\nfor(let i = 0; i < 256; ++i) {\n    const e = i - 127;\n\n    // very small number (0, -0)\n    if(e < -27) {\n        baseTable[i | 0x000] = 0x0000;\n        baseTable[i | 0x100] = 0x8000;\n        shiftTable[i | 0x000] = 24;\n        shiftTable[i | 0x100] = 24;\n\n    // small number (denorm)\n    } else if(e < -14) {\n        baseTable[i | 0x000] =  0x0400 >> (-e - 14);\n        baseTable[i | 0x100] = (0x0400 >> (-e - 14)) | 0x8000;\n        shiftTable[i | 0x000] = -e - 1;\n        shiftTable[i | 0x100] = -e - 1;\n\n    // normal number\n    } else if(e <= 15) {\n        baseTable[i | 0x000] =  (e + 15) << 10;\n        baseTable[i | 0x100] = ((e + 15) << 10) | 0x8000;\n        shiftTable[i | 0x000] = 13;\n        shiftTable[i | 0x100] = 13;\n\n    // large number (Infinity, -Infinity)\n    } else if(e < 128) {\n        baseTable[i | 0x000] = 0x7c00;\n        baseTable[i | 0x100] = 0xfc00;\n        shiftTable[i | 0x000] = 24;\n        shiftTable[i | 0x100] = 24;\n\n    // stay (NaN, Infinity, -Infinity)\n    } else {\n        baseTable[i | 0x000] = 0x7c00;\n        baseTable[i | 0x100] = 0xfc00;\n        shiftTable[i | 0x000] = 13;\n        shiftTable[i | 0x100] = 13;\n    }\n}\n\n/**\n * round a number to a half float number bits.\n * @param {number} num\n */\nfunction roundToFloat16Bits(num) {\n    floatView[0] = num;\n\n    const f = uint32View[0];\n    const e = (f >> 23) & 0x1ff;\n    return baseTable[e] + ((f & 0x007fffff) >> shiftTable[e]);\n}\n\n\nconst mantissaTable = new Uint32Array(2048);\nconst exponentTable = new Uint32Array(64);\nconst offsetTable = new Uint32Array(64);\n\nmantissaTable[0] = 0;\nfor(let i = 1; i < 1024; ++i) {\n    let m = i << 13;    // zero pad mantissa bits\n    let e = 0;          // zero exponent\n\n    // normalized\n    while((m & 0x00800000) === 0) {\n        e -= 0x00800000;    // decrement exponent\n        m <<= 1;\n    }\n\n    m &= ~0x00800000;   // clear leading 1 bit\n    e += 0x38800000;    // adjust bias\n\n    mantissaTable[i] = m | e;\n}\nfor(let i = 1024; i < 2048; ++i) {\n    mantissaTable[i] = 0x38000000 + ((i - 1024) << 13);\n}\n\nexponentTable[0] = 0;\nfor(let i = 1; i < 31; ++i) {\n    exponentTable[i] = i << 23;\n}\nexponentTable[31] = 0x47800000;\nexponentTable[32] = 0x80000000;\nfor(let i = 33; i < 63; ++i) {\n    exponentTable[i] = 0x80000000 + ((i - 32) << 23);\n}\nexponentTable[63] = 0xc7800000;\n\noffsetTable[0] = 0;\nfor(let i = 1; i < 64; ++i) {\n    if(i === 32) {\n        offsetTable[i] = 0;\n    } else {\n        offsetTable[i] = 1024;\n    }\n}\n\n/**\n * convert a half float number bits to a number.\n * @param {number} float16bits - half float number bits\n */\nfunction convertToNumber(float16bits) {\n    const m = float16bits >> 10;\n    uint32View[0] = mantissaTable[offsetTable[m] + (float16bits & 0x3ff)] + exponentTable[m];\n    return floatView[0];\n}\n\n\n//# sourceURL=webpack:///../node_modules/@petamoriken/float16/src/lib.js?");

/***/ }),

/***/ "../node_modules/@petamoriken/float16/src/spec.js":
/*!********************************************************!*\
  !*** ../node_modules/@petamoriken/float16/src/spec.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToInteger\": () => (/* binding */ ToInteger),\n/* harmony export */   \"defaultCompareFunction\": () => (/* binding */ defaultCompareFunction)\n/* harmony export */ });\nfunction ToInteger(num) {\n    if(typeof num !== \"number\") num = Number(num);\n    if(Number.isNaN(num)) num = 0;\n    return Math.trunc(num);\n}\n\nfunction defaultCompareFunction(x, y) {\n    const [isNaN_x, isNaN_y] = [Number.isNaN(x), Number.isNaN(y)];\n\n    if(isNaN_x && isNaN_y)\n        return 0;\n\n    if(isNaN_x)\n        return 1;\n\n    if(isNaN_y)\n        return -1;\n\n    if(x < y)\n        return -1;\n\n    if(x > y)\n        return 1;\n\n    if(x === 0 && y === 0) {\n        const [isPlusZero_x, isPlusZero_y] = [Object.is(x, 0), Object.is(y, 0)];\n\n        if(!isPlusZero_x && isPlusZero_y)\n            return -1;\n\n        if(isPlusZero_x && !isPlusZero_y)\n            return 1;\n    }\n\n    return 0;\n}\n\n\n//# sourceURL=webpack:///../node_modules/@petamoriken/float16/src/spec.js?");

/***/ }),

/***/ "../node_modules/debug/src/browser.js":
/*!********************************************!*\
  !*** ../node_modules/debug/src/browser.js ***!
  \********************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("/* eslint-env browser */\n\n/**\n * This is the web browser implementation of `debug()`.\n */\n\nexports.formatArgs = formatArgs;\nexports.save = save;\nexports.load = load;\nexports.useColors = useColors;\nexports.storage = localstorage();\nexports.destroy = (() => {\n\tlet warned = false;\n\n\treturn () => {\n\t\tif (!warned) {\n\t\t\twarned = true;\n\t\t\tconsole.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n\t\t}\n\t};\n})();\n\n/**\n * Colors.\n */\n\nexports.colors = [\n\t'#0000CC',\n\t'#0000FF',\n\t'#0033CC',\n\t'#0033FF',\n\t'#0066CC',\n\t'#0066FF',\n\t'#0099CC',\n\t'#0099FF',\n\t'#00CC00',\n\t'#00CC33',\n\t'#00CC66',\n\t'#00CC99',\n\t'#00CCCC',\n\t'#00CCFF',\n\t'#3300CC',\n\t'#3300FF',\n\t'#3333CC',\n\t'#3333FF',\n\t'#3366CC',\n\t'#3366FF',\n\t'#3399CC',\n\t'#3399FF',\n\t'#33CC00',\n\t'#33CC33',\n\t'#33CC66',\n\t'#33CC99',\n\t'#33CCCC',\n\t'#33CCFF',\n\t'#6600CC',\n\t'#6600FF',\n\t'#6633CC',\n\t'#6633FF',\n\t'#66CC00',\n\t'#66CC33',\n\t'#9900CC',\n\t'#9900FF',\n\t'#9933CC',\n\t'#9933FF',\n\t'#99CC00',\n\t'#99CC33',\n\t'#CC0000',\n\t'#CC0033',\n\t'#CC0066',\n\t'#CC0099',\n\t'#CC00CC',\n\t'#CC00FF',\n\t'#CC3300',\n\t'#CC3333',\n\t'#CC3366',\n\t'#CC3399',\n\t'#CC33CC',\n\t'#CC33FF',\n\t'#CC6600',\n\t'#CC6633',\n\t'#CC9900',\n\t'#CC9933',\n\t'#CCCC00',\n\t'#CCCC33',\n\t'#FF0000',\n\t'#FF0033',\n\t'#FF0066',\n\t'#FF0099',\n\t'#FF00CC',\n\t'#FF00FF',\n\t'#FF3300',\n\t'#FF3333',\n\t'#FF3366',\n\t'#FF3399',\n\t'#FF33CC',\n\t'#FF33FF',\n\t'#FF6600',\n\t'#FF6633',\n\t'#FF9900',\n\t'#FF9933',\n\t'#FFCC00',\n\t'#FFCC33'\n];\n\n/**\n * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n * and the Firebug extension (any Firefox version) are known\n * to support \"%c\" CSS customizations.\n *\n * TODO: add a `localStorage` variable to explicitly enable/disable colors\n */\n\n// eslint-disable-next-line complexity\nfunction useColors() {\n\t// NB: In an Electron preload script, document will be defined but not fully\n\t// initialized. Since we know we're in Chrome, we'll just detect this case\n\t// explicitly\n\tif (typeof window !== 'undefined' && window.process && (window.process.type === 'renderer' || window.process.__nwjs)) {\n\t\treturn true;\n\t}\n\n\t// Internet Explorer and Edge do not support colors.\n\tif (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\\/(\\d+)/)) {\n\t\treturn false;\n\t}\n\n\t// Is webkit? http://stackoverflow.com/a/16459606/376773\n\t// document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n\treturn (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||\n\t\t// Is firebug? http://stackoverflow.com/a/398120/376773\n\t\t(typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||\n\t\t// Is firefox >= v31?\n\t\t// https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n\t\t(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\\/(\\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||\n\t\t// Double check webkit in userAgent just in case we are in a worker\n\t\t(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\\/(\\d+)/));\n}\n\n/**\n * Colorize log arguments if enabled.\n *\n * @api public\n */\n\nfunction formatArgs(args) {\n\targs[0] = (this.useColors ? '%c' : '') +\n\t\tthis.namespace +\n\t\t(this.useColors ? ' %c' : ' ') +\n\t\targs[0] +\n\t\t(this.useColors ? '%c ' : ' ') +\n\t\t'+' + module.exports.humanize(this.diff);\n\n\tif (!this.useColors) {\n\t\treturn;\n\t}\n\n\tconst c = 'color: ' + this.color;\n\targs.splice(1, 0, c, 'color: inherit');\n\n\t// The final \"%c\" is somewhat tricky, because there could be other\n\t// arguments passed either before or after the %c, so we need to\n\t// figure out the correct index to insert the CSS into\n\tlet index = 0;\n\tlet lastC = 0;\n\targs[0].replace(/%[a-zA-Z%]/g, match => {\n\t\tif (match === '%%') {\n\t\t\treturn;\n\t\t}\n\t\tindex++;\n\t\tif (match === '%c') {\n\t\t\t// We only are interested in the *last* %c\n\t\t\t// (the user may have provided their own)\n\t\t\tlastC = index;\n\t\t}\n\t});\n\n\targs.splice(lastC, 0, c);\n}\n\n/**\n * Invokes `console.debug()` when available.\n * No-op when `console.debug` is not a \"function\".\n * If `console.debug` is not available, falls back\n * to `console.log`.\n *\n * @api public\n */\nexports.log = console.debug || console.log || (() => {});\n\n/**\n * Save `namespaces`.\n *\n * @param {String} namespaces\n * @api private\n */\nfunction save(namespaces) {\n\ttry {\n\t\tif (namespaces) {\n\t\t\texports.storage.setItem('debug', namespaces);\n\t\t} else {\n\t\t\texports.storage.removeItem('debug');\n\t\t}\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n}\n\n/**\n * Load `namespaces`.\n *\n * @return {String} returns the previously persisted debug modes\n * @api private\n */\nfunction load() {\n\tlet r;\n\ttry {\n\t\tr = exports.storage.getItem('debug');\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n\n\t// If debug isn't set in LS, and we're in Electron, try to load $DEBUG\n\tif (!r && typeof process !== 'undefined' && 'env' in process) {\n\t\tr = process.env.DEBUG;\n\t}\n\n\treturn r;\n}\n\n/**\n * Localstorage attempts to return the localstorage.\n *\n * This is necessary because safari throws\n * when a user disables cookies/localstorage\n * and you attempt to access it.\n *\n * @return {LocalStorage}\n * @api private\n */\n\nfunction localstorage() {\n\ttry {\n\t\t// TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context\n\t\t// The Browser also has localStorage in the global context.\n\t\treturn localStorage;\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n}\n\nmodule.exports = __webpack_require__(/*! ./common */ \"../node_modules/debug/src/common.js\")(exports);\n\nconst {formatters} = module.exports;\n\n/**\n * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n */\n\nformatters.j = function (v) {\n\ttry {\n\t\treturn JSON.stringify(v);\n\t} catch (error) {\n\t\treturn '[UnexpectedJSONParseError]: ' + error.message;\n\t}\n};\n\n\n//# sourceURL=webpack:///../node_modules/debug/src/browser.js?");

/***/ }),

/***/ "../node_modules/debug/src/common.js":
/*!*******************************************!*\
  !*** ../node_modules/debug/src/common.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("\n/**\n * This is the common logic for both the Node.js and web browser\n * implementations of `debug()`.\n */\n\nfunction setup(env) {\n\tcreateDebug.debug = createDebug;\n\tcreateDebug.default = createDebug;\n\tcreateDebug.coerce = coerce;\n\tcreateDebug.disable = disable;\n\tcreateDebug.enable = enable;\n\tcreateDebug.enabled = enabled;\n\tcreateDebug.humanize = __webpack_require__(/*! ms */ \"../node_modules/ms/index.js\");\n\tcreateDebug.destroy = destroy;\n\n\tObject.keys(env).forEach(key => {\n\t\tcreateDebug[key] = env[key];\n\t});\n\n\t/**\n\t* The currently active debug mode names, and names to skip.\n\t*/\n\n\tcreateDebug.names = [];\n\tcreateDebug.skips = [];\n\n\t/**\n\t* Map of special \"%n\" handling functions, for the debug \"format\" argument.\n\t*\n\t* Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n\t*/\n\tcreateDebug.formatters = {};\n\n\t/**\n\t* Selects a color for a debug namespace\n\t* @param {String} namespace The namespace string for the for the debug instance to be colored\n\t* @return {Number|String} An ANSI color code for the given namespace\n\t* @api private\n\t*/\n\tfunction selectColor(namespace) {\n\t\tlet hash = 0;\n\n\t\tfor (let i = 0; i < namespace.length; i++) {\n\t\t\thash = ((hash << 5) - hash) + namespace.charCodeAt(i);\n\t\t\thash |= 0; // Convert to 32bit integer\n\t\t}\n\n\t\treturn createDebug.colors[Math.abs(hash) % createDebug.colors.length];\n\t}\n\tcreateDebug.selectColor = selectColor;\n\n\t/**\n\t* Create a debugger with the given `namespace`.\n\t*\n\t* @param {String} namespace\n\t* @return {Function}\n\t* @api public\n\t*/\n\tfunction createDebug(namespace) {\n\t\tlet prevTime;\n\t\tlet enableOverride = null;\n\t\tlet namespacesCache;\n\t\tlet enabledCache;\n\n\t\tfunction debug(...args) {\n\t\t\t// Disabled?\n\t\t\tif (!debug.enabled) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tconst self = debug;\n\n\t\t\t// Set `diff` timestamp\n\t\t\tconst curr = Number(new Date());\n\t\t\tconst ms = curr - (prevTime || curr);\n\t\t\tself.diff = ms;\n\t\t\tself.prev = prevTime;\n\t\t\tself.curr = curr;\n\t\t\tprevTime = curr;\n\n\t\t\targs[0] = createDebug.coerce(args[0]);\n\n\t\t\tif (typeof args[0] !== 'string') {\n\t\t\t\t// Anything else let's inspect with %O\n\t\t\t\targs.unshift('%O');\n\t\t\t}\n\n\t\t\t// Apply any `formatters` transformations\n\t\t\tlet index = 0;\n\t\t\targs[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {\n\t\t\t\t// If we encounter an escaped % then don't increase the array index\n\t\t\t\tif (match === '%%') {\n\t\t\t\t\treturn '%';\n\t\t\t\t}\n\t\t\t\tindex++;\n\t\t\t\tconst formatter = createDebug.formatters[format];\n\t\t\t\tif (typeof formatter === 'function') {\n\t\t\t\t\tconst val = args[index];\n\t\t\t\t\tmatch = formatter.call(self, val);\n\n\t\t\t\t\t// Now we need to remove `args[index]` since it's inlined in the `format`\n\t\t\t\t\targs.splice(index, 1);\n\t\t\t\t\tindex--;\n\t\t\t\t}\n\t\t\t\treturn match;\n\t\t\t});\n\n\t\t\t// Apply env-specific formatting (colors, etc.)\n\t\t\tcreateDebug.formatArgs.call(self, args);\n\n\t\t\tconst logFn = self.log || createDebug.log;\n\t\t\tlogFn.apply(self, args);\n\t\t}\n\n\t\tdebug.namespace = namespace;\n\t\tdebug.useColors = createDebug.useColors();\n\t\tdebug.color = createDebug.selectColor(namespace);\n\t\tdebug.extend = extend;\n\t\tdebug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.\n\n\t\tObject.defineProperty(debug, 'enabled', {\n\t\t\tenumerable: true,\n\t\t\tconfigurable: false,\n\t\t\tget: () => {\n\t\t\t\tif (enableOverride !== null) {\n\t\t\t\t\treturn enableOverride;\n\t\t\t\t}\n\t\t\t\tif (namespacesCache !== createDebug.namespaces) {\n\t\t\t\t\tnamespacesCache = createDebug.namespaces;\n\t\t\t\t\tenabledCache = createDebug.enabled(namespace);\n\t\t\t\t}\n\n\t\t\t\treturn enabledCache;\n\t\t\t},\n\t\t\tset: v => {\n\t\t\t\tenableOverride = v;\n\t\t\t}\n\t\t});\n\n\t\t// Env-specific initialization logic for debug instances\n\t\tif (typeof createDebug.init === 'function') {\n\t\t\tcreateDebug.init(debug);\n\t\t}\n\n\t\treturn debug;\n\t}\n\n\tfunction extend(namespace, delimiter) {\n\t\tconst newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);\n\t\tnewDebug.log = this.log;\n\t\treturn newDebug;\n\t}\n\n\t/**\n\t* Enables a debug mode by namespaces. This can include modes\n\t* separated by a colon and wildcards.\n\t*\n\t* @param {String} namespaces\n\t* @api public\n\t*/\n\tfunction enable(namespaces) {\n\t\tcreateDebug.save(namespaces);\n\t\tcreateDebug.namespaces = namespaces;\n\n\t\tcreateDebug.names = [];\n\t\tcreateDebug.skips = [];\n\n\t\tlet i;\n\t\tconst split = (typeof namespaces === 'string' ? namespaces : '').split(/[\\s,]+/);\n\t\tconst len = split.length;\n\n\t\tfor (i = 0; i < len; i++) {\n\t\t\tif (!split[i]) {\n\t\t\t\t// ignore empty strings\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tnamespaces = split[i].replace(/\\*/g, '.*?');\n\n\t\t\tif (namespaces[0] === '-') {\n\t\t\t\tcreateDebug.skips.push(new RegExp('^' + namespaces.substr(1) + '$'));\n\t\t\t} else {\n\t\t\t\tcreateDebug.names.push(new RegExp('^' + namespaces + '$'));\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t* Disable debug output.\n\t*\n\t* @return {String} namespaces\n\t* @api public\n\t*/\n\tfunction disable() {\n\t\tconst namespaces = [\n\t\t\t...createDebug.names.map(toNamespace),\n\t\t\t...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)\n\t\t].join(',');\n\t\tcreateDebug.enable('');\n\t\treturn namespaces;\n\t}\n\n\t/**\n\t* Returns true if the given mode name is enabled, false otherwise.\n\t*\n\t* @param {String} name\n\t* @return {Boolean}\n\t* @api public\n\t*/\n\tfunction enabled(name) {\n\t\tif (name[name.length - 1] === '*') {\n\t\t\treturn true;\n\t\t}\n\n\t\tlet i;\n\t\tlet len;\n\n\t\tfor (i = 0, len = createDebug.skips.length; i < len; i++) {\n\t\t\tif (createDebug.skips[i].test(name)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\n\t\tfor (i = 0, len = createDebug.names.length; i < len; i++) {\n\t\t\tif (createDebug.names[i].test(name)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\n\t\treturn false;\n\t}\n\n\t/**\n\t* Convert regexp to namespace\n\t*\n\t* @param {RegExp} regxep\n\t* @return {String} namespace\n\t* @api private\n\t*/\n\tfunction toNamespace(regexp) {\n\t\treturn regexp.toString()\n\t\t\t.substring(2, regexp.toString().length - 2)\n\t\t\t.replace(/\\.\\*\\?$/, '*');\n\t}\n\n\t/**\n\t* Coerce `val`.\n\t*\n\t* @param {Mixed} val\n\t* @return {Mixed}\n\t* @api private\n\t*/\n\tfunction coerce(val) {\n\t\tif (val instanceof Error) {\n\t\t\treturn val.stack || val.message;\n\t\t}\n\t\treturn val;\n\t}\n\n\t/**\n\t* XXX DO NOT USE. This is a temporary stub function.\n\t* XXX It WILL be removed in the next major release.\n\t*/\n\tfunction destroy() {\n\t\tconsole.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n\t}\n\n\tcreateDebug.enable(createDebug.load());\n\n\treturn createDebug;\n}\n\nmodule.exports = setup;\n\n\n//# sourceURL=webpack:///../node_modules/debug/src/common.js?");

/***/ }),

/***/ "../node_modules/events/events.js":
/*!****************************************!*\
  !*** ../node_modules/events/events.js ***!
  \****************************************/
/***/ ((module) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nvar R = typeof Reflect === 'object' ? Reflect : null\nvar ReflectApply = R && typeof R.apply === 'function'\n  ? R.apply\n  : function ReflectApply(target, receiver, args) {\n    return Function.prototype.apply.call(target, receiver, args);\n  }\n\nvar ReflectOwnKeys\nif (R && typeof R.ownKeys === 'function') {\n  ReflectOwnKeys = R.ownKeys\n} else if (Object.getOwnPropertySymbols) {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target)\n      .concat(Object.getOwnPropertySymbols(target));\n  };\n} else {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target);\n  };\n}\n\nfunction ProcessEmitWarning(warning) {\n  if (console && console.warn) console.warn(warning);\n}\n\nvar NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {\n  return value !== value;\n}\n\nfunction EventEmitter() {\n  EventEmitter.init.call(this);\n}\nmodule.exports = EventEmitter;\nmodule.exports.once = once;\n\n// Backwards-compat with node 0.10.x\nEventEmitter.EventEmitter = EventEmitter;\n\nEventEmitter.prototype._events = undefined;\nEventEmitter.prototype._eventsCount = 0;\nEventEmitter.prototype._maxListeners = undefined;\n\n// By default EventEmitters will print a warning if more than 10 listeners are\n// added to it. This is a useful default which helps finding memory leaks.\nvar defaultMaxListeners = 10;\n\nfunction checkListener(listener) {\n  if (typeof listener !== 'function') {\n    throw new TypeError('The \"listener\" argument must be of type Function. Received type ' + typeof listener);\n  }\n}\n\nObject.defineProperty(EventEmitter, 'defaultMaxListeners', {\n  enumerable: true,\n  get: function() {\n    return defaultMaxListeners;\n  },\n  set: function(arg) {\n    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {\n      throw new RangeError('The value of \"defaultMaxListeners\" is out of range. It must be a non-negative number. Received ' + arg + '.');\n    }\n    defaultMaxListeners = arg;\n  }\n});\n\nEventEmitter.init = function() {\n\n  if (this._events === undefined ||\n      this._events === Object.getPrototypeOf(this)._events) {\n    this._events = Object.create(null);\n    this._eventsCount = 0;\n  }\n\n  this._maxListeners = this._maxListeners || undefined;\n};\n\n// Obviously not all Emitters should be limited to 10. This function allows\n// that to be increased. Set to zero for unlimited.\nEventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {\n  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {\n    throw new RangeError('The value of \"n\" is out of range. It must be a non-negative number. Received ' + n + '.');\n  }\n  this._maxListeners = n;\n  return this;\n};\n\nfunction _getMaxListeners(that) {\n  if (that._maxListeners === undefined)\n    return EventEmitter.defaultMaxListeners;\n  return that._maxListeners;\n}\n\nEventEmitter.prototype.getMaxListeners = function getMaxListeners() {\n  return _getMaxListeners(this);\n};\n\nEventEmitter.prototype.emit = function emit(type) {\n  var args = [];\n  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);\n  var doError = (type === 'error');\n\n  var events = this._events;\n  if (events !== undefined)\n    doError = (doError && events.error === undefined);\n  else if (!doError)\n    return false;\n\n  // If there is no 'error' event listener then throw.\n  if (doError) {\n    var er;\n    if (args.length > 0)\n      er = args[0];\n    if (er instanceof Error) {\n      // Note: The comments on the `throw` lines are intentional, they show\n      // up in Node's output if this results in an unhandled exception.\n      throw er; // Unhandled 'error' event\n    }\n    // At least give some kind of context to the user\n    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));\n    err.context = er;\n    throw err; // Unhandled 'error' event\n  }\n\n  var handler = events[type];\n\n  if (handler === undefined)\n    return false;\n\n  if (typeof handler === 'function') {\n    ReflectApply(handler, this, args);\n  } else {\n    var len = handler.length;\n    var listeners = arrayClone(handler, len);\n    for (var i = 0; i < len; ++i)\n      ReflectApply(listeners[i], this, args);\n  }\n\n  return true;\n};\n\nfunction _addListener(target, type, listener, prepend) {\n  var m;\n  var events;\n  var existing;\n\n  checkListener(listener);\n\n  events = target._events;\n  if (events === undefined) {\n    events = target._events = Object.create(null);\n    target._eventsCount = 0;\n  } else {\n    // To avoid recursion in the case that type === \"newListener\"! Before\n    // adding it to the listeners, first emit \"newListener\".\n    if (events.newListener !== undefined) {\n      target.emit('newListener', type,\n                  listener.listener ? listener.listener : listener);\n\n      // Re-assign `events` because a newListener handler could have caused the\n      // this._events to be assigned to a new object\n      events = target._events;\n    }\n    existing = events[type];\n  }\n\n  if (existing === undefined) {\n    // Optimize the case of one listener. Don't need the extra array object.\n    existing = events[type] = listener;\n    ++target._eventsCount;\n  } else {\n    if (typeof existing === 'function') {\n      // Adding the second element, need to change to array.\n      existing = events[type] =\n        prepend ? [listener, existing] : [existing, listener];\n      // If we've already got an array, just append.\n    } else if (prepend) {\n      existing.unshift(listener);\n    } else {\n      existing.push(listener);\n    }\n\n    // Check for listener leak\n    m = _getMaxListeners(target);\n    if (m > 0 && existing.length > m && !existing.warned) {\n      existing.warned = true;\n      // No error code for this since it is a Warning\n      // eslint-disable-next-line no-restricted-syntax\n      var w = new Error('Possible EventEmitter memory leak detected. ' +\n                          existing.length + ' ' + String(type) + ' listeners ' +\n                          'added. Use emitter.setMaxListeners() to ' +\n                          'increase limit');\n      w.name = 'MaxListenersExceededWarning';\n      w.emitter = target;\n      w.type = type;\n      w.count = existing.length;\n      ProcessEmitWarning(w);\n    }\n  }\n\n  return target;\n}\n\nEventEmitter.prototype.addListener = function addListener(type, listener) {\n  return _addListener(this, type, listener, false);\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.prependListener =\n    function prependListener(type, listener) {\n      return _addListener(this, type, listener, true);\n    };\n\nfunction onceWrapper() {\n  if (!this.fired) {\n    this.target.removeListener(this.type, this.wrapFn);\n    this.fired = true;\n    if (arguments.length === 0)\n      return this.listener.call(this.target);\n    return this.listener.apply(this.target, arguments);\n  }\n}\n\nfunction _onceWrap(target, type, listener) {\n  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };\n  var wrapped = onceWrapper.bind(state);\n  wrapped.listener = listener;\n  state.wrapFn = wrapped;\n  return wrapped;\n}\n\nEventEmitter.prototype.once = function once(type, listener) {\n  checkListener(listener);\n  this.on(type, _onceWrap(this, type, listener));\n  return this;\n};\n\nEventEmitter.prototype.prependOnceListener =\n    function prependOnceListener(type, listener) {\n      checkListener(listener);\n      this.prependListener(type, _onceWrap(this, type, listener));\n      return this;\n    };\n\n// Emits a 'removeListener' event if and only if the listener was removed.\nEventEmitter.prototype.removeListener =\n    function removeListener(type, listener) {\n      var list, events, position, i, originalListener;\n\n      checkListener(listener);\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      list = events[type];\n      if (list === undefined)\n        return this;\n\n      if (list === listener || list.listener === listener) {\n        if (--this._eventsCount === 0)\n          this._events = Object.create(null);\n        else {\n          delete events[type];\n          if (events.removeListener)\n            this.emit('removeListener', type, list.listener || listener);\n        }\n      } else if (typeof list !== 'function') {\n        position = -1;\n\n        for (i = list.length - 1; i >= 0; i--) {\n          if (list[i] === listener || list[i].listener === listener) {\n            originalListener = list[i].listener;\n            position = i;\n            break;\n          }\n        }\n\n        if (position < 0)\n          return this;\n\n        if (position === 0)\n          list.shift();\n        else {\n          spliceOne(list, position);\n        }\n\n        if (list.length === 1)\n          events[type] = list[0];\n\n        if (events.removeListener !== undefined)\n          this.emit('removeListener', type, originalListener || listener);\n      }\n\n      return this;\n    };\n\nEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\n\nEventEmitter.prototype.removeAllListeners =\n    function removeAllListeners(type) {\n      var listeners, events, i;\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      // not listening for removeListener, no need to emit\n      if (events.removeListener === undefined) {\n        if (arguments.length === 0) {\n          this._events = Object.create(null);\n          this._eventsCount = 0;\n        } else if (events[type] !== undefined) {\n          if (--this._eventsCount === 0)\n            this._events = Object.create(null);\n          else\n            delete events[type];\n        }\n        return this;\n      }\n\n      // emit removeListener for all listeners on all events\n      if (arguments.length === 0) {\n        var keys = Object.keys(events);\n        var key;\n        for (i = 0; i < keys.length; ++i) {\n          key = keys[i];\n          if (key === 'removeListener') continue;\n          this.removeAllListeners(key);\n        }\n        this.removeAllListeners('removeListener');\n        this._events = Object.create(null);\n        this._eventsCount = 0;\n        return this;\n      }\n\n      listeners = events[type];\n\n      if (typeof listeners === 'function') {\n        this.removeListener(type, listeners);\n      } else if (listeners !== undefined) {\n        // LIFO order\n        for (i = listeners.length - 1; i >= 0; i--) {\n          this.removeListener(type, listeners[i]);\n        }\n      }\n\n      return this;\n    };\n\nfunction _listeners(target, type, unwrap) {\n  var events = target._events;\n\n  if (events === undefined)\n    return [];\n\n  var evlistener = events[type];\n  if (evlistener === undefined)\n    return [];\n\n  if (typeof evlistener === 'function')\n    return unwrap ? [evlistener.listener || evlistener] : [evlistener];\n\n  return unwrap ?\n    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);\n}\n\nEventEmitter.prototype.listeners = function listeners(type) {\n  return _listeners(this, type, true);\n};\n\nEventEmitter.prototype.rawListeners = function rawListeners(type) {\n  return _listeners(this, type, false);\n};\n\nEventEmitter.listenerCount = function(emitter, type) {\n  if (typeof emitter.listenerCount === 'function') {\n    return emitter.listenerCount(type);\n  } else {\n    return listenerCount.call(emitter, type);\n  }\n};\n\nEventEmitter.prototype.listenerCount = listenerCount;\nfunction listenerCount(type) {\n  var events = this._events;\n\n  if (events !== undefined) {\n    var evlistener = events[type];\n\n    if (typeof evlistener === 'function') {\n      return 1;\n    } else if (evlistener !== undefined) {\n      return evlistener.length;\n    }\n  }\n\n  return 0;\n}\n\nEventEmitter.prototype.eventNames = function eventNames() {\n  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];\n};\n\nfunction arrayClone(arr, n) {\n  var copy = new Array(n);\n  for (var i = 0; i < n; ++i)\n    copy[i] = arr[i];\n  return copy;\n}\n\nfunction spliceOne(list, index) {\n  for (; index + 1 < list.length; index++)\n    list[index] = list[index + 1];\n  list.pop();\n}\n\nfunction unwrapListeners(arr) {\n  var ret = new Array(arr.length);\n  for (var i = 0; i < ret.length; ++i) {\n    ret[i] = arr[i].listener || arr[i];\n  }\n  return ret;\n}\n\nfunction once(emitter, name) {\n  return new Promise(function (resolve, reject) {\n    function errorListener(err) {\n      emitter.removeListener(name, resolver);\n      reject(err);\n    }\n\n    function resolver() {\n      if (typeof emitter.removeListener === 'function') {\n        emitter.removeListener('error', errorListener);\n      }\n      resolve([].slice.call(arguments));\n    };\n\n    eventTargetAgnosticAddListener(emitter, name, resolver, { once: true });\n    if (name !== 'error') {\n      addErrorHandlerIfEventEmitter(emitter, errorListener, { once: true });\n    }\n  });\n}\n\nfunction addErrorHandlerIfEventEmitter(emitter, handler, flags) {\n  if (typeof emitter.on === 'function') {\n    eventTargetAgnosticAddListener(emitter, 'error', handler, flags);\n  }\n}\n\nfunction eventTargetAgnosticAddListener(emitter, name, listener, flags) {\n  if (typeof emitter.on === 'function') {\n    if (flags.once) {\n      emitter.once(name, listener);\n    } else {\n      emitter.on(name, listener);\n    }\n  } else if (typeof emitter.addEventListener === 'function') {\n    // EventTarget does not have `error` event semantics like Node\n    // EventEmitters, we do not listen for `error` events here.\n    emitter.addEventListener(name, function wrapListener(arg) {\n      // IE does not have builtin `{ once: true }` support so we\n      // have to do it manually.\n      if (flags.once) {\n        emitter.removeEventListener(name, wrapListener);\n      }\n      listener(arg);\n    });\n  } else {\n    throw new TypeError('The \"emitter\" argument must be of type EventEmitter. Received type ' + typeof emitter);\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/events/events.js?");

/***/ }),

/***/ "../node_modules/fs/index.js":
/*!***********************************!*\
  !*** ../node_modules/fs/index.js ***!
  \***********************************/
/***/ (() => {

eval("console.log(\"I'm `fs` modules\");\n\n\n//# sourceURL=webpack:///../node_modules/fs/index.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/compression/basedecoder.js":
/*!**************************************************************!*\
  !*** ../node_modules/geotiff/src/compression/basedecoder.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ BaseDecoder)\n/* harmony export */ });\n/* harmony import */ var _predictor__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../predictor */ \"../node_modules/geotiff/src/predictor.js\");\n\n\nclass BaseDecoder {\n  async decode(fileDirectory, buffer) {\n    const decoded = await this.decodeBlock(buffer);\n    const predictor = fileDirectory.Predictor || 1;\n    if (predictor !== 1) {\n      const isTiled = !fileDirectory.StripOffsets;\n      const tileWidth = isTiled ? fileDirectory.TileWidth : fileDirectory.ImageWidth;\n      const tileHeight = isTiled ? fileDirectory.TileLength : (\n        fileDirectory.RowsPerStrip || fileDirectory.ImageLength\n      );\n      return (0,_predictor__WEBPACK_IMPORTED_MODULE_0__.applyPredictor)(\n        decoded, predictor, tileWidth, tileHeight, fileDirectory.BitsPerSample,\n        fileDirectory.PlanarConfiguration,\n      );\n    }\n    return decoded;\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/compression/basedecoder.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/compression/deflate.js":
/*!**********************************************************!*\
  !*** ../node_modules/geotiff/src/compression/deflate.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ DeflateDecoder)\n/* harmony export */ });\n/* harmony import */ var pako_lib_inflate__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! pako/lib/inflate */ \"../node_modules/pako/lib/inflate.js\");\n/* harmony import */ var _basedecoder__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./basedecoder */ \"../node_modules/geotiff/src/compression/basedecoder.js\");\n\n\n\nclass DeflateDecoder extends _basedecoder__WEBPACK_IMPORTED_MODULE_1__.default {\n  decodeBlock(buffer) {\n    return (0,pako_lib_inflate__WEBPACK_IMPORTED_MODULE_0__.inflate)(new Uint8Array(buffer)).buffer;\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/compression/deflate.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/compression/index.js":
/*!********************************************************!*\
  !*** ../node_modules/geotiff/src/compression/index.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getDecoder\": () => (/* binding */ getDecoder)\n/* harmony export */ });\n/* harmony import */ var _raw__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./raw */ \"../node_modules/geotiff/src/compression/raw.js\");\n/* harmony import */ var _lzw__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lzw */ \"../node_modules/geotiff/src/compression/lzw.js\");\n/* harmony import */ var _jpeg__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./jpeg */ \"../node_modules/geotiff/src/compression/jpeg.js\");\n/* harmony import */ var _deflate__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./deflate */ \"../node_modules/geotiff/src/compression/deflate.js\");\n/* harmony import */ var _packbits__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./packbits */ \"../node_modules/geotiff/src/compression/packbits.js\");\n\n\n\n\n\n\nfunction getDecoder(fileDirectory) {\n  switch (fileDirectory.Compression) {\n    case undefined:\n    case 1: // no compression\n      return new _raw__WEBPACK_IMPORTED_MODULE_0__.default();\n    case 5: // LZW\n      return new _lzw__WEBPACK_IMPORTED_MODULE_1__.default();\n    case 6: // JPEG\n      throw new Error('old style JPEG compression is not supported.');\n    case 7: // JPEG\n      return new _jpeg__WEBPACK_IMPORTED_MODULE_2__.default(fileDirectory);\n    case 8: // Deflate as recognized by Adobe\n    case 32946: // Deflate GDAL default\n      return new _deflate__WEBPACK_IMPORTED_MODULE_3__.default();\n    case 32773: // packbits\n      return new _packbits__WEBPACK_IMPORTED_MODULE_4__.default();\n    default:\n      throw new Error(`Unknown compression method identifier: ${fileDirectory.Compression}`);\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/compression/index.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/compression/jpeg.js":
/*!*******************************************************!*\
  !*** ../node_modules/geotiff/src/compression/jpeg.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ JpegDecoder)\n/* harmony export */ });\n/* harmony import */ var _basedecoder__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./basedecoder */ \"../node_modules/geotiff/src/compression/basedecoder.js\");\n\n\n/* -*- tab-width: 2; indent-tabs-mode: nil; c-basic-offset: 2 -*- /\n/* vim: set shiftwidth=2 tabstop=2 autoindent cindent expandtab: */\n/*\n   Copyright 2011 notmasteryet\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n       http://www.apache.org/licenses/LICENSE-2.0\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n*/\n\n// - The JPEG specification can be found in the ITU CCITT Recommendation T.81\n//   (www.w3.org/Graphics/JPEG/itu-t81.pdf)\n// - The JFIF specification can be found in the JPEG File Interchange Format\n//   (www.w3.org/Graphics/JPEG/jfif3.pdf)\n// - The Adobe Application-Specific JPEG markers in the Supporting the DCT Filters\n//   in PostScript Level 2, Technical Note #5116\n//   (partners.adobe.com/public/developer/en/ps/sdk/5116.DCT_Filter.pdf)\n\n\nconst dctZigZag = new Int32Array([\n  0,\n  1, 8,\n  16, 9, 2,\n  3, 10, 17, 24,\n  32, 25, 18, 11, 4,\n  5, 12, 19, 26, 33, 40,\n  48, 41, 34, 27, 20, 13, 6,\n  7, 14, 21, 28, 35, 42, 49, 56,\n  57, 50, 43, 36, 29, 22, 15,\n  23, 30, 37, 44, 51, 58,\n  59, 52, 45, 38, 31,\n  39, 46, 53, 60,\n  61, 54, 47,\n  55, 62,\n  63,\n]);\n\nconst dctCos1 = 4017; // cos(pi/16)\nconst dctSin1 = 799; // sin(pi/16)\nconst dctCos3 = 3406; // cos(3*pi/16)\nconst dctSin3 = 2276; // sin(3*pi/16)\nconst dctCos6 = 1567; // cos(6*pi/16)\nconst dctSin6 = 3784; // sin(6*pi/16)\nconst dctSqrt2 = 5793; // sqrt(2)\nconst dctSqrt1d2 = 2896;// sqrt(2) / 2\n\nfunction buildHuffmanTable(codeLengths, values) {\n  let k = 0;\n  const code = [];\n  let length = 16;\n  while (length > 0 && !codeLengths[length - 1]) {\n    --length;\n  }\n  code.push({ children: [], index: 0 });\n\n  let p = code[0];\n  let q;\n  for (let i = 0; i < length; i++) {\n    for (let j = 0; j < codeLengths[i]; j++) {\n      p = code.pop();\n      p.children[p.index] = values[k];\n      while (p.index > 0) {\n        p = code.pop();\n      }\n      p.index++;\n      code.push(p);\n      while (code.length <= i) {\n        code.push(q = { children: [], index: 0 });\n        p.children[p.index] = q.children;\n        p = q;\n      }\n      k++;\n    }\n    if (i + 1 < length) {\n      // p here points to last code\n      code.push(q = { children: [], index: 0 });\n      p.children[p.index] = q.children;\n      p = q;\n    }\n  }\n  return code[0].children;\n}\n\nfunction decodeScan(data, initialOffset,\n  frame, components, resetInterval,\n  spectralStart, spectralEnd,\n  successivePrev, successive) {\n  const { mcusPerLine, progressive } = frame;\n\n  const startOffset = initialOffset;\n  let offset = initialOffset;\n  let bitsData = 0;\n  let bitsCount = 0;\n  function readBit() {\n    if (bitsCount > 0) {\n      bitsCount--;\n      return (bitsData >> bitsCount) & 1;\n    }\n    bitsData = data[offset++];\n    if (bitsData === 0xFF) {\n      const nextByte = data[offset++];\n      if (nextByte) {\n        throw new Error(`unexpected marker: ${((bitsData << 8) | nextByte).toString(16)}`);\n      }\n      // unstuff 0\n    }\n    bitsCount = 7;\n    return bitsData >>> 7;\n  }\n  function decodeHuffman(tree) {\n    let node = tree;\n    let bit;\n    while ((bit = readBit()) !== null) { // eslint-disable-line no-cond-assign\n      node = node[bit];\n      if (typeof node === 'number') {\n        return node;\n      }\n      if (typeof node !== 'object') {\n        throw new Error('invalid huffman sequence');\n      }\n    }\n    return null;\n  }\n  function receive(initialLength) {\n    let length = initialLength;\n    let n = 0;\n    while (length > 0) {\n      const bit = readBit();\n      if (bit === null) {\n        return undefined;\n      }\n      n = (n << 1) | bit;\n      --length;\n    }\n    return n;\n  }\n  function receiveAndExtend(length) {\n    const n = receive(length);\n    if (n >= 1 << (length - 1)) {\n      return n;\n    }\n    return n + (-1 << length) + 1;\n  }\n  function decodeBaseline(component, zz) {\n    const t = decodeHuffman(component.huffmanTableDC);\n    const diff = t === 0 ? 0 : receiveAndExtend(t);\n    component.pred += diff;\n    zz[0] = component.pred;\n    let k = 1;\n    while (k < 64) {\n      const rs = decodeHuffman(component.huffmanTableAC);\n      const s = rs & 15;\n      const r = rs >> 4;\n      if (s === 0) {\n        if (r < 15) {\n          break;\n        }\n        k += 16;\n      } else {\n        k += r;\n        const z = dctZigZag[k];\n        zz[z] = receiveAndExtend(s);\n        k++;\n      }\n    }\n  }\n  function decodeDCFirst(component, zz) {\n    const t = decodeHuffman(component.huffmanTableDC);\n    const diff = t === 0 ? 0 : (receiveAndExtend(t) << successive);\n    component.pred += diff;\n    zz[0] = component.pred;\n  }\n  function decodeDCSuccessive(component, zz) {\n    zz[0] |= readBit() << successive;\n  }\n  let eobrun = 0;\n  function decodeACFirst(component, zz) {\n    if (eobrun > 0) {\n      eobrun--;\n      return;\n    }\n    let k = spectralStart;\n    const e = spectralEnd;\n    while (k <= e) {\n      const rs = decodeHuffman(component.huffmanTableAC);\n      const s = rs & 15;\n      const r = rs >> 4;\n      if (s === 0) {\n        if (r < 15) {\n          eobrun = receive(r) + (1 << r) - 1;\n          break;\n        }\n        k += 16;\n      } else {\n        k += r;\n        const z = dctZigZag[k];\n        zz[z] = receiveAndExtend(s) * (1 << successive);\n        k++;\n      }\n    }\n  }\n  let successiveACState = 0;\n  let successiveACNextValue;\n  function decodeACSuccessive(component, zz) {\n    let k = spectralStart;\n    const e = spectralEnd;\n    let r = 0;\n    while (k <= e) {\n      const z = dctZigZag[k];\n      const direction = zz[z] < 0 ? -1 : 1;\n      switch (successiveACState) {\n        case 0: { // initial state\n          const rs = decodeHuffman(component.huffmanTableAC);\n          const s = rs & 15;\n          r = rs >> 4;\n          if (s === 0) {\n            if (r < 15) {\n              eobrun = receive(r) + (1 << r);\n              successiveACState = 4;\n            } else {\n              r = 16;\n              successiveACState = 1;\n            }\n          } else {\n            if (s !== 1) {\n              throw new Error('invalid ACn encoding');\n            }\n            successiveACNextValue = receiveAndExtend(s);\n            successiveACState = r ? 2 : 3;\n          }\n          continue; // eslint-disable-line no-continue\n        }\n        case 1: // skipping r zero items\n        case 2:\n          if (zz[z]) {\n            zz[z] += (readBit() << successive) * direction;\n          } else {\n            r--;\n            if (r === 0) {\n              successiveACState = successiveACState === 2 ? 3 : 0;\n            }\n          }\n          break;\n        case 3: // set value for a zero item\n          if (zz[z]) {\n            zz[z] += (readBit() << successive) * direction;\n          } else {\n            zz[z] = successiveACNextValue << successive;\n            successiveACState = 0;\n          }\n          break;\n        case 4: // eob\n          if (zz[z]) {\n            zz[z] += (readBit() << successive) * direction;\n          }\n          break;\n        default:\n          break;\n      }\n      k++;\n    }\n    if (successiveACState === 4) {\n      eobrun--;\n      if (eobrun === 0) {\n        successiveACState = 0;\n      }\n    }\n  }\n  function decodeMcu(component, decodeFunction, mcu, row, col) {\n    const mcuRow = (mcu / mcusPerLine) | 0;\n    const mcuCol = mcu % mcusPerLine;\n    const blockRow = (mcuRow * component.v) + row;\n    const blockCol = (mcuCol * component.h) + col;\n    decodeFunction(component, component.blocks[blockRow][blockCol]);\n  }\n  function decodeBlock(component, decodeFunction, mcu) {\n    const blockRow = (mcu / component.blocksPerLine) | 0;\n    const blockCol = mcu % component.blocksPerLine;\n    decodeFunction(component, component.blocks[blockRow][blockCol]);\n  }\n\n  const componentsLength = components.length;\n  let component;\n  let i;\n  let j;\n  let k;\n  let n;\n  let decodeFn;\n  if (progressive) {\n    if (spectralStart === 0) {\n      decodeFn = successivePrev === 0 ? decodeDCFirst : decodeDCSuccessive;\n    } else {\n      decodeFn = successivePrev === 0 ? decodeACFirst : decodeACSuccessive;\n    }\n  } else {\n    decodeFn = decodeBaseline;\n  }\n\n  let mcu = 0;\n  let marker;\n  let mcuExpected;\n  if (componentsLength === 1) {\n    mcuExpected = components[0].blocksPerLine * components[0].blocksPerColumn;\n  } else {\n    mcuExpected = mcusPerLine * frame.mcusPerColumn;\n  }\n\n  const usedResetInterval = resetInterval || mcuExpected;\n\n  while (mcu < mcuExpected) {\n    // reset interval stuff\n    for (i = 0; i < componentsLength; i++) {\n      components[i].pred = 0;\n    }\n    eobrun = 0;\n\n    if (componentsLength === 1) {\n      component = components[0];\n      for (n = 0; n < usedResetInterval; n++) {\n        decodeBlock(component, decodeFn, mcu);\n        mcu++;\n      }\n    } else {\n      for (n = 0; n < usedResetInterval; n++) {\n        for (i = 0; i < componentsLength; i++) {\n          component = components[i];\n          const { h, v } = component;\n          for (j = 0; j < v; j++) {\n            for (k = 0; k < h; k++) {\n              decodeMcu(component, decodeFn, mcu, j, k);\n            }\n          }\n        }\n        mcu++;\n\n        // If we've reached our expected MCU's, stop decoding\n        if (mcu === mcuExpected) {\n          break;\n        }\n      }\n    }\n\n    // find marker\n    bitsCount = 0;\n    marker = (data[offset] << 8) | data[offset + 1];\n    if (marker < 0xFF00) {\n      throw new Error('marker was not found');\n    }\n\n    if (marker >= 0xFFD0 && marker <= 0xFFD7) { // RSTx\n      offset += 2;\n    } else {\n      break;\n    }\n  }\n\n  return offset - startOffset;\n}\n\nfunction buildComponentData(frame, component) {\n  const lines = [];\n  const { blocksPerLine, blocksPerColumn } = component;\n  const samplesPerLine = blocksPerLine << 3;\n  const R = new Int32Array(64);\n  const r = new Uint8Array(64);\n\n  // A port of poppler's IDCT method which in turn is taken from:\n  //   Christoph Loeffler, Adriaan Ligtenberg, George S. Moschytz,\n  //   \"Practical Fast 1-D DCT Algorithms with 11 Multiplications\",\n  //   IEEE Intl. Conf. on Acoustics, Speech & Signal Processing, 1989,\n  //   988-991.\n  function quantizeAndInverse(zz, dataOut, dataIn) {\n    const qt = component.quantizationTable;\n    let v0;\n    let v1;\n    let v2;\n    let v3;\n    let v4;\n    let v5;\n    let v6;\n    let v7;\n    let t;\n    const p = dataIn;\n    let i;\n\n    // dequant\n    for (i = 0; i < 64; i++) {\n      p[i] = zz[i] * qt[i];\n    }\n\n    // inverse DCT on rows\n    for (i = 0; i < 8; ++i) {\n      const row = 8 * i;\n\n      // check for all-zero AC coefficients\n      if (p[1 + row] === 0 && p[2 + row] === 0 && p[3 + row] === 0\n        && p[4 + row] === 0 && p[5 + row] === 0 && p[6 + row] === 0\n        && p[7 + row] === 0) {\n        t = ((dctSqrt2 * p[0 + row]) + 512) >> 10;\n        p[0 + row] = t;\n        p[1 + row] = t;\n        p[2 + row] = t;\n        p[3 + row] = t;\n        p[4 + row] = t;\n        p[5 + row] = t;\n        p[6 + row] = t;\n        p[7 + row] = t;\n        continue; // eslint-disable-line no-continue\n      }\n\n      // stage 4\n      v0 = ((dctSqrt2 * p[0 + row]) + 128) >> 8;\n      v1 = ((dctSqrt2 * p[4 + row]) + 128) >> 8;\n      v2 = p[2 + row];\n      v3 = p[6 + row];\n      v4 = ((dctSqrt1d2 * (p[1 + row] - p[7 + row])) + 128) >> 8;\n      v7 = ((dctSqrt1d2 * (p[1 + row] + p[7 + row])) + 128) >> 8;\n      v5 = p[3 + row] << 4;\n      v6 = p[5 + row] << 4;\n\n      // stage 3\n      t = (v0 - v1 + 1) >> 1;\n      v0 = (v0 + v1 + 1) >> 1;\n      v1 = t;\n      t = ((v2 * dctSin6) + (v3 * dctCos6) + 128) >> 8;\n      v2 = ((v2 * dctCos6) - (v3 * dctSin6) + 128) >> 8;\n      v3 = t;\n      t = (v4 - v6 + 1) >> 1;\n      v4 = (v4 + v6 + 1) >> 1;\n      v6 = t;\n      t = (v7 + v5 + 1) >> 1;\n      v5 = (v7 - v5 + 1) >> 1;\n      v7 = t;\n\n      // stage 2\n      t = (v0 - v3 + 1) >> 1;\n      v0 = (v0 + v3 + 1) >> 1;\n      v3 = t;\n      t = (v1 - v2 + 1) >> 1;\n      v1 = (v1 + v2 + 1) >> 1;\n      v2 = t;\n      t = ((v4 * dctSin3) + (v7 * dctCos3) + 2048) >> 12;\n      v4 = ((v4 * dctCos3) - (v7 * dctSin3) + 2048) >> 12;\n      v7 = t;\n      t = ((v5 * dctSin1) + (v6 * dctCos1) + 2048) >> 12;\n      v5 = ((v5 * dctCos1) - (v6 * dctSin1) + 2048) >> 12;\n      v6 = t;\n\n      // stage 1\n      p[0 + row] = v0 + v7;\n      p[7 + row] = v0 - v7;\n      p[1 + row] = v1 + v6;\n      p[6 + row] = v1 - v6;\n      p[2 + row] = v2 + v5;\n      p[5 + row] = v2 - v5;\n      p[3 + row] = v3 + v4;\n      p[4 + row] = v3 - v4;\n    }\n\n    // inverse DCT on columns\n    for (i = 0; i < 8; ++i) {\n      const col = i;\n\n      // check for all-zero AC coefficients\n      if (p[(1 * 8) + col] === 0 && p[(2 * 8) + col] === 0 && p[(3 * 8) + col] === 0\n        && p[(4 * 8) + col] === 0 && p[(5 * 8) + col] === 0 && p[(6 * 8) + col] === 0\n        && p[(7 * 8) + col] === 0) {\n        t = ((dctSqrt2 * dataIn[i + 0]) + 8192) >> 14;\n        p[(0 * 8) + col] = t;\n        p[(1 * 8) + col] = t;\n        p[(2 * 8) + col] = t;\n        p[(3 * 8) + col] = t;\n        p[(4 * 8) + col] = t;\n        p[(5 * 8) + col] = t;\n        p[(6 * 8) + col] = t;\n        p[(7 * 8) + col] = t;\n        continue; // eslint-disable-line no-continue\n      }\n\n      // stage 4\n      v0 = ((dctSqrt2 * p[(0 * 8) + col]) + 2048) >> 12;\n      v1 = ((dctSqrt2 * p[(4 * 8) + col]) + 2048) >> 12;\n      v2 = p[(2 * 8) + col];\n      v3 = p[(6 * 8) + col];\n      v4 = ((dctSqrt1d2 * (p[(1 * 8) + col] - p[(7 * 8) + col])) + 2048) >> 12;\n      v7 = ((dctSqrt1d2 * (p[(1 * 8) + col] + p[(7 * 8) + col])) + 2048) >> 12;\n      v5 = p[(3 * 8) + col];\n      v6 = p[(5 * 8) + col];\n\n      // stage 3\n      t = (v0 - v1 + 1) >> 1;\n      v0 = (v0 + v1 + 1) >> 1;\n      v1 = t;\n      t = ((v2 * dctSin6) + (v3 * dctCos6) + 2048) >> 12;\n      v2 = ((v2 * dctCos6) - (v3 * dctSin6) + 2048) >> 12;\n      v3 = t;\n      t = (v4 - v6 + 1) >> 1;\n      v4 = (v4 + v6 + 1) >> 1;\n      v6 = t;\n      t = (v7 + v5 + 1) >> 1;\n      v5 = (v7 - v5 + 1) >> 1;\n      v7 = t;\n\n      // stage 2\n      t = (v0 - v3 + 1) >> 1;\n      v0 = (v0 + v3 + 1) >> 1;\n      v3 = t;\n      t = (v1 - v2 + 1) >> 1;\n      v1 = (v1 + v2 + 1) >> 1;\n      v2 = t;\n      t = ((v4 * dctSin3) + (v7 * dctCos3) + 2048) >> 12;\n      v4 = ((v4 * dctCos3) - (v7 * dctSin3) + 2048) >> 12;\n      v7 = t;\n      t = ((v5 * dctSin1) + (v6 * dctCos1) + 2048) >> 12;\n      v5 = ((v5 * dctCos1) - (v6 * dctSin1) + 2048) >> 12;\n      v6 = t;\n\n      // stage 1\n      p[(0 * 8) + col] = v0 + v7;\n      p[(7 * 8) + col] = v0 - v7;\n      p[(1 * 8) + col] = v1 + v6;\n      p[(6 * 8) + col] = v1 - v6;\n      p[(2 * 8) + col] = v2 + v5;\n      p[(5 * 8) + col] = v2 - v5;\n      p[(3 * 8) + col] = v3 + v4;\n      p[(4 * 8) + col] = v3 - v4;\n    }\n\n    // convert to 8-bit integers\n    for (i = 0; i < 64; ++i) {\n      const sample = 128 + ((p[i] + 8) >> 4);\n      if (sample < 0) {\n        dataOut[i] = 0;\n      } else if (sample > 0XFF) {\n        dataOut[i] = 0xFF;\n      } else {\n        dataOut[i] = sample;\n      }\n    }\n  }\n\n  for (let blockRow = 0; blockRow < blocksPerColumn; blockRow++) {\n    const scanLine = blockRow << 3;\n    for (let i = 0; i < 8; i++) {\n      lines.push(new Uint8Array(samplesPerLine));\n    }\n    for (let blockCol = 0; blockCol < blocksPerLine; blockCol++) {\n      quantizeAndInverse(component.blocks[blockRow][blockCol], r, R);\n\n      let offset = 0;\n      const sample = blockCol << 3;\n      for (let j = 0; j < 8; j++) {\n        const line = lines[scanLine + j];\n        for (let i = 0; i < 8; i++) {\n          line[sample + i] = r[offset++];\n        }\n      }\n    }\n  }\n  return lines;\n}\n\nclass JpegStreamReader {\n  constructor() {\n    this.jfif = null;\n    this.adobe = null;\n\n    this.quantizationTables = [];\n    this.huffmanTablesAC = [];\n    this.huffmanTablesDC = [];\n    this.resetFrames();\n  }\n\n  resetFrames() {\n    this.frames = [];\n  }\n\n  parse(data) {\n    let offset = 0;\n    // const { length } = data;\n    function readUint16() {\n      const value = (data[offset] << 8) | data[offset + 1];\n      offset += 2;\n      return value;\n    }\n    function readDataBlock() {\n      const length = readUint16();\n      const array = data.subarray(offset, offset + length - 2);\n      offset += array.length;\n      return array;\n    }\n    function prepareComponents(frame) {\n      let maxH = 0;\n      let maxV = 0;\n      let component;\n      let componentId;\n      for (componentId in frame.components) {\n        if (frame.components.hasOwnProperty(componentId)) {\n          component = frame.components[componentId];\n          if (maxH < component.h) {\n            maxH = component.h;\n          }\n          if (maxV < component.v) {\n            maxV = component.v;\n          }\n        }\n      }\n      const mcusPerLine = Math.ceil(frame.samplesPerLine / 8 / maxH);\n      const mcusPerColumn = Math.ceil(frame.scanLines / 8 / maxV);\n      for (componentId in frame.components) {\n        if (frame.components.hasOwnProperty(componentId)) {\n          component = frame.components[componentId];\n          const blocksPerLine = Math.ceil(Math.ceil(frame.samplesPerLine / 8) * component.h / maxH);\n          const blocksPerColumn = Math.ceil(Math.ceil(frame.scanLines / 8) * component.v / maxV);\n          const blocksPerLineForMcu = mcusPerLine * component.h;\n          const blocksPerColumnForMcu = mcusPerColumn * component.v;\n          const blocks = [];\n          for (let i = 0; i < blocksPerColumnForMcu; i++) {\n            const row = [];\n            for (let j = 0; j < blocksPerLineForMcu; j++) {\n              row.push(new Int32Array(64));\n            }\n            blocks.push(row);\n          }\n          component.blocksPerLine = blocksPerLine;\n          component.blocksPerColumn = blocksPerColumn;\n          component.blocks = blocks;\n        }\n      }\n      frame.maxH = maxH;\n      frame.maxV = maxV;\n      frame.mcusPerLine = mcusPerLine;\n      frame.mcusPerColumn = mcusPerColumn;\n    }\n\n    let fileMarker = readUint16();\n    if (fileMarker !== 0xFFD8) { // SOI (Start of Image)\n      throw new Error('SOI not found');\n    }\n\n    fileMarker = readUint16();\n    while (fileMarker !== 0xFFD9) { // EOI (End of image)\n      switch (fileMarker) {\n        case 0xFF00: break;\n        case 0xFFE0: // APP0 (Application Specific)\n        case 0xFFE1: // APP1\n        case 0xFFE2: // APP2\n        case 0xFFE3: // APP3\n        case 0xFFE4: // APP4\n        case 0xFFE5: // APP5\n        case 0xFFE6: // APP6\n        case 0xFFE7: // APP7\n        case 0xFFE8: // APP8\n        case 0xFFE9: // APP9\n        case 0xFFEA: // APP10\n        case 0xFFEB: // APP11\n        case 0xFFEC: // APP12\n        case 0xFFED: // APP13\n        case 0xFFEE: // APP14\n        case 0xFFEF: // APP15\n        case 0xFFFE: { // COM (Comment)\n          const appData = readDataBlock();\n\n          if (fileMarker === 0xFFE0) {\n            if (appData[0] === 0x4A && appData[1] === 0x46 && appData[2] === 0x49\n              && appData[3] === 0x46 && appData[4] === 0) { // 'JFIF\\x00'\n              this.jfif = {\n                version: { major: appData[5], minor: appData[6] },\n                densityUnits: appData[7],\n                xDensity: (appData[8] << 8) | appData[9],\n                yDensity: (appData[10] << 8) | appData[11],\n                thumbWidth: appData[12],\n                thumbHeight: appData[13],\n                thumbData: appData.subarray(14, 14 + (3 * appData[12] * appData[13])),\n              };\n            }\n          }\n          // TODO APP1 - Exif\n          if (fileMarker === 0xFFEE) {\n            if (appData[0] === 0x41 && appData[1] === 0x64 && appData[2] === 0x6F\n              && appData[3] === 0x62 && appData[4] === 0x65 && appData[5] === 0) { // 'Adobe\\x00'\n              this.adobe = {\n                version: appData[6],\n                flags0: (appData[7] << 8) | appData[8],\n                flags1: (appData[9] << 8) | appData[10],\n                transformCode: appData[11],\n              };\n            }\n          }\n          break;\n        }\n\n        case 0xFFDB: { // DQT (Define Quantization Tables)\n          const quantizationTablesLength = readUint16();\n          const quantizationTablesEnd = quantizationTablesLength + offset - 2;\n          while (offset < quantizationTablesEnd) {\n            const quantizationTableSpec = data[offset++];\n            const tableData = new Int32Array(64);\n            if ((quantizationTableSpec >> 4) === 0) { // 8 bit values\n              for (let j = 0; j < 64; j++) {\n                const z = dctZigZag[j];\n                tableData[z] = data[offset++];\n              }\n            } else if ((quantizationTableSpec >> 4) === 1) { // 16 bit\n              for (let j = 0; j < 64; j++) {\n                const z = dctZigZag[j];\n                tableData[z] = readUint16();\n              }\n            } else {\n              throw new Error('DQT: invalid table spec');\n            }\n            this.quantizationTables[quantizationTableSpec & 15] = tableData;\n          }\n          break;\n        }\n\n        case 0xFFC0: // SOF0 (Start of Frame, Baseline DCT)\n        case 0xFFC1: // SOF1 (Start of Frame, Extended DCT)\n        case 0xFFC2: { // SOF2 (Start of Frame, Progressive DCT)\n          readUint16(); // skip data length\n          const frame = {\n            extended: (fileMarker === 0xFFC1),\n            progressive: (fileMarker === 0xFFC2),\n            precision: data[offset++],\n            scanLines: readUint16(),\n            samplesPerLine: readUint16(),\n            components: {},\n            componentsOrder: [],\n          };\n\n          const componentsCount = data[offset++];\n          let componentId;\n          // let maxH = 0;\n          // let maxV = 0;\n          for (let i = 0; i < componentsCount; i++) {\n            componentId = data[offset];\n            const h = data[offset + 1] >> 4;\n            const v = data[offset + 1] & 15;\n            const qId = data[offset + 2];\n            frame.componentsOrder.push(componentId);\n            frame.components[componentId] = {\n              h,\n              v,\n              quantizationIdx: qId,\n            };\n            offset += 3;\n          }\n          prepareComponents(frame);\n          this.frames.push(frame);\n          break;\n        }\n\n        case 0xFFC4: { // DHT (Define Huffman Tables)\n          const huffmanLength = readUint16();\n          for (let i = 2; i < huffmanLength;) {\n            const huffmanTableSpec = data[offset++];\n            const codeLengths = new Uint8Array(16);\n            let codeLengthSum = 0;\n            for (let j = 0; j < 16; j++, offset++) {\n              codeLengths[j] = data[offset];\n              codeLengthSum += codeLengths[j];\n            }\n            const huffmanValues = new Uint8Array(codeLengthSum);\n            for (let j = 0; j < codeLengthSum; j++, offset++) {\n              huffmanValues[j] = data[offset];\n            }\n            i += 17 + codeLengthSum;\n\n            if ((huffmanTableSpec >> 4) === 0) {\n              this.huffmanTablesDC[huffmanTableSpec & 15] = buildHuffmanTable(\n                codeLengths, huffmanValues,\n              );\n            } else {\n              this.huffmanTablesAC[huffmanTableSpec & 15] = buildHuffmanTable(\n                codeLengths, huffmanValues,\n              );\n            }\n          }\n          break;\n        }\n\n        case 0xFFDD: // DRI (Define Restart Interval)\n          readUint16(); // skip data length\n          this.resetInterval = readUint16();\n          break;\n\n        case 0xFFDA: { // SOS (Start of Scan)\n          readUint16(); // skip length\n          const selectorsCount = data[offset++];\n          const components = [];\n          const frame = this.frames[0];\n          for (let i = 0; i < selectorsCount; i++) {\n            const component = frame.components[data[offset++]];\n            const tableSpec = data[offset++];\n            component.huffmanTableDC = this.huffmanTablesDC[tableSpec >> 4];\n            component.huffmanTableAC = this.huffmanTablesAC[tableSpec & 15];\n            components.push(component);\n          }\n          const spectralStart = data[offset++];\n          const spectralEnd = data[offset++];\n          const successiveApproximation = data[offset++];\n          const processed = decodeScan(data, offset,\n            frame, components, this.resetInterval,\n            spectralStart, spectralEnd,\n            successiveApproximation >> 4, successiveApproximation & 15);\n          offset += processed;\n          break;\n        }\n\n        case 0xFFFF: // Fill bytes\n          if (data[offset] !== 0xFF) { // Avoid skipping a valid marker.\n            offset--;\n          }\n          break;\n\n        default:\n          if (data[offset - 3] === 0xFF\n            && data[offset - 2] >= 0xC0 && data[offset - 2] <= 0xFE) {\n            // could be incorrect encoding -- last 0xFF byte of the previous\n            // block was eaten by the encoder\n            offset -= 3;\n            break;\n          }\n          throw new Error(`unknown JPEG marker ${fileMarker.toString(16)}`);\n      }\n      fileMarker = readUint16();\n    }\n  }\n\n  getResult() {\n    const { frames } = this;\n    if (this.frames.length === 0) {\n      throw new Error('no frames were decoded');\n    } else if (this.frames.length > 1) {\n      console.warn('more than one frame is not supported');\n    }\n\n    // set each frame's components quantization table\n    for (let i = 0; i < this.frames.length; i++) {\n      const cp = this.frames[i].components;\n      for (const j of Object.keys(cp)) {\n        cp[j].quantizationTable = this.quantizationTables[cp[j].quantizationIdx];\n        delete cp[j].quantizationIdx;\n      }\n    }\n\n    const frame = frames[0];\n    const { components, componentsOrder } = frame;\n    const outComponents = [];\n    const width = frame.samplesPerLine;\n    const height = frame.scanLines;\n\n    for (let i = 0; i < componentsOrder.length; i++) {\n      const component = components[componentsOrder[i]];\n      outComponents.push({\n        lines: buildComponentData(frame, component),\n        scaleX: component.h / frame.maxH,\n        scaleY: component.v / frame.maxV,\n      });\n    }\n\n    const out = new Uint8Array(width * height * outComponents.length);\n    let oi = 0;\n    for (let y = 0; y < height; ++y) {\n      for (let x = 0; x < width; ++x) {\n        for (let i = 0; i < outComponents.length; ++i) {\n          const component = outComponents[i];\n          out[oi] = component.lines[0 | y * component.scaleY][0 | x * component.scaleX];\n          ++oi;\n        }\n      }\n    }\n    return out;\n  }\n}\n\nclass JpegDecoder extends _basedecoder__WEBPACK_IMPORTED_MODULE_0__.default {\n  constructor(fileDirectory) {\n    super();\n    this.reader = new JpegStreamReader();\n    if (fileDirectory.JPEGTables) {\n      this.reader.parse(fileDirectory.JPEGTables);\n    }\n  }\n\n  decodeBlock(buffer) {\n    this.reader.resetFrames();\n    this.reader.parse(new Uint8Array(buffer));\n    return this.reader.getResult().buffer;\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/compression/jpeg.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/compression/lzw.js":
/*!******************************************************!*\
  !*** ../node_modules/geotiff/src/compression/lzw.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ LZWDecoder)\n/* harmony export */ });\n/* harmony import */ var _basedecoder__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./basedecoder */ \"../node_modules/geotiff/src/compression/basedecoder.js\");\n\n\n\nconst MIN_BITS = 9;\nconst CLEAR_CODE = 256; // clear code\nconst EOI_CODE = 257; // end of information\nconst MAX_BYTELENGTH = 12;\n\nfunction getByte(array, position, length) {\n  const d = position % 8;\n  const a = Math.floor(position / 8);\n  const de = 8 - d;\n  const ef = (position + length) - ((a + 1) * 8);\n  let fg = (8 * (a + 2)) - (position + length);\n  const dg = ((a + 2) * 8) - position;\n  fg = Math.max(0, fg);\n  if (a >= array.length) {\n    console.warn('ran off the end of the buffer before finding EOI_CODE (end on input code)');\n    return EOI_CODE;\n  }\n  let chunk1 = array[a] & ((2 ** (8 - d)) - 1);\n  chunk1 <<= (length - de);\n  let chunks = chunk1;\n  if (a + 1 < array.length) {\n    let chunk2 = array[a + 1] >>> fg;\n    chunk2 <<= Math.max(0, (length - dg));\n    chunks += chunk2;\n  }\n  if (ef > 8 && a + 2 < array.length) {\n    const hi = ((a + 3) * 8) - (position + length);\n    const chunk3 = array[a + 2] >>> hi;\n    chunks += chunk3;\n  }\n  return chunks;\n}\n\nfunction appendReversed(dest, source) {\n  for (let i = source.length - 1; i >= 0; i--) {\n    dest.push(source[i]);\n  }\n  return dest;\n}\n\nfunction decompress(input) {\n  const dictionaryIndex = new Uint16Array(4093);\n  const dictionaryChar = new Uint8Array(4093);\n  for (let i = 0; i <= 257; i++) {\n    dictionaryIndex[i] = 4096;\n    dictionaryChar[i] = i;\n  }\n  let dictionaryLength = 258;\n  let byteLength = MIN_BITS;\n  let position = 0;\n\n  function initDictionary() {\n    dictionaryLength = 258;\n    byteLength = MIN_BITS;\n  }\n  function getNext(array) {\n    const byte = getByte(array, position, byteLength);\n    position += byteLength;\n    return byte;\n  }\n  function addToDictionary(i, c) {\n    dictionaryChar[dictionaryLength] = c;\n    dictionaryIndex[dictionaryLength] = i;\n    dictionaryLength++;\n    return dictionaryLength - 1;\n  }\n  function getDictionaryReversed(n) {\n    const rev = [];\n    for (let i = n; i !== 4096; i = dictionaryIndex[i]) {\n      rev.push(dictionaryChar[i]);\n    }\n    return rev;\n  }\n\n  const result = [];\n  initDictionary();\n  const array = new Uint8Array(input);\n  let code = getNext(array);\n  let oldCode;\n  while (code !== EOI_CODE) {\n    if (code === CLEAR_CODE) {\n      initDictionary();\n      code = getNext(array);\n      while (code === CLEAR_CODE) {\n        code = getNext(array);\n      }\n\n      if (code === EOI_CODE) {\n        break;\n      } else if (code > CLEAR_CODE) {\n        throw new Error(`corrupted code at scanline ${code}`);\n      } else {\n        const val = getDictionaryReversed(code);\n        appendReversed(result, val);\n        oldCode = code;\n      }\n    } else if (code < dictionaryLength) {\n      const val = getDictionaryReversed(code);\n      appendReversed(result, val);\n      addToDictionary(oldCode, val[val.length - 1]);\n      oldCode = code;\n    } else {\n      const oldVal = getDictionaryReversed(oldCode);\n      if (!oldVal) {\n        throw new Error(`Bogus entry. Not in dictionary, ${oldCode} / ${dictionaryLength}, position: ${position}`);\n      }\n      appendReversed(result, oldVal);\n      result.push(oldVal[oldVal.length - 1]);\n      addToDictionary(oldCode, oldVal[oldVal.length - 1]);\n      oldCode = code;\n    }\n\n    if (dictionaryLength + 1 >= (2 ** byteLength)) {\n      if (byteLength === MAX_BYTELENGTH) {\n        oldCode = undefined;\n      } else {\n        byteLength++;\n      }\n    }\n    code = getNext(array);\n  }\n  return new Uint8Array(result);\n}\n\nclass LZWDecoder extends _basedecoder__WEBPACK_IMPORTED_MODULE_0__.default {\n  decodeBlock(buffer) {\n    return decompress(buffer, false).buffer;\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/compression/lzw.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/compression/packbits.js":
/*!***********************************************************!*\
  !*** ../node_modules/geotiff/src/compression/packbits.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ PackbitsDecoder)\n/* harmony export */ });\n/* harmony import */ var _basedecoder__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./basedecoder */ \"../node_modules/geotiff/src/compression/basedecoder.js\");\n\n\n\nclass PackbitsDecoder extends _basedecoder__WEBPACK_IMPORTED_MODULE_0__.default {\n  decodeBlock(buffer) {\n    const dataView = new DataView(buffer);\n    const out = [];\n\n    for (let i = 0; i < buffer.byteLength; ++i) {\n      let header = dataView.getInt8(i);\n      if (header < 0) {\n        const next = dataView.getUint8(i + 1);\n        header = -header;\n        for (let j = 0; j <= header; ++j) {\n          out.push(next);\n        }\n        i += 1;\n      } else {\n        for (let j = 0; j <= header; ++j) {\n          out.push(dataView.getUint8(i + j + 1));\n        }\n        i += header + 1;\n      }\n    }\n    return new Uint8Array(out).buffer;\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/compression/packbits.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/compression/raw.js":
/*!******************************************************!*\
  !*** ../node_modules/geotiff/src/compression/raw.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ RawDecoder)\n/* harmony export */ });\n/* harmony import */ var _basedecoder__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./basedecoder */ \"../node_modules/geotiff/src/compression/basedecoder.js\");\n\n\n\nclass RawDecoder extends _basedecoder__WEBPACK_IMPORTED_MODULE_0__.default {\n  decodeBlock(buffer) {\n    return buffer;\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/compression/raw.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/dataslice.js":
/*!************************************************!*\
  !*** ../node_modules/geotiff/src/dataslice.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ DataSlice)\n/* harmony export */ });\nclass DataSlice {\n  constructor(arrayBuffer, sliceOffset, littleEndian, bigTiff) {\n    this._dataView = new DataView(arrayBuffer);\n    this._sliceOffset = sliceOffset;\n    this._littleEndian = littleEndian;\n    this._bigTiff = bigTiff;\n  }\n\n  get sliceOffset() {\n    return this._sliceOffset;\n  }\n\n  get sliceTop() {\n    return this._sliceOffset + this.buffer.byteLength;\n  }\n\n  get littleEndian() {\n    return this._littleEndian;\n  }\n\n  get bigTiff() {\n    return this._bigTiff;\n  }\n\n  get buffer() {\n    return this._dataView.buffer;\n  }\n\n  covers(offset, length) {\n    return this.sliceOffset <= offset && this.sliceTop >= offset + length;\n  }\n\n  readUint8(offset) {\n    return this._dataView.getUint8(\n      offset - this._sliceOffset, this._littleEndian,\n    );\n  }\n\n  readInt8(offset) {\n    return this._dataView.getInt8(\n      offset - this._sliceOffset, this._littleEndian,\n    );\n  }\n\n  readUint16(offset) {\n    return this._dataView.getUint16(\n      offset - this._sliceOffset, this._littleEndian,\n    );\n  }\n\n  readInt16(offset) {\n    return this._dataView.getInt16(\n      offset - this._sliceOffset, this._littleEndian,\n    );\n  }\n\n  readUint32(offset) {\n    return this._dataView.getUint32(\n      offset - this._sliceOffset, this._littleEndian,\n    );\n  }\n\n  readInt32(offset) {\n    return this._dataView.getInt32(\n      offset - this._sliceOffset, this._littleEndian,\n    );\n  }\n\n  readFloat32(offset) {\n    return this._dataView.getFloat32(\n      offset - this._sliceOffset, this._littleEndian,\n    );\n  }\n\n  readFloat64(offset) {\n    return this._dataView.getFloat64(\n      offset - this._sliceOffset, this._littleEndian,\n    );\n  }\n\n  readUint64(offset) {\n    const left = this.readUint32(offset);\n    const right = this.readUint32(offset + 4);\n    let combined;\n    if (this._littleEndian) {\n      combined = left + 2 ** 32 * right;\n      if (!Number.isSafeInteger(combined)) {\n        throw new Error(\n          `${combined} exceeds MAX_SAFE_INTEGER. Precision may be lost. Please report if you get this message to https://github.com/geotiffjs/geotiff.js/issues`,\n        );\n      }\n      return combined;\n    }\n    combined = 2 ** 32 * left + right;\n    if (!Number.isSafeInteger(combined)) {\n      throw new Error(\n        `${combined} exceeds MAX_SAFE_INTEGER. Precision may be lost. Please report if you get this message to https://github.com/geotiffjs/geotiff.js/issues`,\n      );\n    }\n\n    return combined;\n  }\n\n  // adapted from https://stackoverflow.com/a/55338384/8060591\n  readInt64(offset) {\n    let value = 0;\n    const isNegative =\n      (this._dataView.getUint8(offset + (this._littleEndian ? 7 : 0)) & 0x80) >\n      0;\n    let carrying = true;\n    for (let i = 0; i < 8; i++) {\n      let byte = this._dataView.getUint8(\n        offset + (this._littleEndian ? i : 7 - i)\n      );\n      if (isNegative) {\n        if (carrying) {\n          if (byte !== 0x00) {\n            byte = ~(byte - 1) & 0xff;\n            carrying = false;\n          }\n        } else {\n          byte = ~byte & 0xff;\n        }\n      }\n      value += byte * 256 ** i;\n    }\n    if (isNegative) {\n      value = -value;\n    }\n    return value\n  }\n\n  readOffset(offset) {\n    if (this._bigTiff) {\n      return this.readUint64(offset);\n    }\n    return this.readUint32(offset);\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/dataslice.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/dataview64.js":
/*!*************************************************!*\
  !*** ../node_modules/geotiff/src/dataview64.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ DataView64)\n/* harmony export */ });\n/* harmony import */ var _petamoriken_float16__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @petamoriken/float16 */ \"../node_modules/@petamoriken/float16/src/dataView.js\");\n\n\nclass DataView64 {\n  constructor(arrayBuffer) {\n    this._dataView = new DataView(arrayBuffer);\n  }\n\n  get buffer() {\n    return this._dataView.buffer;\n  }\n\n  getUint64(offset, littleEndian) {\n    const left = this.getUint32(offset, littleEndian);\n    const right = this.getUint32(offset + 4, littleEndian);\n    let combined;\n    if (littleEndian) {\n      combined = left + 2 ** 32 * right;\n      if (!Number.isSafeInteger(combined)) {\n        throw new Error(\n          `${combined} exceeds MAX_SAFE_INTEGER. Precision may be lost. Please report if you get this message to https://github.com/geotiffjs/geotiff.js/issues`\n        );\n      }\n      return combined;\n    }\n    combined = 2 ** 32 * left + right;\n    if (!Number.isSafeInteger(combined)) {\n      throw new Error(\n        `${combined} exceeds MAX_SAFE_INTEGER. Precision may be lost. Please report if you get this message to https://github.com/geotiffjs/geotiff.js/issues`\n      );\n    }\n\n    return combined;\n  }\n\n  // adapted from https://stackoverflow.com/a/55338384/8060591\n  getInt64(offset, littleEndian) {\n    let value = 0;\n    const isNegative =\n      (this._dataView.getUint8(offset + (littleEndian ? 7 : 0)) & 0x80) > 0;\n    let carrying = true;\n    for (let i = 0; i < 8; i++) {\n      let byte = this._dataView.getUint8(offset + (littleEndian ? i : 7 - i));\n      if (isNegative) {\n        if (carrying) {\n          if (byte !== 0x00) {\n            byte = ~(byte - 1) & 0xff;\n            carrying = false;\n          }\n        } else {\n          byte = ~byte & 0xff;\n        }\n      }\n      value += byte * 256 ** i;\n    }\n    if (isNegative) {\n      value = -value;\n    }\n    return value;\n  }\n\n  getUint8(offset, littleEndian) {\n    return this._dataView.getUint8(offset, littleEndian);\n  }\n\n  getInt8(offset, littleEndian) {\n    return this._dataView.getInt8(offset, littleEndian);\n  }\n\n  getUint16(offset, littleEndian) {\n    return this._dataView.getUint16(offset, littleEndian);\n  }\n\n  getInt16(offset, littleEndian) {\n    return this._dataView.getInt16(offset, littleEndian);\n  }\n\n  getUint32(offset, littleEndian) {\n    return this._dataView.getUint32(offset, littleEndian);\n  }\n\n  getInt32(offset, littleEndian) {\n    return this._dataView.getInt32(offset, littleEndian);\n  }\n\n  getFloat16(offset, littleEndian) {\n    return (0,_petamoriken_float16__WEBPACK_IMPORTED_MODULE_0__.getFloat16)(this._dataView, littleEndian);\n  }\n\n  getFloat32(offset, littleEndian) {\n    return this._dataView.getFloat32(offset, littleEndian);\n  }\n\n  getFloat64(offset, littleEndian) {\n    return this._dataView.getFloat64(offset, littleEndian);\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/dataview64.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/geotiff.js":
/*!**********************************************!*\
  !*** ../node_modules/geotiff/src/geotiff.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"globals\": () => (/* reexport module object */ _globals__WEBPACK_IMPORTED_MODULE_8__),\n/* harmony export */   \"rgb\": () => (/* reexport module object */ _rgb__WEBPACK_IMPORTED_MODULE_10__),\n/* harmony export */   \"getDecoder\": () => (/* reexport safe */ _compression__WEBPACK_IMPORTED_MODULE_11__.getDecoder),\n/* harmony export */   \"setLogger\": () => (/* reexport safe */ _logging__WEBPACK_IMPORTED_MODULE_12__.setLogger),\n/* harmony export */   \"GeoTIFF\": () => (/* binding */ GeoTIFF),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__),\n/* harmony export */   \"MultiGeoTIFF\": () => (/* binding */ MultiGeoTIFF),\n/* harmony export */   \"fromUrl\": () => (/* binding */ fromUrl),\n/* harmony export */   \"fromArrayBuffer\": () => (/* binding */ fromArrayBuffer),\n/* harmony export */   \"fromFile\": () => (/* binding */ fromFile),\n/* harmony export */   \"fromBlob\": () => (/* binding */ fromBlob),\n/* harmony export */   \"fromUrls\": () => (/* binding */ fromUrls),\n/* harmony export */   \"writeArrayBuffer\": () => (/* binding */ writeArrayBuffer),\n/* harmony export */   \"Pool\": () => (/* reexport safe */ _pool__WEBPACK_IMPORTED_MODULE_3__.default)\n/* harmony export */ });\n/* harmony import */ var _geotiffimage__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./geotiffimage */ \"../node_modules/geotiff/src/geotiffimage.js\");\n/* harmony import */ var _dataview64__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./dataview64 */ \"../node_modules/geotiff/src/dataview64.js\");\n/* harmony import */ var _dataslice__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./dataslice */ \"../node_modules/geotiff/src/dataslice.js\");\n/* harmony import */ var _pool__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./pool */ \"../node_modules/geotiff/src/pool.js\");\n/* harmony import */ var _source_remote__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./source/remote */ \"../node_modules/geotiff/src/source/remote.js\");\n/* harmony import */ var _source_arraybuffer__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./source/arraybuffer */ \"../node_modules/geotiff/src/source/arraybuffer.js\");\n/* harmony import */ var _source_filereader__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./source/filereader */ \"../node_modules/geotiff/src/source/filereader.js\");\n/* harmony import */ var _source_file__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./source/file */ \"../node_modules/geotiff/src/source/file.js\");\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./globals */ \"../node_modules/geotiff/src/globals.js\");\n/* harmony import */ var _geotiffwriter__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./geotiffwriter */ \"../node_modules/geotiff/src/geotiffwriter.js\");\n/* harmony import */ var _rgb__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./rgb */ \"../node_modules/geotiff/src/rgb.js\");\n/* harmony import */ var _compression__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./compression */ \"../node_modules/geotiff/src/compression/index.js\");\n/* harmony import */ var _logging__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./logging */ \"../node_modules/geotiff/src/logging.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfunction getFieldTypeLength(fieldType) {\n  switch (fieldType) {\n    case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.BYTE: case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.ASCII: case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.SBYTE: case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.UNDEFINED:\n      return 1;\n    case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.SHORT: case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.SSHORT:\n      return 2;\n    case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.LONG: case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.SLONG: case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.FLOAT: case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.IFD:\n      return 4;\n    case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.RATIONAL: case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.SRATIONAL: case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.DOUBLE:\n    case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.LONG8: case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.SLONG8: case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.IFD8:\n      return 8;\n    default:\n      throw new RangeError(`Invalid field type: ${fieldType}`);\n  }\n}\n\nfunction parseGeoKeyDirectory(fileDirectory) {\n  const rawGeoKeyDirectory = fileDirectory.GeoKeyDirectory;\n  if (!rawGeoKeyDirectory) {\n    return null;\n  }\n\n  const geoKeyDirectory = {};\n  for (let i = 4; i <= rawGeoKeyDirectory[3] * 4; i += 4) {\n    const key = _globals__WEBPACK_IMPORTED_MODULE_8__.geoKeyNames[rawGeoKeyDirectory[i]];\n    const location = (rawGeoKeyDirectory[i + 1])\n      ? (_globals__WEBPACK_IMPORTED_MODULE_8__.fieldTagNames[rawGeoKeyDirectory[i + 1]]) : null;\n    const count = rawGeoKeyDirectory[i + 2];\n    const offset = rawGeoKeyDirectory[i + 3];\n\n    let value = null;\n    if (!location) {\n      value = offset;\n    } else {\n      value = fileDirectory[location];\n      if (typeof value === 'undefined' || value === null) {\n        throw new Error(`Could not get value of geoKey '${key}'.`);\n      } else if (typeof value === 'string') {\n        value = value.substring(offset, offset + count - 1);\n      } else if (value.subarray) {\n        value = value.subarray(offset, offset + count);\n        if (count === 1) {\n          value = value[0];\n        }\n      }\n    }\n    geoKeyDirectory[key] = value;\n  }\n  return geoKeyDirectory;\n}\n\nfunction getValues(dataSlice, fieldType, count, offset) {\n  let values = null;\n  let readMethod = null;\n  const fieldTypeLength = getFieldTypeLength(fieldType);\n\n  switch (fieldType) {\n    case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.BYTE: case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.ASCII: case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.UNDEFINED:\n      values = new Uint8Array(count); readMethod = dataSlice.readUint8;\n      break;\n    case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.SBYTE:\n      values = new Int8Array(count); readMethod = dataSlice.readInt8;\n      break;\n    case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.SHORT:\n      values = new Uint16Array(count); readMethod = dataSlice.readUint16;\n      break;\n    case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.SSHORT:\n      values = new Int16Array(count); readMethod = dataSlice.readInt16;\n      break;\n    case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.LONG: case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.IFD:\n      values = new Uint32Array(count); readMethod = dataSlice.readUint32;\n      break;\n    case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.SLONG:\n      values = new Int32Array(count); readMethod = dataSlice.readInt32;\n      break;\n    case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.LONG8: case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.IFD8:\n      values = new Array(count); readMethod = dataSlice.readUint64;\n      break;\n    case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.SLONG8:\n      values = new Array(count); readMethod = dataSlice.readInt64;\n      break;\n    case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.RATIONAL:\n      values = new Uint32Array(count * 2); readMethod = dataSlice.readUint32;\n      break;\n    case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.SRATIONAL:\n      values = new Int32Array(count * 2); readMethod = dataSlice.readInt32;\n      break;\n    case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.FLOAT:\n      values = new Float32Array(count); readMethod = dataSlice.readFloat32;\n      break;\n    case _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.DOUBLE:\n      values = new Float64Array(count); readMethod = dataSlice.readFloat64;\n      break;\n    default:\n      throw new RangeError(`Invalid field type: ${fieldType}`);\n  }\n\n  // normal fields\n  if (!(fieldType === _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.RATIONAL || fieldType === _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.SRATIONAL)) {\n    for (let i = 0; i < count; ++i) {\n      values[i] = readMethod.call(\n        dataSlice, offset + (i * fieldTypeLength),\n      );\n    }\n  } else { // RATIONAL or SRATIONAL\n    for (let i = 0; i < count; i += 2) {\n      values[i] = readMethod.call(\n        dataSlice, offset + (i * fieldTypeLength),\n      );\n      values[i + 1] = readMethod.call(\n        dataSlice, offset + ((i * fieldTypeLength) + 4),\n      );\n    }\n  }\n\n  if (fieldType === _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.ASCII) {\n    return new TextDecoder('utf-8').decode(values);\n  }\n  return values;\n}\n\n/**\n * Data class to store the parsed file directory, geo key directory and\n * offset to the next IFD\n */\nclass ImageFileDirectory {\n  constructor(fileDirectory, geoKeyDirectory, nextIFDByteOffset) {\n    this.fileDirectory = fileDirectory;\n    this.geoKeyDirectory = geoKeyDirectory;\n    this.nextIFDByteOffset = nextIFDByteOffset;\n  }\n}\n\n/**\n * Error class for cases when an IFD index was requested, that does not exist\n * in the file.\n */\nclass GeoTIFFImageIndexError extends Error {\n  constructor(index) {\n    super(`No image at index ${index}`);\n    this.index = index;\n  }\n}\n\n\nclass GeoTIFFBase {\n  /**\n   * (experimental) Reads raster data from the best fitting image. This function uses\n   * the image with the lowest resolution that is still a higher resolution than the\n   * requested resolution.\n   * When specified, the `bbox` option is translated to the `window` option and the\n   * `resX` and `resY` to `width` and `height` respectively.\n   * Then, the [readRasters]{@link GeoTIFFImage#readRasters} method of the selected\n   * image is called and the result returned.\n   * @see GeoTIFFImage.readRasters\n   * @param {Object} [options={}] optional parameters\n   * @param {Array} [options.window=whole image] the subset to read data from.\n   * @param {Array} [options.bbox=whole image] the subset to read data from in\n   *                                           geographical coordinates.\n   * @param {Array} [options.samples=all samples] the selection of samples to read from.\n   * @param {Boolean} [options.interleave=false] whether the data shall be read\n   *                                             in one single array or separate\n   *                                             arrays.\n   * @param {Number} [options.pool=null] The optional decoder pool to use.\n   * @param {Number} [options.width] The desired width of the output. When the width is not the\n   *                                 same as the images, resampling will be performed.\n   * @param {Number} [options.height] The desired height of the output. When the width is not the\n   *                                  same as the images, resampling will be performed.\n   * @param {String} [options.resampleMethod='nearest'] The desired resampling method.\n   * @param {AbortSignal} [options.signal] An AbortSignal that may be signalled if the request is\n   *                                       to be aborted\n   * @param {Number|Number[]} [options.fillValue] The value to use for parts of the image\n   *                                              outside of the images extent. When multiple\n   *                                              samples are requested, an array of fill values\n   *                                              can be passed.\n   * @returns {Promise.<(TypedArray|TypedArray[])>} the decoded arrays as a promise\n   */\n  async readRasters(options = {}) {\n    const { window: imageWindow, width, height } = options;\n    let { resX, resY, bbox } = options;\n\n    const firstImage = await this.getImage();\n    let usedImage = firstImage;\n    const imageCount = await this.getImageCount();\n    const imgBBox = firstImage.getBoundingBox();\n\n    if (imageWindow && bbox) {\n      throw new Error('Both \"bbox\" and \"window\" passed.');\n    }\n\n    // if width/height is passed, transform it to resolution\n    if (width || height) {\n      // if we have an image window (pixel coordinates), transform it to a BBox\n      // using the origin/resolution of the first image.\n      if (imageWindow) {\n        const [oX, oY] = firstImage.getOrigin();\n        const [rX, rY] = firstImage.getResolution();\n\n        bbox = [\n          oX + (imageWindow[0] * rX),\n          oY + (imageWindow[1] * rY),\n          oX + (imageWindow[2] * rX),\n          oY + (imageWindow[3] * rY),\n        ];\n      }\n\n      // if we have a bbox (or calculated one)\n\n      const usedBBox = bbox || imgBBox;\n\n      if (width) {\n        if (resX) {\n          throw new Error('Both width and resX passed');\n        }\n        resX = (usedBBox[2] - usedBBox[0]) / width;\n      }\n      if (height) {\n        if (resY) {\n          throw new Error('Both width and resY passed');\n        }\n        resY = (usedBBox[3] - usedBBox[1]) / height;\n      }\n    }\n\n    // if resolution is set or calculated, try to get the image with the worst acceptable resolution\n    if (resX || resY) {\n      const allImages = [];\n      for (let i = 0; i < imageCount; ++i) {\n        const image = await this.getImage(i);\n        const { SubfileType: subfileType, NewSubfileType: newSubfileType } = image.fileDirectory;\n        if (i === 0 || subfileType === 2 || newSubfileType & 1) {\n          allImages.push(image);\n        }\n      }\n\n      allImages.sort((a, b) => a.getWidth() - b.getWidth());\n      for (let i = 0; i < allImages.length; ++i) {\n        const image = allImages[i];\n        const imgResX = (imgBBox[2] - imgBBox[0]) / image.getWidth();\n        const imgResY = (imgBBox[3] - imgBBox[1]) / image.getHeight();\n\n        usedImage = image;\n        if ((resX && resX > imgResX) || (resY && resY > imgResY)) {\n          break;\n        }\n      }\n    }\n\n    let wnd = imageWindow;\n    if (bbox) {\n      const [oX, oY] = firstImage.getOrigin();\n      const [imageResX, imageResY] = usedImage.getResolution(firstImage);\n\n      wnd = [\n        Math.round((bbox[0] - oX) / imageResX),\n        Math.round((bbox[1] - oY) / imageResY),\n        Math.round((bbox[2] - oX) / imageResX),\n        Math.round((bbox[3] - oY) / imageResY),\n      ];\n      wnd = [\n        Math.min(wnd[0], wnd[2]),\n        Math.min(wnd[1], wnd[3]),\n        Math.max(wnd[0], wnd[2]),\n        Math.max(wnd[1], wnd[3]),\n      ];\n    }\n\n    return usedImage.readRasters({ ...options, window: wnd });\n  }\n}\n\n\n/**\n * The abstraction for a whole GeoTIFF file.\n * @augments GeoTIFFBase\n */\nclass GeoTIFF extends GeoTIFFBase {\n  /**\n   * @constructor\n   * @param {Source} source The datasource to read from.\n   * @param {Boolean} littleEndian Whether the image uses little endian.\n   * @param {Boolean} bigTiff Whether the image uses bigTIFF conventions.\n   * @param {Number} firstIFDOffset The numeric byte-offset from the start of the image\n   *                                to the first IFD.\n   * @param {Object} [options] further options.\n   * @param {Boolean} [options.cache=false] whether or not decoded tiles shall be cached.\n   */\n  constructor(source, littleEndian, bigTiff, firstIFDOffset, options = {}) {\n    super();\n    this.source = source;\n    this.littleEndian = littleEndian;\n    this.bigTiff = bigTiff;\n    this.firstIFDOffset = firstIFDOffset;\n    this.cache = options.cache || false;\n    this.ifdRequests = [];\n    this.ghostValues = null;\n  }\n\n  async getSlice(offset, size) {\n    const fallbackSize = this.bigTiff ? 4048 : 1024;\n    return new _dataslice__WEBPACK_IMPORTED_MODULE_2__.default(\n      (await this.source.fetch([{\n        offset,\n        length: typeof size !== 'undefined' ? size : fallbackSize,\n      }]))[0],\n      offset,\n      this.littleEndian,\n      this.bigTiff,\n    );\n  }\n\n  /**\n   * Instructs to parse an image file directory at the given file offset.\n   * As there is no way to ensure that a location is indeed the start of an IFD,\n   * this function must be called with caution (e.g only using the IFD offsets from\n   * the headers or other IFDs).\n   * @param {number} offset the offset to parse the IFD at\n   * @returns {ImageFileDirectory} the parsed IFD\n   */\n  async parseFileDirectoryAt(offset) {\n    const entrySize = this.bigTiff ? 20 : 12;\n    const offsetSize = this.bigTiff ? 8 : 2;\n\n    let dataSlice = await this.getSlice(offset);\n    const numDirEntries = this.bigTiff ?\n      dataSlice.readUint64(offset) :\n      dataSlice.readUint16(offset);\n\n    // if the slice does not cover the whole IFD, request a bigger slice, where the\n    // whole IFD fits: num of entries + n x tag length + offset to next IFD\n    const byteSize = (numDirEntries * entrySize) + (this.bigTiff ? 16 : 6);\n    if (!dataSlice.covers(offset, byteSize)) {\n      dataSlice = await this.getSlice(offset, byteSize);\n    }\n\n    const fileDirectory = {};\n\n    // loop over the IFD and create a file directory object\n    let i = offset + (this.bigTiff ? 8 : 2);\n    for (let entryCount = 0; entryCount < numDirEntries; i += entrySize, ++entryCount) {\n      const fieldTag = dataSlice.readUint16(i);\n      const fieldType = dataSlice.readUint16(i + 2);\n      const typeCount = this.bigTiff ?\n        dataSlice.readUint64(i + 4) :\n        dataSlice.readUint32(i + 4);\n\n      let fieldValues;\n      let value;\n      const fieldTypeLength = getFieldTypeLength(fieldType);\n      const valueOffset = i + (this.bigTiff ? 12 : 8);\n\n      // check whether the value is directly encoded in the tag or refers to a\n      // different external byte range\n      if (fieldTypeLength * typeCount <= (this.bigTiff ? 8 : 4)) {\n        fieldValues = getValues(dataSlice, fieldType, typeCount, valueOffset);\n      } else {\n        // resolve the reference to the actual byte range\n        const actualOffset = dataSlice.readOffset(valueOffset);\n        const length = getFieldTypeLength(fieldType) * typeCount;\n\n        // check, whether we actually cover the referenced byte range; if not,\n        // request a new slice of bytes to read from it\n        if (dataSlice.covers(actualOffset, length)) {\n          fieldValues = getValues(dataSlice, fieldType, typeCount, actualOffset);\n        } else {\n          const fieldDataSlice = await this.getSlice(actualOffset, length);\n          fieldValues = getValues(fieldDataSlice, fieldType, typeCount, actualOffset);\n        }\n      }\n\n      // unpack single values from the array\n      if (typeCount === 1 && _globals__WEBPACK_IMPORTED_MODULE_8__.arrayFields.indexOf(fieldTag) === -1 &&\n        !(fieldType === _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.RATIONAL || fieldType === _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.SRATIONAL)) {\n        value = fieldValues[0];\n      } else {\n        value = fieldValues;\n      }\n\n      // write the tags value to the file directly\n      fileDirectory[_globals__WEBPACK_IMPORTED_MODULE_8__.fieldTagNames[fieldTag]] = value;\n    }\n    const geoKeyDirectory = parseGeoKeyDirectory(fileDirectory);\n    const nextIFDByteOffset = dataSlice.readOffset(\n      offset + offsetSize + (entrySize * numDirEntries),\n    );\n\n    return new ImageFileDirectory(\n      fileDirectory,\n      geoKeyDirectory,\n      nextIFDByteOffset,\n    );\n  }\n\n  async requestIFD(index) {\n    // see if we already have that IFD index requested.\n    if (this.ifdRequests[index]) {\n      // attach to an already requested IFD\n      return this.ifdRequests[index];\n    } else if (index === 0) {\n      // special case for index 0\n      this.ifdRequests[index] = this.parseFileDirectoryAt(this.firstIFDOffset);\n      return this.ifdRequests[index];\n    } else if (!this.ifdRequests[index - 1]) {\n      // if the previous IFD was not yet loaded, load that one first\n      // this is the recursive call.\n      try {\n        this.ifdRequests[index - 1] = this.requestIFD(index - 1);\n      } catch (e) {\n        // if the previous one already was an index error, rethrow\n        // with the current index\n        if (e instanceof GeoTIFFImageIndexError) {\n          throw new GeoTIFFImageIndexError(index);\n        }\n        // rethrow anything else\n        throw e;\n      }\n    }\n    // if the previous IFD was loaded, we can finally fetch the one we are interested in.\n    // we need to wrap this in an IIFE, otherwise this.ifdRequests[index] would be delayed\n    this.ifdRequests[index] = (async () => {\n      const previousIfd = await this.ifdRequests[index - 1];\n      if (previousIfd.nextIFDByteOffset === 0) {\n        throw new GeoTIFFImageIndexError(index);\n      }\n      return this.parseFileDirectoryAt(previousIfd.nextIFDByteOffset);\n    })();\n    return this.ifdRequests[index];\n  }\n\n  /**\n   * Get the n-th internal subfile of an image. By default, the first is returned.\n   *\n   * @param {Number} [index=0] the index of the image to return.\n   * @returns {GeoTIFFImage} the image at the given index\n   */\n  async getImage(index = 0) {\n    const ifd = await this.requestIFD(index);\n    return new _geotiffimage__WEBPACK_IMPORTED_MODULE_0__.default(\n      ifd.fileDirectory, ifd.geoKeyDirectory,\n      this.dataView, this.littleEndian, this.cache, this.source,\n    );\n  }\n\n  /**\n   * Returns the count of the internal subfiles.\n   *\n   * @returns {Number} the number of internal subfile images\n   */\n  async getImageCount() {\n    let index = 0;\n    // loop until we run out of IFDs\n    let hasNext = true;\n    while (hasNext) {\n      try {\n        await this.requestIFD(index);\n        ++index;\n      } catch (e) {\n        if (e instanceof GeoTIFFImageIndexError) {\n          hasNext = false;\n        } else {\n          throw e;\n        }\n      }\n    }\n    return index;\n  }\n\n  /**\n   * Get the values of the COG ghost area as a parsed map.\n   * See https://gdal.org/drivers/raster/cog.html#header-ghost-area for reference\n   * @returns {Object} the parsed ghost area or null, if no such area was found\n   */\n  async getGhostValues() {\n    const offset = this.bigTiff ? 16 : 8;\n    if (this.ghostValues) {\n      return this.ghostValues;\n    }\n    const detectionString = 'GDAL_STRUCTURAL_METADATA_SIZE=';\n    const heuristicAreaSize = detectionString.length + 100;\n    let slice = await this.getSlice(offset, heuristicAreaSize);\n    if (detectionString === getValues(slice, _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.ASCII, detectionString.length, offset)) {\n      const valuesString = getValues(slice, _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.ASCII, heuristicAreaSize, offset);\n      const firstLine = valuesString.split('\\n')[0];\n      const metadataSize = Number(firstLine.split('=')[1].split(' ')[0]) + firstLine.length;\n      if (metadataSize > heuristicAreaSize) {\n        slice = await this.getSlice(offset, metadataSize);\n      }\n      const fullString = getValues(slice, _globals__WEBPACK_IMPORTED_MODULE_8__.fieldTypes.ASCII, metadataSize, offset);\n      this.ghostValues = {};\n      fullString\n        .split('\\n')\n        .filter(line => line.length > 0)\n        .map(line => line.split('='))\n        .forEach(([key, value]) => {\n          this.ghostValues[key] = value;\n        });\n    }\n    return this.ghostValues;\n  }\n\n  /**\n   * Parse a (Geo)TIFF file from the given source.\n   *\n   * @param {source~Source} source The source of data to parse from.\n   * @param {object} options Additional options.\n   * @param {AbortSignal} [signal] An AbortSignal that may be signalled if the request is\n   *                               to be aborted\n   */\n  static async fromSource(source, options, signal) {\n    const headerData = (await source.fetch([{ offset: 0, length: 1024 }], signal))[0];\n    const dataView = new _dataview64__WEBPACK_IMPORTED_MODULE_1__.default(headerData);\n\n    const BOM = dataView.getUint16(0, 0);\n    let littleEndian;\n    if (BOM === 0x4949) {\n      littleEndian = true;\n    } else if (BOM === 0x4D4D) {\n      littleEndian = false;\n    } else {\n      throw new TypeError('Invalid byte order value.');\n    }\n\n    const magicNumber = dataView.getUint16(2, littleEndian);\n    let bigTiff;\n    if (magicNumber === 42) {\n      bigTiff = false;\n    } else if (magicNumber === 43) {\n      bigTiff = true;\n      const offsetByteSize = dataView.getUint16(4, littleEndian);\n      if (offsetByteSize !== 8) {\n        throw new Error('Unsupported offset byte-size.');\n      }\n    } else {\n      throw new TypeError('Invalid magic number.');\n    }\n\n    const firstIFDOffset = bigTiff\n      ? dataView.getUint64(8, littleEndian)\n      : dataView.getUint32(4, littleEndian);\n    return new GeoTIFF(source, littleEndian, bigTiff, firstIFDOffset, options);\n  }\n\n  /**\n   * Closes the underlying file buffer\n   * N.B. After the GeoTIFF has been completely processed it needs\n   * to be closed but only if it has been constructed from a file.\n   */\n  close() {\n    if (typeof this.source.close === 'function') {\n      return this.source.close();\n    }\n    return false;\n  }\n}\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (GeoTIFF);\n\n/**\n * Wrapper for GeoTIFF files that have external overviews.\n * @augments GeoTIFFBase\n */\nclass MultiGeoTIFF extends GeoTIFFBase {\n  /**\n   * Construct a new MultiGeoTIFF from a main and several overview files.\n   * @param {GeoTIFF} mainFile The main GeoTIFF file.\n   * @param {GeoTIFF[]} overviewFiles An array of overview files.\n   */\n  constructor(mainFile, overviewFiles) {\n    super();\n    this.mainFile = mainFile;\n    this.overviewFiles = overviewFiles;\n    this.imageFiles = [mainFile].concat(overviewFiles);\n\n    this.fileDirectoriesPerFile = null;\n    this.fileDirectoriesPerFileParsing = null;\n    this.imageCount = null;\n  }\n\n  async parseFileDirectoriesPerFile() {\n    const requests = [this.mainFile.parseFileDirectoryAt(this.mainFile.firstIFDOffset)]\n      .concat(this.overviewFiles.map((file) => file.parseFileDirectoryAt(file.firstIFDOffset)));\n\n    this.fileDirectoriesPerFile = await Promise.all(requests);\n    return this.fileDirectoriesPerFile;\n  }\n\n  /**\n   * Get the n-th internal subfile of an image. By default, the first is returned.\n   *\n   * @param {Number} [index=0] the index of the image to return.\n   * @returns {GeoTIFFImage} the image at the given index\n   */\n  async getImage(index = 0) {\n    await this.getImageCount();\n    await this.parseFileDirectoriesPerFile();\n    let visited = 0;\n    let relativeIndex = 0;\n    for (let i = 0; i < this.imageFiles.length; i++) {\n      const imageFile = this.imageFiles[i];\n      for (let ii = 0; ii < this.imageCounts[i]; ii++) {\n        if (index === visited) {\n          const ifd = await imageFile.requestIFD(relativeIndex);\n          return new _geotiffimage__WEBPACK_IMPORTED_MODULE_0__.default(\n            ifd.fileDirectory, ifd.geoKeyDirectory,\n            imageFile.dataView, imageFile.littleEndian, imageFile.cache, imageFile.source,\n          );\n        }\n        visited++;\n        relativeIndex++;\n      }\n      relativeIndex = 0;\n    }\n\n    throw new RangeError('Invalid image index');\n  }\n\n  /**\n   * Returns the count of the internal subfiles.\n   *\n   * @returns {Number} the number of internal subfile images\n   */\n  async getImageCount() {\n    if (this.imageCount !== null) {\n      return this.imageCount;\n    }\n    const requests = [this.mainFile.getImageCount()]\n      .concat(this.overviewFiles.map((file) => file.getImageCount()));\n    this.imageCounts = await Promise.all(requests);\n    this.imageCount = this.imageCounts.reduce((count, ifds) => count + ifds, 0);\n    return this.imageCount;\n  }\n}\n\n\n\n/**\n * Creates a new GeoTIFF from a remote URL.\n * @param {string} url The URL to access the image from\n * @param {object} [options] Additional options to pass to the source.\n *                           See {@link makeRemoteSource} for details.\n * @param {AbortSignal} [signal] An AbortSignal that may be signalled if the request is\n *                               to be aborted\n * @returns {Promise.<GeoTIFF>} The resulting GeoTIFF file.\n */\nasync function fromUrl(url, options = {}, signal) {\n  return GeoTIFF.fromSource((0,_source_remote__WEBPACK_IMPORTED_MODULE_4__.makeRemoteSource)(url, options), signal);\n}\n\n/**\n * Construct a new GeoTIFF from an\n * [ArrayBuffer]{@link https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/ArrayBuffer}.\n * @param {ArrayBuffer} arrayBuffer The data to read the file from.\n * @param {AbortSignal} [signal] An AbortSignal that may be signalled if the request is\n *                               to be aborted\n * @returns {Promise.<GeoTIFF>} The resulting GeoTIFF file.\n */\nasync function fromArrayBuffer(arrayBuffer, signal) {\n  return GeoTIFF.fromSource((0,_source_arraybuffer__WEBPACK_IMPORTED_MODULE_5__.makeBufferSource)(arrayBuffer), signal);\n}\n\n/**\n * Construct a GeoTIFF from a local file path. This uses the node\n * [filesystem API]{@link https://nodejs.org/api/fs.html} and is\n * not available on browsers.\n *\n * N.B. After the GeoTIFF has been completely processed it needs\n * to be closed but only if it has been constructed from a file.\n * @param {string} path The file path to read from.\n * @param {AbortSignal} [signal] An AbortSignal that may be signalled if the request is\n *                               to be aborted\n * @returns {Promise.<GeoTIFF>} The resulting GeoTIFF file.\n */\nasync function fromFile(path, signal) {\n  return GeoTIFF.fromSource((0,_source_file__WEBPACK_IMPORTED_MODULE_7__.makeFileSource)(path), signal);\n}\n\n/**\n * Construct a GeoTIFF from an HTML\n * [Blob]{@link https://developer.mozilla.org/en-US/docs/Web/API/Blob} or\n * [File]{@link https://developer.mozilla.org/en-US/docs/Web/API/File}\n * object.\n * @param {Blob|File} blob The Blob or File object to read from.\n * @param {AbortSignal} [signal] An AbortSignal that may be signalled if the request is\n *                               to be aborted\n * @returns {Promise.<GeoTIFF>} The resulting GeoTIFF file.\n */\nasync function fromBlob(blob, signal) {\n  return GeoTIFF.fromSource((0,_source_filereader__WEBPACK_IMPORTED_MODULE_6__.makeFileReaderSource)(blob), signal);\n}\n\n/**\n * Construct a MultiGeoTIFF from the given URLs.\n * @param {string} mainUrl The URL for the main file.\n * @param {string[]} overviewUrls An array of URLs for the overview images.\n * @param {object} [options] Additional options to pass to the source.\n *                           See [makeRemoteSource]{@link module:source.makeRemoteSource}\n *                           for details.\n * @param {AbortSignal} [signal] An AbortSignal that may be signalled if the request is\n *                               to be aborted\n * @returns {Promise.<MultiGeoTIFF>} The resulting MultiGeoTIFF file.\n */\nasync function fromUrls(mainUrl, overviewUrls = [], options = {}, signal) {\n  const mainFile = await GeoTIFF.fromSource((0,_source_remote__WEBPACK_IMPORTED_MODULE_4__.makeRemoteSource)(mainUrl, options), signal);\n  const overviewFiles = await Promise.all(\n    overviewUrls.map((url) => GeoTIFF.fromSource((0,_source_remote__WEBPACK_IMPORTED_MODULE_4__.makeRemoteSource)(url, options))),\n  );\n\n  return new MultiGeoTIFF(mainFile, overviewFiles);\n}\n\n/**\n * Main creating function for GeoTIFF files.\n * @param {(Array)} array of pixel values\n * @returns {metadata} metadata\n */\nasync function writeArrayBuffer(values, metadata) {\n  return (0,_geotiffwriter__WEBPACK_IMPORTED_MODULE_9__.writeGeotiff)(values, metadata);\n}\n\n\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/geotiff.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/geotiffimage.js":
/*!***************************************************!*\
  !*** ../node_modules/geotiff/src/geotiffimage.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _petamoriken_float16__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! @petamoriken/float16 */ \"../node_modules/@petamoriken/float16/src/dataView.js\");\n/* harmony import */ var txml__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! txml */ \"../node_modules/txml/tXml.js\");\n/* harmony import */ var txml__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(txml__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./globals */ \"../node_modules/geotiff/src/globals.js\");\n/* harmony import */ var _rgb__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./rgb */ \"../node_modules/geotiff/src/rgb.js\");\n/* harmony import */ var _compression__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./compression */ \"../node_modules/geotiff/src/compression/index.js\");\n/* harmony import */ var _resample__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./resample */ \"../node_modules/geotiff/src/resample.js\");\n/* eslint max-len: [\"error\", { \"code\": 120 }] */\n\n\n\n\n\n\n\n\n\nfunction sum(array, start, end) {\n  let s = 0;\n  for (let i = start; i < end; ++i) {\n    s += array[i];\n  }\n  return s;\n}\n\nfunction arrayForType(format, bitsPerSample, size) {\n  switch (format) {\n    case 1: // unsigned integer data\n      if (bitsPerSample <= 8) {\n        return new Uint8Array(size);\n      } else if (bitsPerSample <= 16) {\n        return new Uint16Array(size);\n      } else if (bitsPerSample <= 32) {\n        return new Uint32Array(size);\n      }\n      break;\n    case 2: // twos complement signed integer data\n      if (bitsPerSample === 8) {\n        return new Int8Array(size);\n      } else if (bitsPerSample === 16) {\n        return new Int16Array(size);\n      } else if (bitsPerSample === 32) {\n        return new Int32Array(size);\n      }\n      break;\n    case 3: // floating point data\n      switch (bitsPerSample) {\n        case 16:\n        case 32:\n          return new Float32Array(size);\n        case 64:\n          return new Float64Array(size);\n        default:\n          break;\n      }\n      break;\n    default:\n      break;\n  }\n  throw Error('Unsupported data format/bitsPerSample');\n}\n\nfunction needsNormalization(format, bitsPerSample) {\n  if ((format === 1 || format === 2) && bitsPerSample <= 32 && bitsPerSample % 8 === 0) {\n    return false;\n  } else if (format === 3 && (bitsPerSample === 16 || bitsPerSample === 32 || bitsPerSample === 64)) {\n    return false;\n  }\n  return true;\n}\n\nfunction normalizeArray(inBuffer, format, planarConfiguration, samplesPerPixel, bitsPerSample, tileWidth, tileHeight) {\n  // const inByteArray = new Uint8Array(inBuffer);\n  const view = new DataView(inBuffer);\n  const outSize = planarConfiguration === 2\n    ? tileHeight * tileWidth\n    : tileHeight * tileWidth * samplesPerPixel;\n  const samplesToTransfer = planarConfiguration === 2\n    ? 1 : samplesPerPixel;\n  const outArray = arrayForType(format, bitsPerSample, outSize);\n  // let pixel = 0;\n\n  const bitMask = parseInt('1'.repeat(bitsPerSample), 2);\n\n  if (format === 1) { // unsigned integer\n    // translation of https://github.com/OSGeo/gdal/blob/master/gdal/frmts/gtiff/geotiff.cpp#L7337\n    let pixelBitSkip;\n    // let sampleBitOffset = 0;\n    if (planarConfiguration === 1) {\n      pixelBitSkip = samplesPerPixel * bitsPerSample;\n      // sampleBitOffset = (samplesPerPixel - 1) * bitsPerSample;\n    } else {\n      pixelBitSkip = bitsPerSample;\n    }\n\n    // Bits per line rounds up to next byte boundary.\n    let bitsPerLine = tileWidth * pixelBitSkip;\n    if ((bitsPerLine & 7) !== 0) {\n      bitsPerLine = (bitsPerLine + 7) & (~7);\n    }\n\n    for (let y = 0; y < tileHeight; ++y) {\n      const lineBitOffset = y * bitsPerLine;\n      for (let x = 0; x < tileWidth; ++x) {\n        const pixelBitOffset = lineBitOffset + (x * samplesToTransfer * bitsPerSample);\n        for (let i = 0; i < samplesToTransfer; ++i) {\n          const bitOffset = pixelBitOffset + (i * bitsPerSample);\n          const outIndex = (((y * tileWidth) + x) * samplesToTransfer) + i;\n\n          const byteOffset = Math.floor(bitOffset / 8);\n          const innerBitOffset = bitOffset % 8;\n          if (innerBitOffset + bitsPerSample <= 8) {\n            outArray[outIndex] = (view.getUint8(byteOffset) >> (8 - bitsPerSample) - innerBitOffset) & bitMask;\n          } else if (innerBitOffset + bitsPerSample <= 16) {\n            outArray[outIndex] = (view.getUint16(byteOffset) >> (16 - bitsPerSample) - innerBitOffset) & bitMask;\n          } else if (innerBitOffset + bitsPerSample <= 24) {\n            const raw = (view.getUint16(byteOffset) << 8) | (view.getUint8(byteOffset + 2));\n            outArray[outIndex] = (raw >> (24 - bitsPerSample) - innerBitOffset) & bitMask;\n          } else {\n            outArray[outIndex] = (view.getUint32(byteOffset) >> (32 - bitsPerSample) - innerBitOffset) & bitMask;\n          }\n\n\n          // let outWord = 0;\n          // for (let bit = 0; bit < bitsPerSample; ++bit) {\n          //   if (inByteArray[bitOffset >> 3]\n          //     & (0x80 >> (bitOffset & 7))) {\n          //     outWord |= (1 << (bitsPerSample - 1 - bit));\n          //   }\n          //   ++bitOffset;\n          // }\n\n          // outArray[outIndex] = outWord;\n          // outArray[pixel] = outWord;\n          // pixel += 1;\n        }\n        // bitOffset = bitOffset + pixelBitSkip - bitsPerSample;\n      }\n    }\n  } else if (format === 3) { // floating point\n    // Float16 is handled elsewhere\n    // normalize 16/24 bit floats to 32 bit floats in the array\n    // console.time();\n    // if (bitsPerSample === 16) {\n    //   for (let byte = 0, outIndex = 0; byte < inBuffer.byteLength; byte += 2, ++outIndex) {\n    //     outArray[outIndex] = getFloat16(view, byte);\n    //   }\n    // }\n    // console.timeEnd()\n  }\n\n  return outArray.buffer;\n}\n\n/**\n * GeoTIFF sub-file image.\n */\nclass GeoTIFFImage {\n  /**\n   * @constructor\n   * @param {Object} fileDirectory The parsed file directory\n   * @param {Object} geoKeys The parsed geo-keys\n   * @param {DataView} dataView The DataView for the underlying file.\n   * @param {Boolean} littleEndian Whether the file is encoded in little or big endian\n   * @param {Boolean} cache Whether or not decoded tiles shall be cached\n   * @param {Source} source The datasource to read from\n   */\n  constructor(fileDirectory, geoKeys, dataView, littleEndian, cache, source) {\n    this.fileDirectory = fileDirectory;\n    this.geoKeys = geoKeys;\n    this.dataView = dataView;\n    this.littleEndian = littleEndian;\n    this.tiles = cache ? {} : null;\n    this.isTiled = !fileDirectory.StripOffsets;\n    const planarConfiguration = fileDirectory.PlanarConfiguration;\n    this.planarConfiguration = (typeof planarConfiguration === 'undefined') ? 1 : planarConfiguration;\n    if (this.planarConfiguration !== 1 && this.planarConfiguration !== 2) {\n      throw new Error('Invalid planar configuration.');\n    }\n\n    this.source = source;\n  }\n\n  /**\n   * Returns the associated parsed file directory.\n   * @returns {Object} the parsed file directory\n   */\n  getFileDirectory() {\n    return this.fileDirectory;\n  }\n\n  /**\n   * Returns the associated parsed geo keys.\n   * @returns {Object} the parsed geo keys\n   */\n  getGeoKeys() {\n    return this.geoKeys;\n  }\n\n  /**\n   * Returns the width of the image.\n   * @returns {Number} the width of the image\n   */\n  getWidth() {\n    return this.fileDirectory.ImageWidth;\n  }\n\n  /**\n   * Returns the height of the image.\n   * @returns {Number} the height of the image\n   */\n  getHeight() {\n    return this.fileDirectory.ImageLength;\n  }\n\n  /**\n   * Returns the number of samples per pixel.\n   * @returns {Number} the number of samples per pixel\n   */\n  getSamplesPerPixel() {\n    return typeof this.fileDirectory.SamplesPerPixel !== 'undefined'\n      ? this.fileDirectory.SamplesPerPixel : 1;\n  }\n\n  /**\n   * Returns the width of each tile.\n   * @returns {Number} the width of each tile\n   */\n  getTileWidth() {\n    return this.isTiled ? this.fileDirectory.TileWidth : this.getWidth();\n  }\n\n  /**\n   * Returns the height of each tile.\n   * @returns {Number} the height of each tile\n   */\n  getTileHeight() {\n    if (this.isTiled) {\n      return this.fileDirectory.TileLength;\n    }\n    if (typeof this.fileDirectory.RowsPerStrip !== 'undefined') {\n      return Math.min(this.fileDirectory.RowsPerStrip, this.getHeight());\n    }\n    return this.getHeight();\n  }\n\n  getBlockWidth() {\n    return this.getTileWidth();\n  }\n\n  getBlockHeight(y) {\n    if (this.isTiled || (y + 1) * this.getTileHeight() <= this.getHeight()) {\n      return this.getTileHeight();\n    } else {\n      return this.getHeight() - (y * this.getTileHeight());\n    }\n  }\n\n  /**\n   * Calculates the number of bytes for each pixel across all samples. Only full\n   * bytes are supported, an exception is thrown when this is not the case.\n   * @returns {Number} the bytes per pixel\n   */\n  getBytesPerPixel() {\n    let bytes = 0;\n    for (let i = 0; i < this.fileDirectory.BitsPerSample.length; ++i) {\n      bytes += this.getSampleByteSize(i);\n    }\n    return bytes;\n  }\n\n  getSampleByteSize(i) {\n    if (i >= this.fileDirectory.BitsPerSample.length) {\n      throw new RangeError(`Sample index ${i} is out of range.`);\n    }\n    return Math.ceil(this.fileDirectory.BitsPerSample[i] / 8);\n  }\n\n  getReaderForSample(sampleIndex) {\n    const format = this.fileDirectory.SampleFormat\n      ? this.fileDirectory.SampleFormat[sampleIndex] : 1;\n    const bitsPerSample = this.fileDirectory.BitsPerSample[sampleIndex];\n    switch (format) {\n      case 1: // unsigned integer data\n        if (bitsPerSample <= 8) {\n          return DataView.prototype.getUint8;\n        } else if (bitsPerSample <= 16) {\n          return DataView.prototype.getUint16;\n        } else if (bitsPerSample <= 32) {\n          return DataView.prototype.getUint32;\n        }\n        break;\n      case 2: // twos complement signed integer data\n        if (bitsPerSample <= 8) {\n          return DataView.prototype.getInt8;\n        } else if (bitsPerSample <= 16) {\n          return DataView.prototype.getInt16;\n        } else if (bitsPerSample <= 32) {\n          return DataView.prototype.getInt32;\n        }\n        break;\n      case 3:\n        switch (bitsPerSample) {\n          case 16:\n            return function (offset, littleEndian) {\n              return (0,_petamoriken_float16__WEBPACK_IMPORTED_MODULE_5__.getFloat16)(this, offset, littleEndian);\n            };\n          case 32:\n            return DataView.prototype.getFloat32;\n          case 64:\n            return DataView.prototype.getFloat64;\n          default:\n            break;\n        }\n        break;\n      default:\n        break;\n    }\n    throw Error('Unsupported data format/bitsPerSample');\n  }\n\n  getSampleFormat(sampleIndex = 0) {\n    return this.fileDirectory.SampleFormat\n      ? this.fileDirectory.SampleFormat[sampleIndex] : 1;\n  }\n\n  getBitsPerSample(sampleIndex = 0) {\n    return this.fileDirectory.BitsPerSample[sampleIndex];\n  }\n\n  getArrayForSample(sampleIndex, size) {\n    const format = this.getSampleFormat(sampleIndex);\n    const bitsPerSample = this.getBitsPerSample(sampleIndex);\n    return arrayForType(format, bitsPerSample, size);\n  }\n\n  /**\n   * Returns the decoded strip or tile.\n   * @param {Number} x the strip or tile x-offset\n   * @param {Number} y the tile y-offset (0 for stripped images)\n   * @param {Number} sample the sample to get for separated samples\n   * @param {Pool|AbstractDecoder} poolOrDecoder the decoder or decoder pool\n   * @param {AbortSignal} [signal] An AbortSignal that may be signalled if the request is\n   *                               to be aborted\n   * @returns {Promise.<ArrayBuffer>}\n   */\n  async getTileOrStrip(x, y, sample, poolOrDecoder, signal) {\n    const numTilesPerRow = Math.ceil(this.getWidth() / this.getTileWidth());\n    const numTilesPerCol = Math.ceil(this.getHeight() / this.getTileHeight());\n    let index;\n    const { tiles } = this;\n    if (this.planarConfiguration === 1) {\n      index = (y * numTilesPerRow) + x;\n    } else if (this.planarConfiguration === 2) {\n      index = (sample * numTilesPerRow * numTilesPerCol) + (y * numTilesPerRow) + x;\n    }\n\n    let offset;\n    let byteCount;\n    if (this.isTiled) {\n      offset = this.fileDirectory.TileOffsets[index];\n      byteCount = this.fileDirectory.TileByteCounts[index];\n    } else {\n      offset = this.fileDirectory.StripOffsets[index];\n      byteCount = this.fileDirectory.StripByteCounts[index];\n    }\n    const slice = (await this.source.fetch([{ offset, length: byteCount }], signal))[0];\n\n    let request;\n    if (tiles === null || !tiles[index]) {\n    // resolve each request by potentially applying array normalization\n      request = (async () => {\n        let data = await poolOrDecoder.decode(this.fileDirectory, slice);\n        const sampleFormat = this.getSampleFormat();\n        const bitsPerSample = this.getBitsPerSample();\n        if (needsNormalization(sampleFormat, bitsPerSample)) {\n          data = normalizeArray(\n            data,\n            sampleFormat,\n            this.planarConfiguration,\n            this.getSamplesPerPixel(),\n            bitsPerSample,\n            this.getTileWidth(),\n            this.getBlockHeight(y),\n          );\n        }\n        return data;\n      })();\n\n      // set the cache\n      if (tiles !== null) {\n        tiles[index] = request;\n      }\n    } else {\n      // get from the cache\n      request = tiles[index];\n    }\n\n    // cache the tile request\n    return { x, y, sample, data: await request };\n  }\n\n  /**\n   * Internal read function.\n   * @private\n   * @param {Array} imageWindow The image window in pixel coordinates\n   * @param {Array} samples The selected samples (0-based indices)\n   * @param {TypedArray[]|TypedArray} valueArrays The array(s) to write into\n   * @param {Boolean} interleave Whether or not to write in an interleaved manner\n   * @param {Pool|AbstractDecoder} poolOrDecoder the decoder or decoder pool\n   * @param {number} width the width of window to be read into\n   * @param {number} height the height of window to be read into\n   * @param {number} resampleMethod the resampling method to be used when interpolating\n   * @param {AbortSignal} [signal] An AbortSignal that may be signalled if the request is\n   *                               to be aborted\n   * @returns {Promise<TypedArray[]>|Promise<TypedArray>}\n   */\n  async _readRaster(imageWindow, samples, valueArrays, interleave, poolOrDecoder, width, height, resampleMethod, signal) {\n    const tileWidth = this.getTileWidth();\n    const tileHeight = this.getTileHeight();\n\n    const minXTile = Math.max(Math.floor(imageWindow[0] / tileWidth), 0);\n    const maxXTile = Math.min(\n      Math.ceil(imageWindow[2] / tileWidth),\n      Math.ceil(this.getWidth() / this.getTileWidth()),\n    );\n    const minYTile = Math.max(Math.floor(imageWindow[1] / tileHeight), 0);\n    const maxYTile = Math.min(\n      Math.ceil(imageWindow[3] / tileHeight),\n      Math.ceil(this.getHeight() / this.getTileHeight()),\n    );\n    const windowWidth = imageWindow[2] - imageWindow[0];\n\n    let bytesPerPixel = this.getBytesPerPixel();\n\n    const srcSampleOffsets = [];\n    const sampleReaders = [];\n    for (let i = 0; i < samples.length; ++i) {\n      if (this.planarConfiguration === 1) {\n        srcSampleOffsets.push(sum(this.fileDirectory.BitsPerSample, 0, samples[i]) / 8);\n      } else {\n        srcSampleOffsets.push(0);\n      }\n      sampleReaders.push(this.getReaderForSample(samples[i]));\n    }\n\n    const promises = [];\n    const { littleEndian } = this;\n\n    for (let yTile = minYTile; yTile < maxYTile; ++yTile) {\n      for (let xTile = minXTile; xTile < maxXTile; ++xTile) {\n        for (let sampleIndex = 0; sampleIndex < samples.length; ++sampleIndex) {\n          const si = sampleIndex;\n          const sample = samples[sampleIndex];\n          if (this.planarConfiguration === 2) {\n            bytesPerPixel = this.getSampleByteSize(sampleIndex);\n          }\n          const promise = this.getTileOrStrip(xTile, yTile, sample, poolOrDecoder, signal);\n          promises.push(promise);\n          promise.then((tile) => {\n            const buffer = tile.data;\n            const dataView = new DataView(buffer);\n            const blockHeight = this.getBlockHeight(tile.y);\n            const firstLine = tile.y * tileHeight;\n            const firstCol = tile.x * tileWidth;\n            const lastLine = firstLine + blockHeight;\n            const lastCol = (tile.x + 1) * tileWidth;\n            const reader = sampleReaders[si];\n\n            const ymax = Math.min(blockHeight, blockHeight - (lastLine - imageWindow[3]));\n            const xmax = Math.min(tileWidth, tileWidth - (lastCol - imageWindow[2]));\n\n            for (let y = Math.max(0, imageWindow[1] - firstLine); y < ymax; ++y) {\n              for (let x = Math.max(0, imageWindow[0] - firstCol); x < xmax; ++x) {\n                const pixelOffset = ((y * tileWidth) + x) * bytesPerPixel;\n                const value = reader.call(\n                  dataView, pixelOffset + srcSampleOffsets[si], littleEndian,\n                );\n                let windowCoordinate;\n                if (interleave) {\n                  windowCoordinate = ((y + firstLine - imageWindow[1]) * windowWidth * samples.length)\n                    + ((x + firstCol - imageWindow[0]) * samples.length)\n                    + si;\n                  valueArrays[windowCoordinate] = value;\n                } else {\n                  windowCoordinate = (\n                    (y + firstLine - imageWindow[1]) * windowWidth\n                  ) + x + firstCol - imageWindow[0];\n                  valueArrays[si][windowCoordinate] = value;\n                }\n              }\n            }\n          });\n        }\n      }\n    }\n    await Promise.all(promises);\n\n    if ((width && (imageWindow[2] - imageWindow[0]) !== width)\n        || (height && (imageWindow[3] - imageWindow[1]) !== height)) {\n      let resampled;\n      if (interleave) {\n        resampled = (0,_resample__WEBPACK_IMPORTED_MODULE_4__.resampleInterleaved)(\n          valueArrays,\n          imageWindow[2] - imageWindow[0],\n          imageWindow[3] - imageWindow[1],\n          width, height,\n          samples.length,\n          resampleMethod,\n        );\n      } else {\n        resampled = (0,_resample__WEBPACK_IMPORTED_MODULE_4__.resample)(\n          valueArrays,\n          imageWindow[2] - imageWindow[0],\n          imageWindow[3] - imageWindow[1],\n          width, height,\n          resampleMethod,\n        );\n      }\n      resampled.width = width;\n      resampled.height = height;\n      return resampled;\n    }\n\n    valueArrays.width = width || imageWindow[2] - imageWindow[0];\n    valueArrays.height = height || imageWindow[3] - imageWindow[1];\n\n    return valueArrays;\n  }\n\n  /**\n   * Reads raster data from the image. This function reads all selected samples\n   * into separate arrays of the correct type for that sample or into a single\n   * combined array when `interleave` is set. When provided, only a subset\n   * of the raster is read for each sample.\n   *\n   * @param {Object} [options={}] optional parameters\n   * @param {Array} [options.window=whole image] the subset to read data from.\n   * @param {Array} [options.samples=all samples] the selection of samples to read from.\n   * @param {Boolean} [options.interleave=false] whether the data shall be read\n   *                                             in one single array or separate\n   *                                             arrays.\n   * @param {Number} [options.pool=null] The optional decoder pool to use.\n   * @param {number} [options.width] The desired width of the output. When the width is\n   *                                 not the same as the images, resampling will be\n   *                                 performed.\n   * @param {number} [options.height] The desired height of the output. When the width\n   *                                  is not the same as the images, resampling will\n   *                                  be performed.\n   * @param {string} [options.resampleMethod='nearest'] The desired resampling method.\n   * @param {number|number[]} [options.fillValue] The value to use for parts of the image\n   *                                              outside of the images extent. When\n   *                                              multiple samples are requested, an\n   *                                              array of fill values can be passed.\n   * @param {AbortSignal} [options.signal] An AbortSignal that may be signalled if the request is\n   *                                       to be aborted\n   * @returns {Promise.<(TypedArray|TypedArray[])>} the decoded arrays as a promise\n   */\n  async readRasters({\n    window: wnd, samples = [], interleave, pool = null,\n    width, height, resampleMethod, fillValue, signal,\n  } = {}) {\n    const imageWindow = wnd || [0, 0, this.getWidth(), this.getHeight()];\n\n    // check parameters\n    if (imageWindow[0] > imageWindow[2] || imageWindow[1] > imageWindow[3]) {\n      throw new Error('Invalid subsets');\n    }\n\n    const imageWindowWidth = imageWindow[2] - imageWindow[0];\n    const imageWindowHeight = imageWindow[3] - imageWindow[1];\n    const numPixels = imageWindowWidth * imageWindowHeight;\n    const samplesPerPixel = this.getSamplesPerPixel();\n\n    if (!samples || !samples.length) {\n      for (let i = 0; i < samplesPerPixel; ++i) {\n        samples.push(i);\n      }\n    } else {\n      for (let i = 0; i < samples.length; ++i) {\n        if (samples[i] >= samplesPerPixel) {\n          return Promise.reject(new RangeError(`Invalid sample index '${samples[i]}'.`));\n        }\n      }\n    }\n    let valueArrays;\n    if (interleave) {\n      const format = this.fileDirectory.SampleFormat\n        ? Math.max.apply(null, this.fileDirectory.SampleFormat) : 1;\n      const bitsPerSample = Math.max.apply(null, this.fileDirectory.BitsPerSample);\n      valueArrays = arrayForType(format, bitsPerSample, numPixels * samples.length);\n      if (fillValue) {\n        valueArrays.fill(fillValue);\n      }\n    } else {\n      valueArrays = [];\n      for (let i = 0; i < samples.length; ++i) {\n        const valueArray = this.getArrayForSample(samples[i], numPixels);\n        if (Array.isArray(fillValue) && i < fillValue.length) {\n          valueArray.fill(fillValue[i]);\n        } else if (fillValue && !Array.isArray(fillValue)) {\n          valueArray.fill(fillValue);\n        }\n        valueArrays.push(valueArray);\n      }\n    }\n\n    const poolOrDecoder = pool || (0,_compression__WEBPACK_IMPORTED_MODULE_3__.getDecoder)(this.fileDirectory);\n\n    const result = await this._readRaster(\n      imageWindow, samples, valueArrays, interleave, poolOrDecoder, width, height, resampleMethod, signal,\n    );\n    return result;\n  }\n\n  /**\n   * Reads raster data from the image as RGB. The result is always an\n   * interleaved typed array.\n   * Colorspaces other than RGB will be transformed to RGB, color maps expanded.\n   * When no other method is applicable, the first sample is used to produce a\n   * greayscale image.\n   * When provided, only a subset of the raster is read for each sample.\n   *\n   * @param {Object} [options] optional parameters\n   * @param {Array} [options.window=whole image] the subset to read data from.\n   * @param {Number} [options.pool=null] The optional decoder pool to use.\n   * @param {number} [options.width] The desired width of the output. When the width is no the\n   *                                 same as the images, resampling will be performed.\n   * @param {number} [options.height] The desired height of the output. When the width is no the\n   *                                  same as the images, resampling will be performed.\n   * @param {string} [options.resampleMethod='nearest'] The desired resampling method.\n   * @param {bool} [options.enableAlpha=false] Enable reading alpha channel if present.\n   * @param {AbortSignal} [options.signal] An AbortSignal that may be signalled if the request is\n   *                                       to be aborted\n   * @returns {Promise.<TypedArray|TypedArray[]>} the RGB array as a Promise\n   */\n  async readRGB({ window, pool = null, width, height, resampleMethod, enableAlpha = false, signal } = {}) {\n    const imageWindow = window || [0, 0, this.getWidth(), this.getHeight()];\n\n    // check parameters\n    if (imageWindow[0] > imageWindow[2] || imageWindow[1] > imageWindow[3]) {\n      throw new Error('Invalid subsets');\n    }\n\n    const pi = this.fileDirectory.PhotometricInterpretation;\n\n    if (pi === _globals__WEBPACK_IMPORTED_MODULE_1__.photometricInterpretations.RGB) {\n      let s = [0, 1, 2];\n      if ((!(this.fileDirectory.ExtraSamples === _globals__WEBPACK_IMPORTED_MODULE_1__.ExtraSamplesValues.Unspecified)) && enableAlpha) {\n        s = [];\n        for (let i = 0; i < this.fileDirectory.BitsPerSample.length; i += 1) {\n          s.push(i);\n        }\n      }\n      return this.readRasters({\n        window,\n        interleave: true,\n        samples: s,\n        pool,\n        width,\n        height,\n        resampleMethod,\n        signal,\n      });\n    }\n\n    let samples;\n    switch (pi) {\n      case _globals__WEBPACK_IMPORTED_MODULE_1__.photometricInterpretations.WhiteIsZero:\n      case _globals__WEBPACK_IMPORTED_MODULE_1__.photometricInterpretations.BlackIsZero:\n      case _globals__WEBPACK_IMPORTED_MODULE_1__.photometricInterpretations.Palette:\n        samples = [0];\n        break;\n      case _globals__WEBPACK_IMPORTED_MODULE_1__.photometricInterpretations.CMYK:\n        samples = [0, 1, 2, 3];\n        break;\n      case _globals__WEBPACK_IMPORTED_MODULE_1__.photometricInterpretations.YCbCr:\n      case _globals__WEBPACK_IMPORTED_MODULE_1__.photometricInterpretations.CIELab:\n        samples = [0, 1, 2];\n        break;\n      default:\n        throw new Error('Invalid or unsupported photometric interpretation.');\n    }\n\n    const subOptions = {\n      window: imageWindow,\n      interleave: true,\n      samples,\n      pool,\n      width,\n      height,\n      resampleMethod,\n      signal,\n    };\n    const { fileDirectory } = this;\n    const raster = await this.readRasters(subOptions);\n\n    const max = 2 ** this.fileDirectory.BitsPerSample[0];\n    let data;\n    switch (pi) {\n      case _globals__WEBPACK_IMPORTED_MODULE_1__.photometricInterpretations.WhiteIsZero:\n        data = (0,_rgb__WEBPACK_IMPORTED_MODULE_2__.fromWhiteIsZero)(raster, max);\n        break;\n      case _globals__WEBPACK_IMPORTED_MODULE_1__.photometricInterpretations.BlackIsZero:\n        data = (0,_rgb__WEBPACK_IMPORTED_MODULE_2__.fromBlackIsZero)(raster, max);\n        break;\n      case _globals__WEBPACK_IMPORTED_MODULE_1__.photometricInterpretations.Palette:\n        data = (0,_rgb__WEBPACK_IMPORTED_MODULE_2__.fromPalette)(raster, fileDirectory.ColorMap);\n        break;\n      case _globals__WEBPACK_IMPORTED_MODULE_1__.photometricInterpretations.CMYK:\n        data = (0,_rgb__WEBPACK_IMPORTED_MODULE_2__.fromCMYK)(raster);\n        break;\n      case _globals__WEBPACK_IMPORTED_MODULE_1__.photometricInterpretations.YCbCr:\n        data = (0,_rgb__WEBPACK_IMPORTED_MODULE_2__.fromYCbCr)(raster);\n        break;\n      case _globals__WEBPACK_IMPORTED_MODULE_1__.photometricInterpretations.CIELab:\n        data = (0,_rgb__WEBPACK_IMPORTED_MODULE_2__.fromCIELab)(raster);\n        break;\n      default:\n        throw new Error('Unsupported photometric interpretation.');\n    }\n    data.width = raster.width;\n    data.height = raster.height;\n    return data;\n  }\n\n  /**\n   * Returns an array of tiepoints.\n   * @returns {Object[]}\n   */\n  getTiePoints() {\n    if (!this.fileDirectory.ModelTiepoint) {\n      return [];\n    }\n\n    const tiePoints = [];\n    for (let i = 0; i < this.fileDirectory.ModelTiepoint.length; i += 6) {\n      tiePoints.push({\n        i: this.fileDirectory.ModelTiepoint[i],\n        j: this.fileDirectory.ModelTiepoint[i + 1],\n        k: this.fileDirectory.ModelTiepoint[i + 2],\n        x: this.fileDirectory.ModelTiepoint[i + 3],\n        y: this.fileDirectory.ModelTiepoint[i + 4],\n        z: this.fileDirectory.ModelTiepoint[i + 5],\n      });\n    }\n    return tiePoints;\n  }\n\n  /**\n   * Returns the parsed GDAL metadata items.\n   *\n   * If sample is passed to null, dataset-level metadata will be returned.\n   * Otherwise only metadata specific to the provided sample will be returned.\n   *\n   * @param {Number} [sample=null] The sample index.\n   * @returns {Object}\n   */\n  getGDALMetadata(sample = null) {\n    const metadata = {};\n    if (!this.fileDirectory.GDAL_METADATA) {\n      return null;\n    }\n    const string = this.fileDirectory.GDAL_METADATA;\n    const xmlDom = txml__WEBPACK_IMPORTED_MODULE_0___default()(string.substring(0, string.length - 1));\n\n    if (!xmlDom[0].tagName) {\n      throw new Error('Failed to parse GDAL metadata XML.');\n    }\n\n    const root = xmlDom[0];\n    if (root.tagName !== 'GDALMetadata') {\n      throw new Error('Unexpected GDAL metadata XML tag.');\n    }\n\n    let items = root.children\n      .filter((child) => child.tagName === 'Item');\n\n    if (sample !== null) {\n      items = items.filter((item) => Number(item.attributes.sample) === sample);\n    }\n\n    for (let i = 0; i < items.length; ++i) {\n      const item = items[i];\n      metadata[item.attributes.name] = item.children[0];\n    }\n    return metadata;\n  }\n\n  /**\n   * Returns the GDAL nodata value\n   * @returns {Number} or null\n   */\n  getGDALNoData() {\n    if (!this.fileDirectory.GDAL_NODATA) {\n      return null;\n    }\n    const string = this.fileDirectory.GDAL_NODATA;\n    return Number(string.substring(0, string.length - 1));\n  }\n\n  /**\n   * Returns the image origin as a XYZ-vector. When the image has no affine\n   * transformation, then an exception is thrown.\n   * @returns {Array} The origin as a vector\n   */\n  getOrigin() {\n    const tiePoints = this.fileDirectory.ModelTiepoint;\n    const modelTransformation = this.fileDirectory.ModelTransformation;\n    if (tiePoints && tiePoints.length === 6) {\n      return [\n        tiePoints[3],\n        tiePoints[4],\n        tiePoints[5],\n      ];\n    }\n    if (modelTransformation) {\n      return [\n        modelTransformation[3],\n        modelTransformation[7],\n        modelTransformation[11],\n      ];\n    }\n    throw new Error('The image does not have an affine transformation.');\n  }\n\n  /**\n   * Returns the image resolution as a XYZ-vector. When the image has no affine\n   * transformation, then an exception is thrown.\n   * @param {GeoTIFFImage} [referenceImage=null] A reference image to calculate the resolution from\n   *                                             in cases when the current image does not have the\n   *                                             required tags on its own.\n   * @returns {Array} The resolution as a vector\n   */\n  getResolution(referenceImage = null) {\n    const modelPixelScale = this.fileDirectory.ModelPixelScale;\n    const modelTransformation = this.fileDirectory.ModelTransformation;\n\n    if (modelPixelScale) {\n      return [\n        modelPixelScale[0],\n        -modelPixelScale[1],\n        modelPixelScale[2],\n      ];\n    }\n    if (modelTransformation) {\n      return [\n        modelTransformation[0],\n        modelTransformation[5],\n        modelTransformation[10],\n      ];\n    }\n\n    if (referenceImage) {\n      const [refResX, refResY, refResZ] = referenceImage.getResolution();\n      return [\n        refResX * referenceImage.getWidth() / this.getWidth(),\n        refResY * referenceImage.getHeight() / this.getHeight(),\n        refResZ * referenceImage.getWidth() / this.getWidth(),\n      ];\n    }\n\n    throw new Error('The image does not have an affine transformation.');\n  }\n\n  /**\n   * Returns whether or not the pixels of the image depict an area (or point).\n   * @returns {Boolean} Whether the pixels are a point\n   */\n  pixelIsArea() {\n    return this.geoKeys.GTRasterTypeGeoKey === 1;\n  }\n\n  /**\n   * Returns the image bounding box as an array of 4 values: min-x, min-y,\n   * max-x and max-y. When the image has no affine transformation, then an\n   * exception is thrown.\n   * @returns {Array} The bounding box\n   */\n  getBoundingBox() {\n    const origin = this.getOrigin();\n    const resolution = this.getResolution();\n\n    const x1 = origin[0];\n    const y1 = origin[1];\n\n    const x2 = x1 + (resolution[0] * this.getWidth());\n    const y2 = y1 + (resolution[1] * this.getHeight());\n\n    return [\n      Math.min(x1, x2),\n      Math.min(y1, y2),\n      Math.max(x1, x2),\n      Math.max(y1, y2),\n    ];\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (GeoTIFFImage);\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/geotiffimage.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/geotiffwriter.js":
/*!****************************************************!*\
  !*** ../node_modules/geotiff/src/geotiffwriter.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"writeGeotiff\": () => (/* binding */ writeGeotiff)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./globals */ \"../node_modules/geotiff/src/globals.js\");\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils */ \"../node_modules/geotiff/src/utils.js\");\n/*\n  Some parts of this file are based on UTIF.js,\n  which was released under the MIT License.\n  You can view that here:\n  https://github.com/photopea/UTIF.js/blob/master/LICENSE\n*/\n\n\n\nconst tagName2Code = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.invert)(_globals__WEBPACK_IMPORTED_MODULE_0__.fieldTagNames);\nconst geoKeyName2Code = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.invert)(_globals__WEBPACK_IMPORTED_MODULE_0__.geoKeyNames);\nconst name2code = {};\n(0,_utils__WEBPACK_IMPORTED_MODULE_1__.assign)(name2code, tagName2Code);\n(0,_utils__WEBPACK_IMPORTED_MODULE_1__.assign)(name2code, geoKeyName2Code);\nconst typeName2byte = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.invert)(_globals__WEBPACK_IMPORTED_MODULE_0__.fieldTypeNames);\n\n// config variables\nconst numBytesInIfd = 1000;\n\nconst _binBE = {\n  nextZero: (data, o) => {\n    let oincr = o;\n    while (data[oincr] !== 0) {\n      oincr++;\n    }\n    return oincr;\n  },\n  readUshort: (buff, p) => {\n    return (buff[p] << 8) | buff[p + 1];\n  },\n  readShort: (buff, p) => {\n    const a = _binBE.ui8;\n    a[0] = buff[p + 1];\n    a[1] = buff[p + 0];\n    return _binBE.i16[0];\n  },\n  readInt: (buff, p) => {\n    const a = _binBE.ui8;\n    a[0] = buff[p + 3];\n    a[1] = buff[p + 2];\n    a[2] = buff[p + 1];\n    a[3] = buff[p + 0];\n    return _binBE.i32[0];\n  },\n  readUint: (buff, p) => {\n    const a = _binBE.ui8;\n    a[0] = buff[p + 3];\n    a[1] = buff[p + 2];\n    a[2] = buff[p + 1];\n    a[3] = buff[p + 0];\n    return _binBE.ui32[0];\n  },\n  readASCII: (buff, p, l) => {\n    return l.map((i) => String.fromCharCode(buff[p + i])).join('');\n  },\n  readFloat: (buff, p) => {\n    const a = _binBE.ui8;\n    (0,_utils__WEBPACK_IMPORTED_MODULE_1__.times)(4, (i) => {\n      a[i] = buff[p + 3 - i];\n    });\n    return _binBE.fl32[0];\n  },\n  readDouble: (buff, p) => {\n    const a = _binBE.ui8;\n    (0,_utils__WEBPACK_IMPORTED_MODULE_1__.times)(8, (i) => {\n      a[i] = buff[p + 7 - i];\n    });\n    return _binBE.fl64[0];\n  },\n  writeUshort: (buff, p, n) => {\n    buff[p] = (n >> 8) & 255;\n    buff[p + 1] = n & 255;\n  },\n  writeUint: (buff, p, n) => {\n    buff[p] = (n >> 24) & 255;\n    buff[p + 1] = (n >> 16) & 255;\n    buff[p + 2] = (n >> 8) & 255;\n    buff[p + 3] = (n >> 0) & 255;\n  },\n  writeASCII: (buff, p, s) => {\n    (0,_utils__WEBPACK_IMPORTED_MODULE_1__.times)(s.length, (i) => {\n      buff[p + i] = s.charCodeAt(i);\n    });\n  },\n  ui8: new Uint8Array(8),\n};\n\n_binBE.fl64 = new Float64Array(_binBE.ui8.buffer);\n\n_binBE.writeDouble = (buff, p, n) => {\n  _binBE.fl64[0] = n;\n  (0,_utils__WEBPACK_IMPORTED_MODULE_1__.times)(8, (i) => {\n    buff[p + i] = _binBE.ui8[7 - i];\n  });\n};\n\n\nconst _writeIFD = (bin, data, _offset, ifd) => {\n  let offset = _offset;\n\n  const keys = Object.keys(ifd).filter((key) => {\n    return key !== undefined && key !== null && key !== 'undefined';\n  });\n\n  bin.writeUshort(data, offset, keys.length);\n  offset += 2;\n\n  let eoff = offset + (12 * keys.length) + 4;\n\n  for (const key of keys) {\n    let tag = null;\n    if (typeof key === 'number') {\n      tag = key;\n    } else if (typeof key === 'string') {\n      tag = parseInt(key, 10);\n    }\n\n    const typeName = _globals__WEBPACK_IMPORTED_MODULE_0__.fieldTagTypes[tag];\n    const typeNum = typeName2byte[typeName];\n\n    if (typeName == null || typeName === undefined || typeof typeName === 'undefined') {\n      throw new Error(`unknown type of tag: ${tag}`);\n    }\n\n    let val = ifd[key];\n\n    if (typeof val === 'undefined') {\n      throw new Error(`failed to get value for key ${key}`);\n    }\n\n    // ASCIIZ format with trailing 0 character\n    // http://www.fileformat.info/format/tiff/corion.htm\n    // https://stackoverflow.com/questions/7783044/whats-the-difference-between-asciiz-vs-ascii\n    if (typeName === 'ASCII' && typeof val === 'string' && (0,_utils__WEBPACK_IMPORTED_MODULE_1__.endsWith)(val, '\\u0000') === false) {\n      val += '\\u0000';\n    }\n\n    const num = val.length;\n\n    bin.writeUshort(data, offset, tag);\n    offset += 2;\n\n    bin.writeUshort(data, offset, typeNum);\n    offset += 2;\n\n    bin.writeUint(data, offset, num);\n    offset += 4;\n\n    let dlen = [-1, 1, 1, 2, 4, 8, 0, 0, 0, 0, 0, 0, 8][typeNum] * num;\n    let toff = offset;\n\n    if (dlen > 4) {\n      bin.writeUint(data, offset, eoff);\n      toff = eoff;\n    }\n\n    if (typeName === 'ASCII') {\n      bin.writeASCII(data, toff, val);\n    } else if (typeName === 'SHORT') {\n      (0,_utils__WEBPACK_IMPORTED_MODULE_1__.times)(num, (i) => {\n        bin.writeUshort(data, toff + (2 * i), val[i]);\n      });\n    } else if (typeName === 'LONG') {\n      (0,_utils__WEBPACK_IMPORTED_MODULE_1__.times)(num, (i) => {\n        bin.writeUint(data, toff + (4 * i), val[i]);\n      });\n    } else if (typeName === 'RATIONAL') {\n      (0,_utils__WEBPACK_IMPORTED_MODULE_1__.times)(num, (i) => {\n        bin.writeUint(data, toff + (8 * i), Math.round(val[i] * 10000));\n        bin.writeUint(data, toff + (8 * i) + 4, 10000);\n      });\n    } else if (typeName === 'DOUBLE') {\n      (0,_utils__WEBPACK_IMPORTED_MODULE_1__.times)(num, (i) => {\n        bin.writeDouble(data, toff + (8 * i), val[i]);\n      });\n    }\n\n    if (dlen > 4) {\n      dlen += (dlen & 1);\n      eoff += dlen;\n    }\n\n    offset += 4;\n  }\n\n  return [offset, eoff];\n};\n\nconst encodeIfds = (ifds) => {\n  const data = new Uint8Array(numBytesInIfd);\n  let offset = 4;\n  const bin = _binBE;\n\n  // set big-endian byte-order\n  // https://en.wikipedia.org/wiki/TIFF#Byte_order\n  data[0] = 77;\n  data[1] = 77;\n\n  // set format-version number\n  // https://en.wikipedia.org/wiki/TIFF#Byte_order\n  data[3] = 42;\n\n  let ifdo = 8;\n\n  bin.writeUint(data, offset, ifdo);\n\n  offset += 4;\n\n  ifds.forEach((ifd, i) => {\n    const noffs = _writeIFD(bin, data, ifdo, ifd);\n    ifdo = noffs[1];\n    if (i < ifds.length - 1) {\n      bin.writeUint(data, noffs[0], ifdo);\n    }\n  });\n\n  if (data.slice) {\n    return data.slice(0, ifdo).buffer;\n  }\n\n  // node hasn't implemented slice on Uint8Array yet\n  const result = new Uint8Array(ifdo);\n  for (let i = 0; i < ifdo; i++) {\n    result[i] = data[i];\n  }\n  return result.buffer;\n};\n\nconst encodeImage = (values, width, height, metadata) => {\n  if (height === undefined || height === null) {\n    throw new Error(`you passed into encodeImage a width of type ${height}`);\n  }\n\n  if (width === undefined || width === null) {\n    throw new Error(`you passed into encodeImage a width of type ${width}`);\n  }\n\n  const ifd = {\n    256: [width], // ImageWidth\n    257: [height], // ImageLength\n    273: [numBytesInIfd], // strips offset\n    278: [height], // RowsPerStrip\n    305: 'geotiff.js', // no array for ASCII(Z)\n  };\n\n  if (metadata) {\n    for (const i in metadata) {\n      if (metadata.hasOwnProperty(i)) {\n        ifd[i] = metadata[i];\n      }\n    }\n  }\n\n  const prfx = new Uint8Array(encodeIfds([ifd]));\n\n  const img = new Uint8Array(values);\n\n  const samplesPerPixel = ifd[277];\n\n  const data = new Uint8Array(numBytesInIfd + (width * height * samplesPerPixel));\n  (0,_utils__WEBPACK_IMPORTED_MODULE_1__.times)(prfx.length, (i) => {\n    data[i] = prfx[i];\n  });\n  (0,_utils__WEBPACK_IMPORTED_MODULE_1__.forEach)(img, (value, i) => {\n    data[numBytesInIfd + i] = value;\n  });\n\n  return data.buffer;\n};\n\nconst convertToTids = (input) => {\n  const result = {};\n  for (const key in input) {\n    if (key !== 'StripOffsets') {\n      if (!name2code[key]) {\n        console.error(key, 'not in name2code:', Object.keys(name2code));\n      }\n      result[name2code[key]] = input[key];\n    }\n  }\n  return result;\n};\n\nconst toArray = (input) => {\n  if (Array.isArray(input)) {\n    return input;\n  }\n  return [input];\n};\n\nconst metadataDefaults = [\n  ['Compression', 1], // no compression\n  ['PlanarConfiguration', 1],\n  ['XPosition', 0],\n  ['YPosition', 0],\n  ['ResolutionUnit', 1], // Code 1 for actual pixel count or 2 for pixels per inch.\n  ['ExtraSamples', 0], // should this be an array??\n  ['GeoAsciiParams', 'WGS 84\\u0000'],\n  ['ModelTiepoint', [0, 0, 0, -180, 90, 0]], // raster fits whole globe\n  ['GTModelTypeGeoKey', 2],\n  ['GTRasterTypeGeoKey', 1],\n  ['GeographicTypeGeoKey', 4326],\n  ['GeogCitationGeoKey', 'WGS 84'],\n];\n\nfunction writeGeotiff(data, metadata) {\n  const isFlattened = typeof data[0] === 'number';\n\n  let height;\n  let numBands;\n  let width;\n  let flattenedValues;\n\n  if (isFlattened) {\n    height = metadata.height || metadata.ImageLength;\n    width = metadata.width || metadata.ImageWidth;\n    numBands = data.length / (height * width);\n    flattenedValues = data;\n  } else {\n    numBands = data.length;\n    height = data[0].length;\n    width = data[0][0].length;\n    flattenedValues = [];\n    (0,_utils__WEBPACK_IMPORTED_MODULE_1__.times)(height, (rowIndex) => {\n      (0,_utils__WEBPACK_IMPORTED_MODULE_1__.times)(width, (columnIndex) => {\n        (0,_utils__WEBPACK_IMPORTED_MODULE_1__.times)(numBands, (bandIndex) => {\n          flattenedValues.push(data[bandIndex][rowIndex][columnIndex]);\n        });\n      });\n    });\n  }\n\n  metadata.ImageLength = height;\n  delete metadata.height;\n  metadata.ImageWidth = width;\n  delete metadata.width;\n\n  // consult https://www.loc.gov/preservation/digital/formats/content/tiff_tags.shtml\n\n  if (!metadata.BitsPerSample) {\n    metadata.BitsPerSample = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.times)(numBands, () => 8);\n  }\n\n  metadataDefaults.forEach((tag) => {\n    const key = tag[0];\n    if (!metadata[key]) {\n      const value = tag[1];\n      metadata[key] = value;\n    }\n  });\n\n  // The color space of the image data.\n  // 1=black is zero and 2=RGB.\n  if (!metadata.PhotometricInterpretation) {\n    metadata.PhotometricInterpretation = metadata.BitsPerSample.length === 3 ? 2 : 1;\n  }\n\n  // The number of components per pixel.\n  if (!metadata.SamplesPerPixel) {\n    metadata.SamplesPerPixel = [numBands];\n  }\n\n  if (!metadata.StripByteCounts) {\n    // we are only writing one strip\n    metadata.StripByteCounts = [numBands * height * width];\n  }\n\n  if (!metadata.ModelPixelScale) {\n    // assumes raster takes up exactly the whole globe\n    metadata.ModelPixelScale = [360 / width, 180 / height, 0];\n  }\n\n  if (!metadata.SampleFormat) {\n    metadata.SampleFormat = (0,_utils__WEBPACK_IMPORTED_MODULE_1__.times)(numBands, () => 1);\n  }\n\n\n  const geoKeys = Object.keys(metadata)\n    .filter((key) => (0,_utils__WEBPACK_IMPORTED_MODULE_1__.endsWith)(key, 'GeoKey'))\n    .sort((a, b) => name2code[a] - name2code[b]);\n\n  if (!metadata.GeoKeyDirectory) {\n    const NumberOfKeys = geoKeys.length;\n\n    const GeoKeyDirectory = [1, 1, 0, NumberOfKeys];\n    geoKeys.forEach((geoKey) => {\n      const KeyID = Number(name2code[geoKey]);\n      GeoKeyDirectory.push(KeyID);\n\n      let Count;\n      let TIFFTagLocation;\n      let valueOffset;\n      if (_globals__WEBPACK_IMPORTED_MODULE_0__.fieldTagTypes[KeyID] === 'SHORT') {\n        Count = 1;\n        TIFFTagLocation = 0;\n        valueOffset = metadata[geoKey];\n      } else if (geoKey === 'GeogCitationGeoKey') {\n        Count = metadata.GeoAsciiParams.length;\n        TIFFTagLocation = Number(name2code.GeoAsciiParams);\n        valueOffset = 0;\n      } else {\n        console.log(`[geotiff.js] couldn't get TIFFTagLocation for ${geoKey}`);\n      }\n      GeoKeyDirectory.push(TIFFTagLocation);\n      GeoKeyDirectory.push(Count);\n      GeoKeyDirectory.push(valueOffset);\n    });\n    metadata.GeoKeyDirectory = GeoKeyDirectory;\n  }\n\n  // delete GeoKeys from metadata, because stored in GeoKeyDirectory tag\n  for (const geoKey in geoKeys) {\n    if (geoKeys.hasOwnProperty(geoKey)) {\n      delete metadata[geoKey];\n    }\n  }\n\n  [\n    'Compression',\n    'ExtraSamples',\n    'GeographicTypeGeoKey',\n    'GTModelTypeGeoKey',\n    'GTRasterTypeGeoKey',\n    'ImageLength', // synonym of ImageHeight\n    'ImageWidth',\n    'PhotometricInterpretation',\n    'PlanarConfiguration',\n    'ResolutionUnit',\n    'SamplesPerPixel',\n    'XPosition',\n    'YPosition',\n  ].forEach((name) => {\n    if (metadata[name]) {\n      metadata[name] = toArray(metadata[name]);\n    }\n  });\n\n\n  const encodedMetadata = convertToTids(metadata);\n\n  const outputImage = encodeImage(flattenedValues, width, height, encodedMetadata);\n\n  return outputImage;\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/geotiffwriter.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/globals.js":
/*!**********************************************!*\
  !*** ../node_modules/geotiff/src/globals.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"fieldTagNames\": () => (/* binding */ fieldTagNames),\n/* harmony export */   \"fieldTags\": () => (/* binding */ fieldTags),\n/* harmony export */   \"fieldTagTypes\": () => (/* binding */ fieldTagTypes),\n/* harmony export */   \"arrayFields\": () => (/* binding */ arrayFields),\n/* harmony export */   \"fieldTypeNames\": () => (/* binding */ fieldTypeNames),\n/* harmony export */   \"fieldTypes\": () => (/* binding */ fieldTypes),\n/* harmony export */   \"photometricInterpretations\": () => (/* binding */ photometricInterpretations),\n/* harmony export */   \"ExtraSamplesValues\": () => (/* binding */ ExtraSamplesValues),\n/* harmony export */   \"geoKeyNames\": () => (/* binding */ geoKeyNames),\n/* harmony export */   \"geoKeys\": () => (/* binding */ geoKeys)\n/* harmony export */ });\nconst fieldTagNames = {\n  // TIFF Baseline\n  0x013B: 'Artist',\n  0x0102: 'BitsPerSample',\n  0x0109: 'CellLength',\n  0x0108: 'CellWidth',\n  0x0140: 'ColorMap',\n  0x0103: 'Compression',\n  0x8298: 'Copyright',\n  0x0132: 'DateTime',\n  0x0152: 'ExtraSamples',\n  0x010A: 'FillOrder',\n  0x0121: 'FreeByteCounts',\n  0x0120: 'FreeOffsets',\n  0x0123: 'GrayResponseCurve',\n  0x0122: 'GrayResponseUnit',\n  0x013C: 'HostComputer',\n  0x010E: 'ImageDescription',\n  0x0101: 'ImageLength',\n  0x0100: 'ImageWidth',\n  0x010F: 'Make',\n  0x0119: 'MaxSampleValue',\n  0x0118: 'MinSampleValue',\n  0x0110: 'Model',\n  0x00FE: 'NewSubfileType',\n  0x0112: 'Orientation',\n  0x0106: 'PhotometricInterpretation',\n  0x011C: 'PlanarConfiguration',\n  0x0128: 'ResolutionUnit',\n  0x0116: 'RowsPerStrip',\n  0x0115: 'SamplesPerPixel',\n  0x0131: 'Software',\n  0x0117: 'StripByteCounts',\n  0x0111: 'StripOffsets',\n  0x00FF: 'SubfileType',\n  0x0107: 'Threshholding',\n  0x011A: 'XResolution',\n  0x011B: 'YResolution',\n\n  // TIFF Extended\n  0x0146: 'BadFaxLines',\n  0x0147: 'CleanFaxData',\n  0x0157: 'ClipPath',\n  0x0148: 'ConsecutiveBadFaxLines',\n  0x01B1: 'Decode',\n  0x01B2: 'DefaultImageColor',\n  0x010D: 'DocumentName',\n  0x0150: 'DotRange',\n  0x0141: 'HalftoneHints',\n  0x015A: 'Indexed',\n  0x015B: 'JPEGTables',\n  0x011D: 'PageName',\n  0x0129: 'PageNumber',\n  0x013D: 'Predictor',\n  0x013F: 'PrimaryChromaticities',\n  0x0214: 'ReferenceBlackWhite',\n  0x0153: 'SampleFormat',\n  0x0154: 'SMinSampleValue',\n  0x0155: 'SMaxSampleValue',\n  0x022F: 'StripRowCounts',\n  0x014A: 'SubIFDs',\n  0x0124: 'T4Options',\n  0x0125: 'T6Options',\n  0x0145: 'TileByteCounts',\n  0x0143: 'TileLength',\n  0x0144: 'TileOffsets',\n  0x0142: 'TileWidth',\n  0x012D: 'TransferFunction',\n  0x013E: 'WhitePoint',\n  0x0158: 'XClipPathUnits',\n  0x011E: 'XPosition',\n  0x0211: 'YCbCrCoefficients',\n  0x0213: 'YCbCrPositioning',\n  0x0212: 'YCbCrSubSampling',\n  0x0159: 'YClipPathUnits',\n  0x011F: 'YPosition',\n\n  // EXIF\n  0x9202: 'ApertureValue',\n  0xA001: 'ColorSpace',\n  0x9004: 'DateTimeDigitized',\n  0x9003: 'DateTimeOriginal',\n  0x8769: 'Exif IFD',\n  0x9000: 'ExifVersion',\n  0x829A: 'ExposureTime',\n  0xA300: 'FileSource',\n  0x9209: 'Flash',\n  0xA000: 'FlashpixVersion',\n  0x829D: 'FNumber',\n  0xA420: 'ImageUniqueID',\n  0x9208: 'LightSource',\n  0x927C: 'MakerNote',\n  0x9201: 'ShutterSpeedValue',\n  0x9286: 'UserComment',\n\n  // IPTC\n  0x83BB: 'IPTC',\n\n  // ICC\n  0x8773: 'ICC Profile',\n\n  // XMP\n  0x02BC: 'XMP',\n\n  // GDAL\n  0xA480: 'GDAL_METADATA',\n  0xA481: 'GDAL_NODATA',\n\n  // Photoshop\n  0x8649: 'Photoshop',\n\n  // GeoTiff\n  0x830E: 'ModelPixelScale',\n  0x8482: 'ModelTiepoint',\n  0x85D8: 'ModelTransformation',\n  0x87AF: 'GeoKeyDirectory',\n  0x87B0: 'GeoDoubleParams',\n  0x87B1: 'GeoAsciiParams',\n};\n\nconst fieldTags = {};\nfor (const key in fieldTagNames) {\n  if (fieldTagNames.hasOwnProperty(key)) {\n    fieldTags[fieldTagNames[key]] = parseInt(key, 10);\n  }\n}\n\nconst fieldTagTypes = {\n  256: 'SHORT',\n  257: 'SHORT',\n  258: 'SHORT',\n  259: 'SHORT',\n  262: 'SHORT',\n  273: 'LONG',\n  274: 'SHORT',\n  277: 'SHORT',\n  278: 'LONG',\n  279: 'LONG',\n  282: 'RATIONAL',\n  283: 'RATIONAL',\n  284: 'SHORT',\n  286: 'SHORT',\n  287: 'RATIONAL',\n  296: 'SHORT',\n  305: 'ASCII',\n  306: 'ASCII',\n  338: 'SHORT',\n  339: 'SHORT',\n  513: 'LONG',\n  514: 'LONG',\n  1024: 'SHORT',\n  1025: 'SHORT',\n  2048: 'SHORT',\n  2049: 'ASCII',\n  33550: 'DOUBLE',\n  33922: 'DOUBLE',\n  34665: 'LONG',\n  34735: 'SHORT',\n  34737: 'ASCII',\n  42113: 'ASCII',\n};\n\nconst arrayFields = [\n  fieldTags.BitsPerSample,\n  fieldTags.ExtraSamples,\n  fieldTags.SampleFormat,\n  fieldTags.StripByteCounts,\n  fieldTags.StripOffsets,\n  fieldTags.StripRowCounts,\n  fieldTags.TileByteCounts,\n  fieldTags.TileOffsets,\n  fieldTags.SubIFDs,\n];\n\nconst fieldTypeNames = {\n  0x0001: 'BYTE',\n  0x0002: 'ASCII',\n  0x0003: 'SHORT',\n  0x0004: 'LONG',\n  0x0005: 'RATIONAL',\n  0x0006: 'SBYTE',\n  0x0007: 'UNDEFINED',\n  0x0008: 'SSHORT',\n  0x0009: 'SLONG',\n  0x000A: 'SRATIONAL',\n  0x000B: 'FLOAT',\n  0x000C: 'DOUBLE',\n  // IFD offset, suggested by https://owl.phy.queensu.ca/~phil/exiftool/standards.html\n  0x000D: 'IFD',\n  // introduced by BigTIFF\n  0x0010: 'LONG8',\n  0x0011: 'SLONG8',\n  0x0012: 'IFD8',\n};\n\nconst fieldTypes = {};\nfor (const key in fieldTypeNames) {\n  if (fieldTypeNames.hasOwnProperty(key)) {\n    fieldTypes[fieldTypeNames[key]] = parseInt(key, 10);\n  }\n}\n\nconst photometricInterpretations = {\n  WhiteIsZero: 0,\n  BlackIsZero: 1,\n  RGB: 2,\n  Palette: 3,\n  TransparencyMask: 4,\n  CMYK: 5,\n  YCbCr: 6,\n\n  CIELab: 8,\n  ICCLab: 9,\n};\n\nconst ExtraSamplesValues = {\n  Unspecified: 0,\n  Assocalpha: 1,\n  Unassalpha: 2,\n};\n\n\nconst geoKeyNames = {\n  1024: 'GTModelTypeGeoKey',\n  1025: 'GTRasterTypeGeoKey',\n  1026: 'GTCitationGeoKey',\n  2048: 'GeographicTypeGeoKey',\n  2049: 'GeogCitationGeoKey',\n  2050: 'GeogGeodeticDatumGeoKey',\n  2051: 'GeogPrimeMeridianGeoKey',\n  2052: 'GeogLinearUnitsGeoKey',\n  2053: 'GeogLinearUnitSizeGeoKey',\n  2054: 'GeogAngularUnitsGeoKey',\n  2055: 'GeogAngularUnitSizeGeoKey',\n  2056: 'GeogEllipsoidGeoKey',\n  2057: 'GeogSemiMajorAxisGeoKey',\n  2058: 'GeogSemiMinorAxisGeoKey',\n  2059: 'GeogInvFlatteningGeoKey',\n  2060: 'GeogAzimuthUnitsGeoKey',\n  2061: 'GeogPrimeMeridianLongGeoKey',\n  2062: 'GeogTOWGS84GeoKey',\n  3072: 'ProjectedCSTypeGeoKey',\n  3073: 'PCSCitationGeoKey',\n  3074: 'ProjectionGeoKey',\n  3075: 'ProjCoordTransGeoKey',\n  3076: 'ProjLinearUnitsGeoKey',\n  3077: 'ProjLinearUnitSizeGeoKey',\n  3078: 'ProjStdParallel1GeoKey',\n  3079: 'ProjStdParallel2GeoKey',\n  3080: 'ProjNatOriginLongGeoKey',\n  3081: 'ProjNatOriginLatGeoKey',\n  3082: 'ProjFalseEastingGeoKey',\n  3083: 'ProjFalseNorthingGeoKey',\n  3084: 'ProjFalseOriginLongGeoKey',\n  3085: 'ProjFalseOriginLatGeoKey',\n  3086: 'ProjFalseOriginEastingGeoKey',\n  3087: 'ProjFalseOriginNorthingGeoKey',\n  3088: 'ProjCenterLongGeoKey',\n  3089: 'ProjCenterLatGeoKey',\n  3090: 'ProjCenterEastingGeoKey',\n  3091: 'ProjCenterNorthingGeoKey',\n  3092: 'ProjScaleAtNatOriginGeoKey',\n  3093: 'ProjScaleAtCenterGeoKey',\n  3094: 'ProjAzimuthAngleGeoKey',\n  3095: 'ProjStraightVertPoleLongGeoKey',\n  3096: 'ProjRectifiedGridAngleGeoKey',\n  4096: 'VerticalCSTypeGeoKey',\n  4097: 'VerticalCitationGeoKey',\n  4098: 'VerticalDatumGeoKey',\n  4099: 'VerticalUnitsGeoKey',\n};\n\nconst geoKeys = {};\nfor (const key in geoKeyNames) {\n  if (geoKeyNames.hasOwnProperty(key)) {\n    geoKeys[geoKeyNames[key]] = parseInt(key, 10);\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/globals.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/logging.js":
/*!**********************************************!*\
  !*** ../node_modules/geotiff/src/logging.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"setLogger\": () => (/* binding */ setLogger),\n/* harmony export */   \"debug\": () => (/* binding */ debug),\n/* harmony export */   \"log\": () => (/* binding */ log),\n/* harmony export */   \"info\": () => (/* binding */ info),\n/* harmony export */   \"warn\": () => (/* binding */ warn),\n/* harmony export */   \"error\": () => (/* binding */ error),\n/* harmony export */   \"time\": () => (/* binding */ time),\n/* harmony export */   \"timeEnd\": () => (/* binding */ timeEnd)\n/* harmony export */ });\n\n/**\n * A no-op logger\n */\nclass DummyLogger {\n  log() {}\n\n  debug() {}\n\n  info() {}\n\n  warn() {}\n\n  error() {}\n\n  time() {}\n\n  timeEnd() {}\n}\n\nlet LOGGER = new DummyLogger();\n\n/**\n *\n * @param {object} logger the new logger. e.g `console`\n */\nfunction setLogger(logger = new DummyLogger()) {\n  LOGGER = logger;\n}\n\nfunction debug(...args) {\n  return LOGGER.debug(...args);\n}\n\nfunction log(...args) {\n  return LOGGER.log(...args);\n}\n\nfunction info(...args) {\n  return LOGGER.info(...args);\n}\n\nfunction warn(...args) {\n  return LOGGER.warn(...args);\n}\n\nfunction error(...args) {\n  return LOGGER.error(...args);\n}\n\nfunction time(...args) {\n  return LOGGER.time(...args);\n}\n\nfunction timeEnd(...args) {\n  return LOGGER.timeEnd(...args);\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/logging.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/pool.js":
/*!*******************************************!*\
  !*** ../node_modules/geotiff/src/pool.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var threads__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! threads */ \"../node_modules/threads/index.mjs\");\n\n\nconst defaultPoolSize = typeof navigator !== 'undefined' ? navigator.hardwareConcurrency : null;\n\n/**\n * @module pool\n */\n\n/**\n * Pool for workers to decode chunks of the images.\n */\nclass Pool {\n  /**\n   * @constructor\n   * @param {Number} size The size of the pool. Defaults to the number of CPUs\n   *                      available. When this parameter is `null` or 0, then the\n   *                      decoding will be done in the main thread.\n   * @param {Worker} worker The decoder worker, loaded and initialised. Enables\n   *                        loading the worker using worker-loader(or others) externally\n   *                        when using this library as a webpack dependency.\n   */\n  constructor(size = defaultPoolSize, worker = new threads__WEBPACK_IMPORTED_MODULE_0__.Worker('./decoder.worker.js')) {\n    this.pool = (0,threads__WEBPACK_IMPORTED_MODULE_0__.Pool)(() => (0,threads__WEBPACK_IMPORTED_MODULE_0__.spawn)(worker), size);\n  }\n\n  /**\n   * Decode the given block of bytes with the set compression method.\n   * @param {ArrayBuffer} buffer the array buffer of bytes to decode.\n   * @returns {Promise.<ArrayBuffer>} the decoded result as a `Promise`\n   */\n  async decode(fileDirectory, buffer) {\n    return new Promise((resolve, reject) => {\n      this.pool.queue(async (decode) => {\n        try {\n          const data = await decode(fileDirectory, (0,threads__WEBPACK_IMPORTED_MODULE_0__.Transfer)(buffer));\n          resolve(data);\n        } catch (err) {\n          reject(err);\n        }\n      });\n    });\n  }\n\n  destroy() {\n    this.pool.terminate(true);\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Pool);\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/pool.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/predictor.js":
/*!************************************************!*\
  !*** ../node_modules/geotiff/src/predictor.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"applyPredictor\": () => (/* binding */ applyPredictor)\n/* harmony export */ });\n\nfunction decodeRowAcc(row, stride) {\n  let length = row.length - stride;\n  let offset = 0;\n  do {\n    for (let i = stride; i > 0; i--) {\n      row[offset + stride] += row[offset];\n      offset++;\n    }\n\n    length -= stride;\n  } while (length > 0);\n}\n\nfunction decodeRowFloatingPoint(row, stride, bytesPerSample) {\n  let index = 0;\n  let count = row.length;\n  const wc = count / bytesPerSample;\n\n  while (count > stride) {\n    for (let i = stride; i > 0; --i) {\n      row[index + stride] += row[index];\n      ++index;\n    }\n    count -= stride;\n  }\n\n  const copy = row.slice();\n  for (let i = 0; i < wc; ++i) {\n    for (let b = 0; b < bytesPerSample; ++b) {\n      row[(bytesPerSample * i) + b] = copy[((bytesPerSample - b - 1) * wc) + i];\n    }\n  }\n}\n\nfunction applyPredictor(block, predictor, width, height, bitsPerSample,\n  planarConfiguration) {\n  if (!predictor || predictor === 1) {\n    return block;\n  }\n\n  for (let i = 0; i < bitsPerSample.length; ++i) {\n    if (bitsPerSample[i] % 8 !== 0) {\n      throw new Error('When decoding with predictor, only multiple of 8 bits are supported.');\n    }\n    if (bitsPerSample[i] !== bitsPerSample[0]) {\n      throw new Error('When decoding with predictor, all samples must have the same size.');\n    }\n  }\n\n  const bytesPerSample = bitsPerSample[0] / 8;\n  const stride = planarConfiguration === 2 ? 1 : bitsPerSample.length;\n\n  for (let i = 0; i < height; ++i) {\n    // Last strip will be truncated if height % stripHeight != 0\n    if (i * stride * width * bytesPerSample >= block.byteLength) {\n      break;\n    }\n    let row;\n    if (predictor === 2) { // horizontal prediction\n      switch (bitsPerSample[0]) {\n        case 8:\n          row = new Uint8Array(\n            block, i * stride * width * bytesPerSample, stride * width * bytesPerSample,\n          );\n          break;\n        case 16:\n          row = new Uint16Array(\n            block, i * stride * width * bytesPerSample, stride * width * bytesPerSample / 2,\n          );\n          break;\n        case 32:\n          row = new Uint32Array(\n            block, i * stride * width * bytesPerSample, stride * width * bytesPerSample / 4,\n          );\n          break;\n        default:\n          throw new Error(`Predictor 2 not allowed with ${bitsPerSample[0]} bits per sample.`);\n      }\n      decodeRowAcc(row, stride, bytesPerSample);\n    } else if (predictor === 3) { // horizontal floating point\n      row = new Uint8Array(\n        block, i * stride * width * bytesPerSample, stride * width * bytesPerSample,\n      );\n      decodeRowFloatingPoint(row, stride, bytesPerSample);\n    }\n  }\n  return block;\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/predictor.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/resample.js":
/*!***********************************************!*\
  !*** ../node_modules/geotiff/src/resample.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"resampleNearest\": () => (/* binding */ resampleNearest),\n/* harmony export */   \"resampleBilinear\": () => (/* binding */ resampleBilinear),\n/* harmony export */   \"resample\": () => (/* binding */ resample),\n/* harmony export */   \"resampleNearestInterleaved\": () => (/* binding */ resampleNearestInterleaved),\n/* harmony export */   \"resampleBilinearInterleaved\": () => (/* binding */ resampleBilinearInterleaved),\n/* harmony export */   \"resampleInterleaved\": () => (/* binding */ resampleInterleaved)\n/* harmony export */ });\n/**\n * @module resample\n */\n\nfunction copyNewSize(array, width, height, samplesPerPixel = 1) {\n  return new (Object.getPrototypeOf(array).constructor)(width * height * samplesPerPixel);\n}\n\n/**\n * Resample the input arrays using nearest neighbor value selection.\n * @param {TypedArray[]} valueArrays The input arrays to resample\n * @param {number} inWidth The width of the input rasters\n * @param {number} inHeight The height of the input rasters\n * @param {number} outWidth The desired width of the output rasters\n * @param {number} outHeight The desired height of the output rasters\n * @returns {TypedArray[]} The resampled rasters\n */\nfunction resampleNearest(valueArrays, inWidth, inHeight, outWidth, outHeight) {\n  const relX = inWidth / outWidth;\n  const relY = inHeight / outHeight;\n  return valueArrays.map((array) => {\n    const newArray = copyNewSize(array, outWidth, outHeight);\n    for (let y = 0; y < outHeight; ++y) {\n      const cy = Math.min(Math.round(relY * y), inHeight - 1);\n      for (let x = 0; x < outWidth; ++x) {\n        const cx = Math.min(Math.round(relX * x), inWidth - 1);\n        const value = array[(cy * inWidth) + cx];\n        newArray[(y * outWidth) + x] = value;\n      }\n    }\n    return newArray;\n  });\n}\n\n// simple linear interpolation, code from:\n// https://en.wikipedia.org/wiki/Linear_interpolation#Programming_language_support\nfunction lerp(v0, v1, t) {\n  return ((1 - t) * v0) + (t * v1);\n}\n\n/**\n * Resample the input arrays using bilinear interpolation.\n * @param {TypedArray[]} valueArrays The input arrays to resample\n * @param {number} inWidth The width of the input rasters\n * @param {number} inHeight The height of the input rasters\n * @param {number} outWidth The desired width of the output rasters\n * @param {number} outHeight The desired height of the output rasters\n * @returns {TypedArray[]} The resampled rasters\n */\nfunction resampleBilinear(valueArrays, inWidth, inHeight, outWidth, outHeight) {\n  const relX = inWidth / outWidth;\n  const relY = inHeight / outHeight;\n\n  return valueArrays.map((array) => {\n    const newArray = copyNewSize(array, outWidth, outHeight);\n    for (let y = 0; y < outHeight; ++y) {\n      const rawY = relY * y;\n\n      const yl = Math.floor(rawY);\n      const yh = Math.min(Math.ceil(rawY), (inHeight - 1));\n\n      for (let x = 0; x < outWidth; ++x) {\n        const rawX = relX * x;\n        const tx = rawX % 1;\n\n        const xl = Math.floor(rawX);\n        const xh = Math.min(Math.ceil(rawX), (inWidth - 1));\n\n        const ll = array[(yl * inWidth) + xl];\n        const hl = array[(yl * inWidth) + xh];\n        const lh = array[(yh * inWidth) + xl];\n        const hh = array[(yh * inWidth) + xh];\n\n        const value = lerp(\n          lerp(ll, hl, tx),\n          lerp(lh, hh, tx),\n          rawY % 1,\n        );\n        newArray[(y * outWidth) + x] = value;\n      }\n    }\n    return newArray;\n  });\n}\n\n/**\n * Resample the input arrays using the selected resampling method.\n * @param {TypedArray[]} valueArrays The input arrays to resample\n * @param {number} inWidth The width of the input rasters\n * @param {number} inHeight The height of the input rasters\n * @param {number} outWidth The desired width of the output rasters\n * @param {number} outHeight The desired height of the output rasters\n * @param {string} [method = 'nearest'] The desired resampling method\n * @returns {TypedArray[]} The resampled rasters\n */\nfunction resample(valueArrays, inWidth, inHeight, outWidth, outHeight, method = 'nearest') {\n  switch (method.toLowerCase()) {\n    case 'nearest':\n      return resampleNearest(valueArrays, inWidth, inHeight, outWidth, outHeight);\n    case 'bilinear':\n    case 'linear':\n      return resampleBilinear(valueArrays, inWidth, inHeight, outWidth, outHeight);\n    default:\n      throw new Error(`Unsupported resampling method: '${method}'`);\n  }\n}\n\n/**\n * Resample the pixel interleaved input array using nearest neighbor value selection.\n * @param {TypedArray} valueArrays The input arrays to resample\n * @param {number} inWidth The width of the input rasters\n * @param {number} inHeight The height of the input rasters\n * @param {number} outWidth The desired width of the output rasters\n * @param {number} outHeight The desired height of the output rasters\n * @param {number} samples The number of samples per pixel for pixel\n *                         interleaved data\n * @returns {TypedArray} The resampled raster\n */\nfunction resampleNearestInterleaved(\n  valueArray, inWidth, inHeight, outWidth, outHeight, samples) {\n  const relX = inWidth / outWidth;\n  const relY = inHeight / outHeight;\n\n  const newArray = copyNewSize(valueArray, outWidth, outHeight, samples);\n  for (let y = 0; y < outHeight; ++y) {\n    const cy = Math.min(Math.round(relY * y), inHeight - 1);\n    for (let x = 0; x < outWidth; ++x) {\n      const cx = Math.min(Math.round(relX * x), inWidth - 1);\n      for (let i = 0; i < samples; ++i) {\n        const value = valueArray[(cy * inWidth * samples) + (cx * samples) + i];\n        newArray[(y * outWidth * samples) + (x * samples) + i] = value;\n      }\n    }\n  }\n  return newArray;\n}\n\n/**\n * Resample the pixel interleaved input array using bilinear interpolation.\n * @param {TypedArray} valueArrays The input arrays to resample\n * @param {number} inWidth The width of the input rasters\n * @param {number} inHeight The height of the input rasters\n * @param {number} outWidth The desired width of the output rasters\n * @param {number} outHeight The desired height of the output rasters\n * @param {number} samples The number of samples per pixel for pixel\n *                         interleaved data\n * @returns {TypedArray} The resampled raster\n */\nfunction resampleBilinearInterleaved(\n  valueArray, inWidth, inHeight, outWidth, outHeight, samples) {\n  const relX = inWidth / outWidth;\n  const relY = inHeight / outHeight;\n  const newArray = copyNewSize(valueArray, outWidth, outHeight, samples);\n  for (let y = 0; y < outHeight; ++y) {\n    const rawY = relY * y;\n\n    const yl = Math.floor(rawY);\n    const yh = Math.min(Math.ceil(rawY), (inHeight - 1));\n\n    for (let x = 0; x < outWidth; ++x) {\n      const rawX = relX * x;\n      const tx = rawX % 1;\n\n      const xl = Math.floor(rawX);\n      const xh = Math.min(Math.ceil(rawX), (inWidth - 1));\n\n      for (let i = 0; i < samples; ++i) {\n        const ll = valueArray[(yl * inWidth * samples) + (xl * samples) + i];\n        const hl = valueArray[(yl * inWidth * samples) + (xh * samples) + i];\n        const lh = valueArray[(yh * inWidth * samples) + (xl * samples) + i];\n        const hh = valueArray[(yh * inWidth * samples) + (xh * samples) + i];\n\n        const value = lerp(\n          lerp(ll, hl, tx),\n          lerp(lh, hh, tx),\n          rawY % 1,\n        );\n        newArray[(y * outWidth * samples) + (x * samples) + i] = value;\n      }\n    }\n  }\n  return newArray;\n}\n\n/**\n * Resample the pixel interleaved input array using the selected resampling method.\n * @param {TypedArray} valueArray The input array to resample\n * @param {number} inWidth The width of the input rasters\n * @param {number} inHeight The height of the input rasters\n * @param {number} outWidth The desired width of the output rasters\n * @param {number} outHeight The desired height of the output rasters\n * @param {number} samples The number of samples per pixel for pixel\n *                                 interleaved data\n * @param {string} [method = 'nearest'] The desired resampling method\n * @returns {TypedArray} The resampled rasters\n */\nfunction resampleInterleaved(valueArray, inWidth, inHeight, outWidth, outHeight, samples, method = 'nearest') {\n  switch (method.toLowerCase()) {\n    case 'nearest':\n      return resampleNearestInterleaved(\n        valueArray, inWidth, inHeight, outWidth, outHeight, samples,\n      );\n    case 'bilinear':\n    case 'linear':\n      return resampleBilinearInterleaved(\n        valueArray, inWidth, inHeight, outWidth, outHeight, samples,\n      );\n    default:\n      throw new Error(`Unsupported resampling method: '${method}'`);\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/resample.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/rgb.js":
/*!******************************************!*\
  !*** ../node_modules/geotiff/src/rgb.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"fromWhiteIsZero\": () => (/* binding */ fromWhiteIsZero),\n/* harmony export */   \"fromBlackIsZero\": () => (/* binding */ fromBlackIsZero),\n/* harmony export */   \"fromPalette\": () => (/* binding */ fromPalette),\n/* harmony export */   \"fromCMYK\": () => (/* binding */ fromCMYK),\n/* harmony export */   \"fromYCbCr\": () => (/* binding */ fromYCbCr),\n/* harmony export */   \"fromCIELab\": () => (/* binding */ fromCIELab)\n/* harmony export */ });\nfunction fromWhiteIsZero(raster, max) {\n  const { width, height } = raster;\n  const rgbRaster = new Uint8Array(width * height * 3);\n  let value;\n  for (let i = 0, j = 0; i < raster.length; ++i, j += 3) {\n    value = 256 - (raster[i] / max * 256);\n    rgbRaster[j] = value;\n    rgbRaster[j + 1] = value;\n    rgbRaster[j + 2] = value;\n  }\n  return rgbRaster;\n}\n\nfunction fromBlackIsZero(raster, max) {\n  const { width, height } = raster;\n  const rgbRaster = new Uint8Array(width * height * 3);\n  let value;\n  for (let i = 0, j = 0; i < raster.length; ++i, j += 3) {\n    value = raster[i] / max * 256;\n    rgbRaster[j] = value;\n    rgbRaster[j + 1] = value;\n    rgbRaster[j + 2] = value;\n  }\n  return rgbRaster;\n}\n\nfunction fromPalette(raster, colorMap) {\n  const { width, height } = raster;\n  const rgbRaster = new Uint8Array(width * height * 3);\n  const greenOffset = colorMap.length / 3;\n  const blueOffset = colorMap.length / 3 * 2;\n  for (let i = 0, j = 0; i < raster.length; ++i, j += 3) {\n    const mapIndex = raster[i];\n    rgbRaster[j] = colorMap[mapIndex] / 65536 * 256;\n    rgbRaster[j + 1] = colorMap[mapIndex + greenOffset] / 65536 * 256;\n    rgbRaster[j + 2] = colorMap[mapIndex + blueOffset] / 65536 * 256;\n  }\n  return rgbRaster;\n}\n\nfunction fromCMYK(cmykRaster) {\n  const { width, height } = cmykRaster;\n  const rgbRaster = new Uint8Array(width * height * 3);\n  for (let i = 0, j = 0; i < cmykRaster.length; i += 4, j += 3) {\n    const c = cmykRaster[i];\n    const m = cmykRaster[i + 1];\n    const y = cmykRaster[i + 2];\n    const k = cmykRaster[i + 3];\n\n    rgbRaster[j] = 255 * ((255 - c) / 256) * ((255 - k) / 256);\n    rgbRaster[j + 1] = 255 * ((255 - m) / 256) * ((255 - k) / 256);\n    rgbRaster[j + 2] = 255 * ((255 - y) / 256) * ((255 - k) / 256);\n  }\n  return rgbRaster;\n}\n\nfunction fromYCbCr(yCbCrRaster) {\n  const { width, height } = yCbCrRaster;\n  const rgbRaster = new Uint8ClampedArray(width * height * 3);\n  for (let i = 0, j = 0; i < yCbCrRaster.length; i += 3, j += 3) {\n    const y = yCbCrRaster[i];\n    const cb = yCbCrRaster[i + 1];\n    const cr = yCbCrRaster[i + 2];\n\n    rgbRaster[j] = (y + (1.40200 * (cr - 0x80)));\n    rgbRaster[j + 1] = (y - (0.34414 * (cb - 0x80)) - (0.71414 * (cr - 0x80)));\n    rgbRaster[j + 2] = (y + (1.77200 * (cb - 0x80)));\n  }\n  return rgbRaster;\n}\n\nconst Xn = 0.95047;\nconst Yn = 1.00000;\nconst Zn = 1.08883;\n\n// from https://github.com/antimatter15/rgb-lab/blob/master/color.js\n\nfunction fromCIELab(cieLabRaster) {\n  const { width, height } = cieLabRaster;\n  const rgbRaster = new Uint8Array(width * height * 3);\n\n  for (let i = 0, j = 0; i < cieLabRaster.length; i += 3, j += 3) {\n    const L = cieLabRaster[i + 0];\n    const a_ = cieLabRaster[i + 1] << 24 >> 24; // conversion from uint8 to int8\n    const b_ = cieLabRaster[i + 2] << 24 >> 24; // same\n\n    let y = (L + 16) / 116;\n    let x = (a_ / 500) + y;\n    let z = y - (b_ / 200);\n    let r;\n    let g;\n    let b;\n\n    x = Xn * ((x * x * x > 0.008856) ? x * x * x : (x - (16 / 116)) / 7.787);\n    y = Yn * ((y * y * y > 0.008856) ? y * y * y : (y - (16 / 116)) / 7.787);\n    z = Zn * ((z * z * z > 0.008856) ? z * z * z : (z - (16 / 116)) / 7.787);\n\n    r = (x * 3.2406) + (y * -1.5372) + (z * -0.4986);\n    g = (x * -0.9689) + (y * 1.8758) + (z * 0.0415);\n    b = (x * 0.0557) + (y * -0.2040) + (z * 1.0570);\n\n    r = (r > 0.0031308) ? ((1.055 * (r ** (1 / 2.4))) - 0.055) : 12.92 * r;\n    g = (g > 0.0031308) ? ((1.055 * (g ** (1 / 2.4))) - 0.055) : 12.92 * g;\n    b = (b > 0.0031308) ? ((1.055 * (b ** (1 / 2.4))) - 0.055) : 12.92 * b;\n\n    rgbRaster[j] = Math.max(0, Math.min(1, r)) * 255;\n    rgbRaster[j + 1] = Math.max(0, Math.min(1, g)) * 255;\n    rgbRaster[j + 2] = Math.max(0, Math.min(1, b)) * 255;\n  }\n  return rgbRaster;\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/rgb.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/source/arraybuffer.js":
/*!*********************************************************!*\
  !*** ../node_modules/geotiff/src/source/arraybuffer.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"makeBufferSource\": () => (/* binding */ makeBufferSource)\n/* harmony export */ });\n/* harmony import */ var _basesource__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./basesource */ \"../node_modules/geotiff/src/source/basesource.js\");\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils */ \"../node_modules/geotiff/src/utils.js\");\n\n\n\n\nclass ArrayBufferSource extends _basesource__WEBPACK_IMPORTED_MODULE_0__.BaseSource {\n  constructor(arrayBuffer) {\n    super();\n    this.arrayBuffer = arrayBuffer;\n  }\n\n  fetchSlice(slice, signal) {\n    if (signal && signal.aborted) {\n      throw new _utils__WEBPACK_IMPORTED_MODULE_1__.AbortError('Request aborted');\n    }\n    return this.arrayBuffer.slice(slice.offset, slice.offset + slice.length);\n  }\n}\n\nfunction makeBufferSource(arrayBuffer) {\n  return new ArrayBufferSource(arrayBuffer);\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/source/arraybuffer.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/source/basesource.js":
/*!********************************************************!*\
  !*** ../node_modules/geotiff/src/source/basesource.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"BaseSource\": () => (/* binding */ BaseSource)\n/* harmony export */ });\n/**\n * @typedef Slice\n * @property {number} offset\n * @property {number} length\n */\n\nclass BaseSource {\n  /**\n   *\n   * @param {Slice[]} slices\n   * @returns {ArrayBuffer[]}\n   */\n  async fetch(slices, signal = undefined) {\n    return await Promise.all(\n      slices.map((slice) => this.fetchSlice(slice, signal)),\n    );\n  }\n\n  /**\n   *\n   * @param {Slice} slice\n   * @returns {ArrayBuffer}\n   */\n  async fetchSlice(slice) {\n    throw new Error(`fetching of slice ${slice} not possible, not implemented`);\n  }\n\n  /**\n   * Returns the filesize if already determined and null otherwise\n   */\n  get fileSize() {\n    return null;\n  }\n\n  async close() {\n    // no-op by default\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/source/basesource.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/source/blockedsource.js":
/*!***********************************************************!*\
  !*** ../node_modules/geotiff/src/source/blockedsource.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"BlockedSource\": () => (/* binding */ BlockedSource)\n/* harmony export */ });\n/* harmony import */ var lru_cache__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! lru-cache */ \"../node_modules/lru-cache/index.js\");\n/* harmony import */ var lru_cache__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(lru_cache__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _basesource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./basesource */ \"../node_modules/geotiff/src/source/basesource.js\");\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils */ \"../node_modules/geotiff/src/utils.js\");\n\n\n\n\nclass Block {\n  /**\n   *\n   * @param {number} offset\n   * @param {number} length\n   * @param {ArrayBuffer} [data]\n   */\n  constructor(offset, length, data = null) {\n    this.offset = offset;\n    this.length = length;\n    this.data = data;\n  }\n\n  /**\n   * @returns {number} the top byte border\n   */\n  get top() {\n    return this.offset + this.length;\n  }\n}\n\n\nclass BlockGroup {\n  /**\n   *\n   * @param {number} offset\n   * @param {number} length\n   * @param {number[]} blockIds\n   */\n  constructor(offset, length, blockIds) {\n    this.offset = offset;\n    this.length = length;\n    this.blockIds = blockIds;\n  }\n}\n\n\nclass BlockedSource extends _basesource__WEBPACK_IMPORTED_MODULE_1__.BaseSource {\n  /**\n   *\n   * @param {Source} source The underlying source that shall be blocked and cached\n   * @param {object} options\n   */\n  constructor(source, { blockSize = 65536, cacheSize = 100 } = {}) {\n    super();\n    this.source = source;\n    this.blockSize = blockSize;\n\n    this.blockCache = new (lru_cache__WEBPACK_IMPORTED_MODULE_0___default())({ max: cacheSize });\n\n    // mapping blockId -> Block instance\n    this.blockRequests = new Map();\n\n    // set of blockIds missing for the current requests\n    this.blockIdsToFetch = new Set();\n  }\n\n  get fileSize() {\n    return this.source.fileSize;\n  }\n\n  /**\n   *\n   * @param {basesource/Slice[]} slices\n   */\n  async fetch(slices, signal) {\n    const cachedBlocks = new Map();\n    const blockRequests = new Map();\n    const missingBlockIds = new Set();\n\n    for (const { offset, length } of slices) {\n      let top = offset + length;\n\n      const { fileSize } = this;\n      if (fileSize !== null) {\n        top = Math.min(top, fileSize);\n      }\n\n      const firstBlockOffset = Math.floor(offset / this.blockSize) * this.blockSize;\n\n      // chunk the current slice into blocks\n      for (let current = firstBlockOffset; current < top; current += this.blockSize) {\n        // check if the block is cached, being requested or still missing\n        const blockId = Math.floor(current / this.blockSize);\n\n        if (this.blockCache.has(blockId)) {\n          cachedBlocks.set(blockId, this.blockCache.get(blockId));\n        } else if (this.blockRequests.has(blockId)) {\n          blockRequests.set(blockId, this.blockRequests.get(blockId));\n        } else if (this.blockIdsToFetch.has(blockId)) {\n          missingBlockIds.add(blockId);\n        } else {\n          this.blockIdsToFetch.add(blockId);\n          missingBlockIds.add(blockId);\n        }\n      }\n    }\n\n    // allow additional block requests to accumulate\n    await (0,_utils__WEBPACK_IMPORTED_MODULE_2__.wait)();\n    this.fetchBlocks(signal);\n\n    for (const blockId of missingBlockIds) {\n      const block = this.blockRequests.get(blockId);\n      const cachedBlock = this.blockCache.get(blockId);\n\n      if (block) {\n        blockRequests.set(blockId, block);\n      } else if (cachedBlock) {\n        cachedBlocks.set(blockId, cachedBlock);\n      } else {\n        throw new Error(`Block ${blockId} is not in the block requests`);\n      }\n    }\n\n    // actually await all pending requests\n    let results = await Promise.allSettled(blockRequests.values());\n\n    // perform retries if a block was interrupted by a previous signal\n    if (results.some((result) => result.status === 'rejected')) {\n      const retriedBlockRequests = new Set();\n      for (const [blockId, result] of (0,_utils__WEBPACK_IMPORTED_MODULE_2__.zip)(blockRequests.keys(), results)) {\n        const { rejected, reason } = result;\n        if (rejected) {\n          // push some blocks back to the to-fetch list if they were\n          // aborted, but only when a different signal was used\n          if (reason.name === 'AbortError' && reason.signal !== signal) {\n            this.blockIdsToFetch.add(blockId);\n            retriedBlockRequests.add(blockId);\n          }\n        }\n      }\n\n      // start the retry of some blocks if required\n      if (this.blockIdsToFetch.length > 0) {\n        this.fetchBlocks(signal);\n        for (const blockId of retriedBlockRequests) {\n          const block = this.blockRequests.get(blockId);\n          if (!block) {\n            throw new Error(`Block ${blockId} is not in the block requests`);\n          }\n          blockRequests.set(blockId, block);\n        }\n        results = await Promise.allSettled(Array.from(blockRequests.values()));\n      }\n    }\n\n    // throw an error (either abort error or AggregateError if no abort was done)\n    if (results.some((result) => result.status === 'rejected')) {\n      if (signal && signal.aborted) {\n        throw new _utils__WEBPACK_IMPORTED_MODULE_2__.AbortError('Request was aborted');\n      }\n      throw new _utils__WEBPACK_IMPORTED_MODULE_2__.AggregateError(\n        results.filter((result) => result.status === 'rejected').map((result) => result.reason),\n        'Request failed',\n      );\n    }\n\n    // extract the actual block responses\n    const values = results.map((result) => result.value);\n\n    // create a final Map, with all required blocks for this request to satisfy\n    const requiredBlocks = new Map((0,_utils__WEBPACK_IMPORTED_MODULE_2__.zip)(Array.from(blockRequests.keys()), values));\n    for (const [blockId, block] of cachedBlocks) {\n      requiredBlocks.set(blockId, block);\n    }\n\n    // TODO: satisfy each slice\n    return this.readSliceData(slices, requiredBlocks);\n  }\n\n  /**\n   *\n   * @param {AbortSignal} signal\n   */\n  fetchBlocks(signal) {\n    // check if we still need to\n    if (this.blockIdsToFetch.size > 0) {\n      const groups = this.groupBlocks(this.blockIdsToFetch);\n\n      // start requesting slices of data\n      const groupRequests = this.source.fetch(groups, signal);\n\n      for (let groupIndex = 0; groupIndex < groups.length; ++groupIndex) {\n        const group = groups[groupIndex];\n\n        for (const blockId of group.blockIds) {\n          // make an async IIFE for each block\n          const blockRequest = (async () => {\n            try {\n              const response = (await groupRequests)[groupIndex];\n              const blockOffset = blockId * this.blockSize;\n              const o = blockOffset - response.offset;\n              const t = Math.min(o + this.blockSize, response.data.byteLength);\n              const data = response.data.slice(o, t);\n              const block = new Block(\n                blockOffset,\n                data.byteLength,\n                data,\n              );\n              this.blockCache.set(blockId, block);\n              return block;\n            } catch (err) {\n              if (err.name === 'AbortError') {\n                // store the signal here, we need it to determine later if an\n                // error was caused by this signal\n                err.signal = signal;\n              }\n              throw err;\n            } finally {\n              this.blockRequests.delete(blockId);\n            }\n          })();\n          this.blockRequests.set(blockId, blockRequest);\n        }\n      }\n      this.blockIdsToFetch.clear();\n    }\n  }\n\n  /**\n   *\n   * @param {Set} blockIds\n   * @returns {BlockGroup[]}\n   */\n  groupBlocks(blockIds) {\n    const sortedBlockIds = Array.from(blockIds).sort((a, b) => a - b);\n    if (sortedBlockIds.length === 0) {\n      return [];\n    }\n    let current = [];\n    let lastBlockId = null;\n    const groups = [];\n\n    for (const blockId of sortedBlockIds) {\n      if (lastBlockId === null || lastBlockId + 1 === blockId) {\n        current.push(blockId);\n        lastBlockId = blockId;\n      } else {\n        groups.push(new BlockGroup(\n          current[0] * this.blockSize,\n          current.length * this.blockSize,\n          current,\n        ));\n        current = [blockId];\n        lastBlockId = blockId;\n      }\n    }\n\n    groups.push(new BlockGroup(\n      current[0] * this.blockSize,\n      current.length * this.blockSize,\n      current,\n    ));\n\n    return groups;\n  }\n\n  /**\n   *\n   * @param {Slice[]} slices\n   * @param {Map} blocks\n   */\n  readSliceData(slices, blocks) {\n    return slices.map((slice) => {\n      const top = slice.offset + slice.length;\n      const blockIdLow = Math.floor(slice.offset / this.blockSize);\n      const blockIdHigh = Math.floor((slice.offset + slice.length) / this.blockSize);\n      const sliceData = new ArrayBuffer(slice.length);\n      const sliceView = new Uint8Array(sliceData);\n\n      for (let blockId = blockIdLow; blockId <= blockIdHigh; ++blockId) {\n        const block = blocks.get(blockId);\n        const delta = block.offset - slice.offset;\n        const topDelta = block.top - top;\n        let blockInnerOffset = 0;\n        let rangeInnerOffset = 0;\n        let usedBlockLength;\n\n        if (delta < 0) {\n          blockInnerOffset = -delta;\n        } else if (delta > 0) {\n          rangeInnerOffset = delta;\n        }\n\n        if (topDelta < 0) {\n          usedBlockLength = block.length - blockInnerOffset;\n        } else {\n          usedBlockLength = top - block.offset - blockInnerOffset;\n        }\n\n        const blockView = new Uint8Array(block.data, blockInnerOffset, usedBlockLength);\n        sliceView.set(blockView, rangeInnerOffset);\n      }\n\n      return sliceData;\n    });\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/source/blockedsource.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/source/client/base.js":
/*!*********************************************************!*\
  !*** ../node_modules/geotiff/src/source/client/base.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"BaseResponse\": () => (/* binding */ BaseResponse),\n/* harmony export */   \"BaseClient\": () => (/* binding */ BaseClient)\n/* harmony export */ });\nclass BaseResponse {\n  /**\n   * Returns whether the response has an ok'ish status code\n   */\n  get ok() {\n    return this.status >= 200 && this.status <= 299;\n  }\n\n  /**\n   * Returns the status code of the response\n   */\n  get status() {\n    throw new Error('not implemented');\n  }\n\n  /**\n   * Returns the value of the specified header\n   * @param {string} headerName the header name\n   * @returns {string} the header value\n   */\n  getHeader(headerName) {\n    throw new Error('not implemented');\n  }\n\n  /**\n   * @returns {ArrayBuffer} the response data of the request\n   */\n  async getData() {\n    throw new Error('not implemented');\n  }\n}\n\nclass BaseClient {\n  constructor(url) {\n    this.url = url;\n  }\n\n  /**\n   * Send a request with the options\n   * @param {object} [options]\n   */\n  async request({ headers, credentials, signal } = {}) {\n    throw new Error(`request is not implemented`);\n  }\n}\n\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/source/client/base.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/source/client/fetch.js":
/*!**********************************************************!*\
  !*** ../node_modules/geotiff/src/source/client/fetch.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FetchClient\": () => (/* binding */ FetchClient)\n/* harmony export */ });\n/* harmony import */ var _base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./base */ \"../node_modules/geotiff/src/source/client/base.js\");\n\n\n\nclass FetchResponse extends _base__WEBPACK_IMPORTED_MODULE_0__.BaseResponse {\n  /**\n   * BaseResponse facade for fetch API Response\n   * @param {Response} response\n   */\n  constructor(response) {\n    super();\n    this.response = response;\n  }\n\n  get status() {\n    return this.response.status;\n  }\n\n  getHeader(name) {\n    return this.response.headers.get(name);\n  }\n\n  async getData() {\n    const data = this.response.arrayBuffer\n      ? await this.response.arrayBuffer()\n      : (await this.response.buffer()).buffer;\n    return data;\n  }\n}\n\nclass FetchClient extends _base__WEBPACK_IMPORTED_MODULE_0__.BaseClient {\n  constructor(url, credentials) {\n    super(url);\n    this.credentials = credentials;\n  }\n\n  async request({ headers, credentials, signal } = {}) {\n    const response = await fetch(this.url, {\n      headers, credentials, signal,\n    });\n    return new FetchResponse(response);\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/source/client/fetch.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/source/client/http.js":
/*!*********************************************************!*\
  !*** ../node_modules/geotiff/src/source/client/http.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"HttpClient\": () => (/* binding */ HttpClient)\n/* harmony export */ });\n/* harmony import */ var http__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! http */ \"?3701\");\n/* harmony import */ var http__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(http__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var https__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! https */ \"?9079\");\n/* harmony import */ var https__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(https__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var url__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! url */ \"?c08e\");\n/* harmony import */ var url__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(url__WEBPACK_IMPORTED_MODULE_2__);\n/* harmony import */ var _base__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./base */ \"../node_modules/geotiff/src/source/client/base.js\");\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../utils */ \"../node_modules/geotiff/src/utils.js\");\n\n\n\n\n\n\n\n\nclass HttpResponse extends _base__WEBPACK_IMPORTED_MODULE_3__.BaseResponse {\n  /**\n   * BaseResponse facade for node HTTP/HTTPS API Response\n   * @param {http.ServerResponse} response\n   */\n  constructor(response, dataPromise) {\n    super();\n    this.response = response;\n    this.dataPromise = dataPromise;\n  }\n\n  get status() {\n    return this.response.statusCode;\n  }\n\n  getHeader(name) {\n    return this.response.headers[name];\n  }\n\n  async getData() {\n    const data = await this.dataPromise;\n    return data;\n  }\n}\n\nclass HttpClient extends _base__WEBPACK_IMPORTED_MODULE_3__.BaseClient {\n  constructor(url) {\n    super(url);\n    this.parsedUrl = url__WEBPACK_IMPORTED_MODULE_2___default().parse(this.url);\n    this.httpApi = (this.parsedUrl.protocol === 'http:' ? (http__WEBPACK_IMPORTED_MODULE_0___default()) : (https__WEBPACK_IMPORTED_MODULE_1___default()));\n  }\n  constructRequest(headers, signal) {\n    return new Promise((resolve, reject) => {\n      const request = this.httpApi.get(\n        {\n          ...this.parsedUrl,\n          headers,\n        },\n        (response) => {\n          const dataPromise = new Promise((resolve) => {\n            const chunks = [];\n\n            // collect chunks\n            response.on('data', (chunk) => {\n              chunks.push(chunk);\n            });\n\n            // concatenate all chunks and resolve the promise with the resulting buffer\n            response.on('end', () => {\n              const data = Buffer.concat(chunks).buffer;\n              resolve(data);\n            });\n            response.on('error', reject);\n          });\n          resolve(new HttpResponse(response, dataPromise));\n        },\n      );\n      request.on('error', reject);\n\n      if (signal) {\n        if (signal.aborted) {\n          request.destroy(new _utils__WEBPACK_IMPORTED_MODULE_4__.AbortError('Request aborted'));\n        }\n        signal.addEventListener('abort', () => request.destroy(new _utils__WEBPACK_IMPORTED_MODULE_4__.AbortError('Request aborted')));\n      }\n    });\n  }\n  async request({ headers, signal } = {}) {\n    const response = await this.constructRequest(headers, signal);\n    return response;\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/source/client/http.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/source/client/xhr.js":
/*!********************************************************!*\
  !*** ../node_modules/geotiff/src/source/client/xhr.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"XHRClient\": () => (/* binding */ XHRClient)\n/* harmony export */ });\n/* harmony import */ var _base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./base */ \"../node_modules/geotiff/src/source/client/base.js\");\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../utils */ \"../node_modules/geotiff/src/utils.js\");\n\n\n\n\nclass XHRResponse extends _base__WEBPACK_IMPORTED_MODULE_0__.BaseResponse {\n  /**\n   * BaseResponse facade for XMLHttpRequest\n   * @param {XMLHttpRequest} xhr\n   * @param {ArrayBuffer} data\n   */\n  constructor(xhr, data) {\n    super();\n    this.xhr = xhr;\n    this.data = data;\n  }\n\n  get status() {\n    return this.xhr.status;\n  }\n\n  getHeader(name) {\n    return this.xhr.getResponseHeader(name);\n  }\n\n  async getData() {\n    return this.data;\n  }\n}\n\nclass XHRClient extends _base__WEBPACK_IMPORTED_MODULE_0__.BaseClient {\n  constructRequest(headers, signal) {\n    return new Promise((resolve, reject) => {\n      const xhr = new XMLHttpRequest();\n      xhr.open('GET', this.url);\n      xhr.responseType = 'arraybuffer';\n      for (const [key, value] of Object.entries(headers)) {\n        xhr.setRequestHeader(key, value);\n      }\n\n      // hook signals\n      xhr.onload = () => {\n        const data = xhr.response;\n        resolve(new XHRResponse(xhr, data));\n      };\n      xhr.onerror = reject;\n      xhr.onabort = () => reject(new _utils__WEBPACK_IMPORTED_MODULE_1__.AbortError('Request aborted'));\n      xhr.send();\n\n      if (signal) {\n        if (signal.aborted) {\n          xhr.abort();\n        }\n        signal.addEventListener('abort', () => xhr.abort());\n      }\n    });\n  }\n\n  async request({ headers, signal } = {}) {\n    const response = await this.constructRequest(headers, signal);\n    return response;\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/source/client/xhr.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/source/file.js":
/*!**************************************************!*\
  !*** ../node_modules/geotiff/src/source/file.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"makeFileSource\": () => (/* binding */ makeFileSource)\n/* harmony export */ });\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ \"../node_modules/fs/index.js\");\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _basesource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./basesource */ \"../node_modules/geotiff/src/source/basesource.js\");\n\n\n\nfunction closeAsync(fd) {\n  return new Promise((resolve, reject) => {\n    (0,fs__WEBPACK_IMPORTED_MODULE_0__.close)(fd, (err) => {\n      if (err) {\n        reject(err);\n      } else {\n        resolve();\n      }\n    });\n  });\n}\n\nfunction openAsync(path, flags, mode = undefined) {\n  return new Promise((resolve, reject) => {\n    (0,fs__WEBPACK_IMPORTED_MODULE_0__.open)(path, flags, mode, (err, fd) => {\n      if (err) {\n        reject(err);\n      } else {\n        resolve(fd);\n      }\n    });\n  });\n}\n\nfunction readAsync(...args) {\n  return new Promise((resolve, reject) => {\n    (0,fs__WEBPACK_IMPORTED_MODULE_0__.read)(...args, (err, bytesRead, buffer) => {\n      if (err) {\n        reject(err);\n      } else {\n        resolve({ bytesRead, buffer });\n      }\n    });\n  });\n}\n\nclass FileSource extends _basesource__WEBPACK_IMPORTED_MODULE_1__.BaseSource {\n  constructor(path) {\n    super();\n    this.path = path;\n    this.openRequest = openAsync(path, 'r');\n  }\n\n  async fetchSlice(slice) {\n    // TODO: use `signal`\n    const fd = await this.openRequest;\n    const { buffer } = await readAsync(\n      fd,\n      Buffer.alloc(slice.length),\n      0,\n      slice.length,\n      slice.offset,\n    );\n    return buffer.buffer;\n  }\n\n  async close() {\n    const fd = await this.openRequest;\n    await closeAsync(fd);\n  }\n}\n\nfunction makeFileSource(path) {\n  return new FileSource(path);\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/source/file.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/source/filereader.js":
/*!********************************************************!*\
  !*** ../node_modules/geotiff/src/source/filereader.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"makeFileReaderSource\": () => (/* binding */ makeFileReaderSource)\n/* harmony export */ });\n/* harmony import */ var _basesource__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./basesource */ \"../node_modules/geotiff/src/source/basesource.js\");\n\n\n\nclass FileReaderSource extends _basesource__WEBPACK_IMPORTED_MODULE_0__.BaseSource {\n  constructor(file) {\n    super();\n    this.file = file;\n  }\n\n  async fetchSlice(slice, signal) {\n    return new Promise((resolve, reject) => {\n      const blob = this.file.slice(slice.offset, slice.offset + slice.length);\n      const reader = new FileReader();\n      reader.onload = (event) => resolve(event.target.result);\n      reader.onerror = reject;\n      reader.onabort = reject;\n      reader.readAsArrayBuffer(blob);\n\n      if (signal) {\n        signal.addEventListener('abort', () => reader.abort());\n      }\n    });\n  }\n}\n\n/**\n * Create a new source from a given file/blob.\n * @param {Blob} file The file or blob to read from.\n * @returns The constructed source\n */\nfunction makeFileReaderSource(file) {\n  return new FileReaderSource(file);\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/source/filereader.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/source/httputils.js":
/*!*******************************************************!*\
  !*** ../node_modules/geotiff/src/source/httputils.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"parseContentType\": () => (/* binding */ parseContentType),\n/* harmony export */   \"parseContentRange\": () => (/* binding */ parseContentRange),\n/* harmony export */   \"parseByteRanges\": () => (/* binding */ parseByteRanges)\n/* harmony export */ });\n\nconst CRLFCRLF = '\\r\\n\\r\\n';\n\n/*\n * Shim for 'Object.fromEntries'\n */\nfunction itemsToObject(items) {\n  if (typeof Object.fromEntries !== 'undefined') {\n    return Object.fromEntries(items);\n  }\n  const obj = {};\n  for (const [key, value] of items) {\n    obj[key.toLowerCase()] = value;\n  }\n  return obj;\n}\n\n/**\n * Parse HTTP headers from a given string.\n * @param {String} text the text to parse the headers from\n * @returns {Object} the parsed headers with lowercase keys\n */\nfunction parseHeaders(text) {\n  const items = text\n    .split('\\r\\n')\n    .map(line => {\n      const kv = line.split(':').map(str => str.trim());\n      kv[0] = kv[0].toLowerCase();\n      return kv\n    });\n\n  return itemsToObject(items);\n}\n\n/**\n * Parse a 'Content-Type' header value to the content-type and parameters\n * @param {String} rawContentType the raw string to parse from\n * @returns {Object} the parsed content type with the fields: type and params\n */\nfunction parseContentType(rawContentType) {\n  const [type, ...rawParams] = rawContentType.split(';').map((s) => s.trim());\n  const paramsItems = rawParams.map((param) => param.split('='));\n  return { type, params: itemsToObject(paramsItems) };\n}\n\n/**\n * Parse a 'Content-Range' header value to its start, end, and total parts\n * @param {String} rawContentRange the raw string to parse from\n * @returns {Object} the parsed parts\n */\nfunction parseContentRange(rawContentRange) {\n  let start;\n  let end;\n  let total;\n\n  if (rawContentRange) {\n    [, start, end, total] = rawContentRange.match(/bytes (\\d+)-(\\d+)\\/(\\d+)/);\n    start = parseInt(start, 10);\n    end = parseInt(end, 10);\n    total = parseInt(total, 10);\n  }\n\n  return { start, end, total };\n}\n\n/**\n * Parses a list of byteranges from the given 'multipart/byteranges' HTTP response.\n * Each item in the list has the following properties:\n * - headers: the HTTP headers\n * - data: the sliced ArrayBuffer for that specific part\n * - offset: the offset of the byterange within its originating file\n * - length: the length of the byterange\n * @param {ArrayBuffer} responseArrayBuffer the response to be parsed and split\n * @param {String} boundary the boundary string used to split the sections\n * @returns {Object[]} the parsed byteranges\n */\nfunction parseByteRanges(responseArrayBuffer, boundary) {\n  let offset = null;\n  const decoder = new TextDecoder('ascii');\n  const out = [];\n\n  const startBoundary = `--${boundary}`;\n  const endBoundary = `${startBoundary}--`;\n\n  // search for the initial boundary, may be offset by some bytes\n  // TODO: more efficient to check for `--` in bytes directly\n  for (let i = 0; i < 10; ++i) {\n    const text = decoder.decode(\n      new Uint8Array(responseArrayBuffer, i, startBoundary.length)\n    );\n    if (text === startBoundary) {\n      offset = i;\n    }\n  }\n\n  if (offset === null) {\n    throw new Error(\"Could not find initial boundary\");\n  }\n\n  while (offset < responseArrayBuffer.byteLength) {\n    const text = decoder.decode(\n      new Uint8Array(responseArrayBuffer, offset,\n        Math.min(startBoundary.length + 1024, responseArrayBuffer.byteLength - offset),\n      ),\n    );\n\n    // break if we arrived at the end\n    if (text.length === 0 || text.startsWith(endBoundary)) {\n      break;\n    }\n\n    // assert that we are actually dealing with a byterange and are at the correct offset\n    if (!text.startsWith(startBoundary)) {\n      throw new Error('Part does not start with boundary');\n    }\n\n    // get a substring from where we read the headers\n    const innerText = text.substr(startBoundary.length + 2);\n\n    if (innerText.length === 0) {\n      break;\n    }\n\n    // find the double linebreak that denotes the end of the headers\n    const endOfHeaders = innerText.indexOf(CRLFCRLF);\n\n    // parse the headers to get the content range size\n    const headers = parseHeaders(innerText.substr(0, endOfHeaders));\n    const { start, end, total } = parseContentRange(headers['content-range']);\n\n    // calculate the length of the slice and the next offset\n    const startOfData = offset + startBoundary.length + endOfHeaders + CRLFCRLF.length;\n    const length = parseInt(end, 10) + 1 - parseInt(start, 10);\n    out.push({\n      headers,\n      data: responseArrayBuffer.slice(startOfData, startOfData + length),\n      offset: start,\n      length,\n      fileSize: total,\n    });\n\n    offset = startOfData + length + 4;\n  }\n\n  return out;\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/source/httputils.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/source/remote.js":
/*!****************************************************!*\
  !*** ../node_modules/geotiff/src/source/remote.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"makeFetchSource\": () => (/* binding */ makeFetchSource),\n/* harmony export */   \"makeXHRSource\": () => (/* binding */ makeXHRSource),\n/* harmony export */   \"makeHttpSource\": () => (/* binding */ makeHttpSource),\n/* harmony export */   \"makeRemoteSource\": () => (/* binding */ makeRemoteSource)\n/* harmony export */ });\n/* harmony import */ var _httputils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./httputils */ \"../node_modules/geotiff/src/source/httputils.js\");\n/* harmony import */ var _basesource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./basesource */ \"../node_modules/geotiff/src/source/basesource.js\");\n/* harmony import */ var _blockedsource__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./blockedsource */ \"../node_modules/geotiff/src/source/blockedsource.js\");\n/* harmony import */ var _client_fetch__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./client/fetch */ \"../node_modules/geotiff/src/source/client/fetch.js\");\n/* harmony import */ var _client_xhr__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./client/xhr */ \"../node_modules/geotiff/src/source/client/xhr.js\");\n/* harmony import */ var _client_http__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./client/http */ \"../node_modules/geotiff/src/source/client/http.js\");\n\n\n\n\n\n\n\n\n\nclass RemoteSource extends _basesource__WEBPACK_IMPORTED_MODULE_1__.BaseSource {\n  /**\n   *\n   * @param {BaseClient} client\n   * @param {object} headers\n   * @param {numbers} maxRanges\n   * @param {boolean} allowFullFile\n   */\n  constructor(client, headers, maxRanges, allowFullFile) {\n    super();\n    this.client = client;\n    this.headers = headers;\n    this.maxRanges = maxRanges;\n    this.allowFullFile = allowFullFile;\n    this._fileSize = null;\n  }\n\n  /**\n   *\n   * @param {Slice[]} slices\n   */\n  async fetch(slices, signal) {\n    // if we allow multi-ranges, split the incoming request into that many sub-requests\n    // and join them afterwards\n    if (this.maxRanges >= slices.length) {\n      return this.fetchSlices(slices, signal);\n    } else if (this.maxRanges > 0 && slices.length > 1) {\n      // TODO: split into multiple multi-range requests\n\n      // const subSlicesRequests = [];\n      // for (let i = 0; i < slices.length; i += this.maxRanges) {\n      //   subSlicesRequests.push(\n      //     this.fetchSlices(slices.slice(i, i + this.maxRanges), signal),\n      //   );\n      // }\n      // return (await Promise.all(subSlicesRequests)).flat();\n    }\n\n    // otherwise make a single request for each slice\n    return await Promise.all(\n      slices.map((slice) => this.fetchSlice(slice, signal)),\n    );\n  }\n\n  async fetchSlices(slices, signal) {\n    const response = await this.client.request({\n      headers: {\n        ...this.headers,\n        Range: `bytes=${slices\n          .map(({ offset, length }) => `${offset}-${offset + length}`)\n          .join(',')\n        }`,\n      },\n      signal,\n    });\n\n    if (!response.ok) {\n      throw new Error('Error fetching data.');\n    } else if (response.status === 206) {\n      const { type, params } = (0,_httputils__WEBPACK_IMPORTED_MODULE_0__.parseContentType)(response.getHeader('content-type'));\n      if (type === 'multipart/byteranges') {\n        const byteRanges = (0,_httputils__WEBPACK_IMPORTED_MODULE_0__.parseByteRanges)(await response.getData(), params.boundary);\n        this._fileSize = byteRanges[0].fileSize || null;\n        return byteRanges;\n      }\n\n      const data = await response.getData();\n\n      const { start, end, total } = (0,_httputils__WEBPACK_IMPORTED_MODULE_0__.parseContentRange)(response.getHeader('content-range'));\n      this._fileSize = total || null;\n      const first = [{\n        data,\n        offset: start,\n        length: end - start,\n      }];\n\n      if (slices.length > 1) {\n        // we requested more than one slice, but got only the first\n        // unfortunately, some HTTP Servers don't support multi-ranges\n        // and return onyl the first\n\n        // get the rest of the slices and fetch them iteratetively\n        const others = await Promise.all(slices.slice(1).map((slice) => this.fetchSlice(slice, signal)));\n        return first.concat(others);\n      }\n      return first;\n    } else {\n      if (!this.allowFullFile) {\n        throw new Error('Server responded with full file');\n      }\n      const data = await response.getData();\n      this._fileSize = data.byteLength;\n      return [{\n        data,\n        offset: 0,\n        length: data.byteLength,\n      }];\n    }\n  }\n\n  async fetchSlice(slice, signal) {\n    const { offset, length } = slice;\n    const response = await this.client.request({\n      headers: {\n        ...this.headers,\n        Range: `bytes=${offset}-${offset + length}`,\n      },\n      signal,\n    });\n\n    // check the response was okay and if the server actually understands range requests\n    if (!response.ok) {\n      throw new Error('Error fetching data.');\n    } else if (response.status === 206) {\n      const data = await response.getData();\n\n      const { total } = (0,_httputils__WEBPACK_IMPORTED_MODULE_0__.parseContentRange)(response.getHeader('content-range'));\n      this._fileSize = total || null;\n      return {\n        data,\n        offset,\n        length,\n      };\n    } else {\n      if (!this.allowFullFile) {\n        throw new Error('Server responded with full file');\n      }\n\n      const data = await response.getData();\n\n      this._fileSize = data.byteLength;\n      return {\n        data,\n        offset: 0,\n        length: data.byteLength,\n      };\n    }\n  }\n\n  get fileSize() {\n    return this._fileSize;\n  }\n}\n\n\nfunction maybeWrapInBlockedSource(source, { blockSize, cacheSize }) {\n  if (blockSize === null) {\n    return source;\n  }\n  return new _blockedsource__WEBPACK_IMPORTED_MODULE_2__.BlockedSource(source, blockSize, cacheSize);\n}\n\nfunction makeFetchSource(url, { headers = {}, credentials, maxRanges = 0, allowFullFile = false, ...blockOptions } = {}) {\n  const client = new _client_fetch__WEBPACK_IMPORTED_MODULE_3__.FetchClient(url, credentials);\n  const source = new RemoteSource(client, headers, maxRanges, allowFullFile);\n  return maybeWrapInBlockedSource(source, blockOptions);\n}\n\nfunction makeXHRSource(url, { headers = {}, maxRanges = 0, allowFullFile = false, ...blockOptions } = {}) {\n  const client = new _client_xhr__WEBPACK_IMPORTED_MODULE_4__.XHRClient(url);\n  const source = new RemoteSource(client, headers, maxRanges, allowFullFile);\n  return maybeWrapInBlockedSource(source, blockOptions);\n}\n\nfunction makeHttpSource(url, { headers = {}, maxRanges = 0, allowFullFile = false, ...blockOptions } = {}) {\n  const client = new _client_http__WEBPACK_IMPORTED_MODULE_5__.HttpClient(url);\n  const source = new RemoteSource(client, headers, maxRanges, allowFullFile);\n  return maybeWrapInBlockedSource(source, blockOptions);\n}\n\n/**\n *\n * @param {string} url\n * @param {object} options\n */\nfunction makeRemoteSource(url, { forceXHR = false, ...clientOptions } = {}) {\n\n  if (typeof fetch === 'function' && !forceXHR) {\n    return makeFetchSource(url, clientOptions);\n  }\n  if (typeof XMLHttpRequest !== 'undefined') {\n    return makeXHRSource(url, clientOptions);\n  }\n  return makeHttpSource(url, clientOptions);\n}\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/source/remote.js?");

/***/ }),

/***/ "../node_modules/geotiff/src/utils.js":
/*!********************************************!*\
  !*** ../node_modules/geotiff/src/utils.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"assign\": () => (/* binding */ assign),\n/* harmony export */   \"chunk\": () => (/* binding */ chunk),\n/* harmony export */   \"endsWith\": () => (/* binding */ endsWith),\n/* harmony export */   \"forEach\": () => (/* binding */ forEach),\n/* harmony export */   \"invert\": () => (/* binding */ invert),\n/* harmony export */   \"range\": () => (/* binding */ range),\n/* harmony export */   \"times\": () => (/* binding */ times),\n/* harmony export */   \"toArray\": () => (/* binding */ toArray),\n/* harmony export */   \"toArrayRecursively\": () => (/* binding */ toArrayRecursively),\n/* harmony export */   \"parseContentRange\": () => (/* binding */ parseContentRange),\n/* harmony export */   \"wait\": () => (/* binding */ wait),\n/* harmony export */   \"zip\": () => (/* binding */ zip),\n/* harmony export */   \"AbortError\": () => (/* binding */ AbortError),\n/* harmony export */   \"CustomAggregateError\": () => (/* binding */ CustomAggregateError),\n/* harmony export */   \"AggregateError\": () => (/* binding */ AggregateError)\n/* harmony export */ });\nfunction assign(target, source) {\n  for (const key in source) {\n    if (source.hasOwnProperty(key)) {\n      target[key] = source[key];\n    }\n  }\n}\n\nfunction chunk(iterable, length) {\n  const results = [];\n  const lengthOfIterable = iterable.length;\n  for (let i = 0; i < lengthOfIterable; i += length) {\n    const chunked = [];\n    for (let ci = i; ci < i + length; ci++) {\n      chunked.push(iterable[ci]);\n    }\n    results.push(chunked);\n  }\n  return results;\n}\n\nfunction endsWith(string, expectedEnding) {\n  if (string.length < expectedEnding.length) {\n    return false;\n  }\n  const actualEnding = string.substr(string.length - expectedEnding.length);\n  return actualEnding === expectedEnding;\n}\n\nfunction forEach(iterable, func) {\n  const { length } = iterable;\n  for (let i = 0; i < length; i++) {\n    func(iterable[i], i);\n  }\n}\n\nfunction invert(oldObj) {\n  const newObj = {};\n  for (const key in oldObj) {\n    if (oldObj.hasOwnProperty(key)) {\n      const value = oldObj[key];\n      newObj[value] = key;\n    }\n  }\n  return newObj;\n}\n\nfunction range(n) {\n  const results = [];\n  for (let i = 0; i < n; i++) {\n    results.push(i);\n  }\n  return results;\n}\n\nfunction times(numTimes, func) {\n  const results = [];\n  for (let i = 0; i < numTimes; i++) {\n    results.push(func(i));\n  }\n  return results;\n}\n\nfunction toArray(iterable) {\n  const results = [];\n  const { length } = iterable;\n  for (let i = 0; i < length; i++) {\n    results.push(iterable[i]);\n  }\n  return results;\n}\n\nfunction toArrayRecursively(input) {\n  if (input.length) {\n    return toArray(input).map(toArrayRecursively);\n  }\n  return input;\n}\n\n// copied from https://github.com/academia-de-codigo/parse-content-range-header/blob/master/index.js\nfunction parseContentRange(headerValue) {\n  if (!headerValue) {\n    return null;\n  }\n\n  if (typeof headerValue !== 'string') {\n    throw new Error('invalid argument');\n  }\n\n  const parseInt = (number) => Number.parseInt(number, 10);\n\n  // Check for presence of unit\n  let matches = headerValue.match(/^(\\w*) /);\n  const unit = matches && matches[1];\n\n  // check for start-end/size header format\n  matches = headerValue.match(/(\\d+)-(\\d+)\\/(\\d+|\\*)/);\n  if (matches) {\n    return {\n      unit,\n      first: parseInt(matches[1]),\n      last: parseInt(matches[2]),\n      length: matches[3] === '*' ? null : parseInt(matches[3]),\n    };\n  }\n\n  // check for size header format\n  matches = headerValue.match(/(\\d+|\\*)/);\n  if (matches) {\n    return {\n      unit,\n      first: null,\n      last: null,\n      length: matches[1] === '*' ? null : parseInt(matches[1]),\n    };\n  }\n\n  return null;\n}\n\n\n/*\n * Promisified wrapper around 'setTimeout' to allow 'await'\n */\nasync function wait(milliseconds) {\n  return new Promise((resolve) => setTimeout(resolve, milliseconds));\n}\n\nfunction zip(a, b) {\n  const A = Array.isArray(a) ? a : Array.from(a);\n  const B = Array.isArray(b) ? b : Array.from(b);\n  return A.map((k, i) => [k, B[i]]);\n}\n\n\n// Based on https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Error\nclass AbortError extends Error {\n  constructor(params) {\n    // Pass remaining arguments (including vendor specific ones) to parent constructor\n    super(params);\n\n    // Maintains proper stack trace for where our error was thrown (only available on V8)\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, AbortError);\n    }\n\n    this.name = 'AbortError';\n  }\n}\n\nclass CustomAggregateError extends Error {\n  constructor(errors, message) {\n    super(message);\n    this.errors = errors;\n    this.message = message;\n    this.name = 'AggregateError';\n  }\n}\n\nconst AggregateError = CustomAggregateError;\n\n\n//# sourceURL=webpack:///../node_modules/geotiff/src/utils.js?");

/***/ }),

/***/ "../node_modules/inherits/inherits_browser.js":
/*!****************************************************!*\
  !*** ../node_modules/inherits/inherits_browser.js ***!
  \****************************************************/
/***/ ((module) => {

eval("if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      ctor.prototype = Object.create(superCtor.prototype, {\n        constructor: {\n          value: ctor,\n          enumerable: false,\n          writable: true,\n          configurable: true\n        }\n      })\n    }\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      var TempCtor = function () {}\n      TempCtor.prototype = superCtor.prototype\n      ctor.prototype = new TempCtor()\n      ctor.prototype.constructor = ctor\n    }\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/inherits/inherits_browser.js?");

/***/ }),

/***/ "../node_modules/is-observable/index.js":
/*!**********************************************!*\
  !*** ../node_modules/is-observable/index.js ***!
  \**********************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = value => {\n\tif (!value) {\n\t\treturn false;\n\t}\n\n\t// eslint-disable-next-line no-use-extend-native/no-use-extend-native\n\tif (typeof Symbol.observable === 'symbol' && typeof value[Symbol.observable] === 'function') {\n\t\t// eslint-disable-next-line no-use-extend-native/no-use-extend-native\n\t\treturn value === value[Symbol.observable]();\n\t}\n\n\tif (typeof value['@@observable'] === 'function') {\n\t\treturn value === value['@@observable']();\n\t}\n\n\treturn false;\n};\n\n\n//# sourceURL=webpack:///../node_modules/is-observable/index.js?");

/***/ }),

/***/ "../node_modules/lru-cache/index.js":
/*!******************************************!*\
  !*** ../node_modules/lru-cache/index.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n// A linked list to keep track of recently-used-ness\nconst Yallist = __webpack_require__(/*! yallist */ \"../node_modules/yallist/yallist.js\")\n\nconst MAX = Symbol('max')\nconst LENGTH = Symbol('length')\nconst LENGTH_CALCULATOR = Symbol('lengthCalculator')\nconst ALLOW_STALE = Symbol('allowStale')\nconst MAX_AGE = Symbol('maxAge')\nconst DISPOSE = Symbol('dispose')\nconst NO_DISPOSE_ON_SET = Symbol('noDisposeOnSet')\nconst LRU_LIST = Symbol('lruList')\nconst CACHE = Symbol('cache')\nconst UPDATE_AGE_ON_GET = Symbol('updateAgeOnGet')\n\nconst naiveLength = () => 1\n\n// lruList is a yallist where the head is the youngest\n// item, and the tail is the oldest.  the list contains the Hit\n// objects as the entries.\n// Each Hit object has a reference to its Yallist.Node.  This\n// never changes.\n//\n// cache is a Map (or PseudoMap) that matches the keys to\n// the Yallist.Node object.\nclass LRUCache {\n  constructor (options) {\n    if (typeof options === 'number')\n      options = { max: options }\n\n    if (!options)\n      options = {}\n\n    if (options.max && (typeof options.max !== 'number' || options.max < 0))\n      throw new TypeError('max must be a non-negative number')\n    // Kind of weird to have a default max of Infinity, but oh well.\n    const max = this[MAX] = options.max || Infinity\n\n    const lc = options.length || naiveLength\n    this[LENGTH_CALCULATOR] = (typeof lc !== 'function') ? naiveLength : lc\n    this[ALLOW_STALE] = options.stale || false\n    if (options.maxAge && typeof options.maxAge !== 'number')\n      throw new TypeError('maxAge must be a number')\n    this[MAX_AGE] = options.maxAge || 0\n    this[DISPOSE] = options.dispose\n    this[NO_DISPOSE_ON_SET] = options.noDisposeOnSet || false\n    this[UPDATE_AGE_ON_GET] = options.updateAgeOnGet || false\n    this.reset()\n  }\n\n  // resize the cache when the max changes.\n  set max (mL) {\n    if (typeof mL !== 'number' || mL < 0)\n      throw new TypeError('max must be a non-negative number')\n\n    this[MAX] = mL || Infinity\n    trim(this)\n  }\n  get max () {\n    return this[MAX]\n  }\n\n  set allowStale (allowStale) {\n    this[ALLOW_STALE] = !!allowStale\n  }\n  get allowStale () {\n    return this[ALLOW_STALE]\n  }\n\n  set maxAge (mA) {\n    if (typeof mA !== 'number')\n      throw new TypeError('maxAge must be a non-negative number')\n\n    this[MAX_AGE] = mA\n    trim(this)\n  }\n  get maxAge () {\n    return this[MAX_AGE]\n  }\n\n  // resize the cache when the lengthCalculator changes.\n  set lengthCalculator (lC) {\n    if (typeof lC !== 'function')\n      lC = naiveLength\n\n    if (lC !== this[LENGTH_CALCULATOR]) {\n      this[LENGTH_CALCULATOR] = lC\n      this[LENGTH] = 0\n      this[LRU_LIST].forEach(hit => {\n        hit.length = this[LENGTH_CALCULATOR](hit.value, hit.key)\n        this[LENGTH] += hit.length\n      })\n    }\n    trim(this)\n  }\n  get lengthCalculator () { return this[LENGTH_CALCULATOR] }\n\n  get length () { return this[LENGTH] }\n  get itemCount () { return this[LRU_LIST].length }\n\n  rforEach (fn, thisp) {\n    thisp = thisp || this\n    for (let walker = this[LRU_LIST].tail; walker !== null;) {\n      const prev = walker.prev\n      forEachStep(this, fn, walker, thisp)\n      walker = prev\n    }\n  }\n\n  forEach (fn, thisp) {\n    thisp = thisp || this\n    for (let walker = this[LRU_LIST].head; walker !== null;) {\n      const next = walker.next\n      forEachStep(this, fn, walker, thisp)\n      walker = next\n    }\n  }\n\n  keys () {\n    return this[LRU_LIST].toArray().map(k => k.key)\n  }\n\n  values () {\n    return this[LRU_LIST].toArray().map(k => k.value)\n  }\n\n  reset () {\n    if (this[DISPOSE] &&\n        this[LRU_LIST] &&\n        this[LRU_LIST].length) {\n      this[LRU_LIST].forEach(hit => this[DISPOSE](hit.key, hit.value))\n    }\n\n    this[CACHE] = new Map() // hash of items by key\n    this[LRU_LIST] = new Yallist() // list of items in order of use recency\n    this[LENGTH] = 0 // length of items in the list\n  }\n\n  dump () {\n    return this[LRU_LIST].map(hit =>\n      isStale(this, hit) ? false : {\n        k: hit.key,\n        v: hit.value,\n        e: hit.now + (hit.maxAge || 0)\n      }).toArray().filter(h => h)\n  }\n\n  dumpLru () {\n    return this[LRU_LIST]\n  }\n\n  set (key, value, maxAge) {\n    maxAge = maxAge || this[MAX_AGE]\n\n    if (maxAge && typeof maxAge !== 'number')\n      throw new TypeError('maxAge must be a number')\n\n    const now = maxAge ? Date.now() : 0\n    const len = this[LENGTH_CALCULATOR](value, key)\n\n    if (this[CACHE].has(key)) {\n      if (len > this[MAX]) {\n        del(this, this[CACHE].get(key))\n        return false\n      }\n\n      const node = this[CACHE].get(key)\n      const item = node.value\n\n      // dispose of the old one before overwriting\n      // split out into 2 ifs for better coverage tracking\n      if (this[DISPOSE]) {\n        if (!this[NO_DISPOSE_ON_SET])\n          this[DISPOSE](key, item.value)\n      }\n\n      item.now = now\n      item.maxAge = maxAge\n      item.value = value\n      this[LENGTH] += len - item.length\n      item.length = len\n      this.get(key)\n      trim(this)\n      return true\n    }\n\n    const hit = new Entry(key, value, len, now, maxAge)\n\n    // oversized objects fall out of cache automatically.\n    if (hit.length > this[MAX]) {\n      if (this[DISPOSE])\n        this[DISPOSE](key, value)\n\n      return false\n    }\n\n    this[LENGTH] += hit.length\n    this[LRU_LIST].unshift(hit)\n    this[CACHE].set(key, this[LRU_LIST].head)\n    trim(this)\n    return true\n  }\n\n  has (key) {\n    if (!this[CACHE].has(key)) return false\n    const hit = this[CACHE].get(key).value\n    return !isStale(this, hit)\n  }\n\n  get (key) {\n    return get(this, key, true)\n  }\n\n  peek (key) {\n    return get(this, key, false)\n  }\n\n  pop () {\n    const node = this[LRU_LIST].tail\n    if (!node)\n      return null\n\n    del(this, node)\n    return node.value\n  }\n\n  del (key) {\n    del(this, this[CACHE].get(key))\n  }\n\n  load (arr) {\n    // reset the cache\n    this.reset()\n\n    const now = Date.now()\n    // A previous serialized cache has the most recent items first\n    for (let l = arr.length - 1; l >= 0; l--) {\n      const hit = arr[l]\n      const expiresAt = hit.e || 0\n      if (expiresAt === 0)\n        // the item was created without expiration in a non aged cache\n        this.set(hit.k, hit.v)\n      else {\n        const maxAge = expiresAt - now\n        // dont add already expired items\n        if (maxAge > 0) {\n          this.set(hit.k, hit.v, maxAge)\n        }\n      }\n    }\n  }\n\n  prune () {\n    this[CACHE].forEach((value, key) => get(this, key, false))\n  }\n}\n\nconst get = (self, key, doUse) => {\n  const node = self[CACHE].get(key)\n  if (node) {\n    const hit = node.value\n    if (isStale(self, hit)) {\n      del(self, node)\n      if (!self[ALLOW_STALE])\n        return undefined\n    } else {\n      if (doUse) {\n        if (self[UPDATE_AGE_ON_GET])\n          node.value.now = Date.now()\n        self[LRU_LIST].unshiftNode(node)\n      }\n    }\n    return hit.value\n  }\n}\n\nconst isStale = (self, hit) => {\n  if (!hit || (!hit.maxAge && !self[MAX_AGE]))\n    return false\n\n  const diff = Date.now() - hit.now\n  return hit.maxAge ? diff > hit.maxAge\n    : self[MAX_AGE] && (diff > self[MAX_AGE])\n}\n\nconst trim = self => {\n  if (self[LENGTH] > self[MAX]) {\n    for (let walker = self[LRU_LIST].tail;\n      self[LENGTH] > self[MAX] && walker !== null;) {\n      // We know that we're about to delete this one, and also\n      // what the next least recently used key will be, so just\n      // go ahead and set it now.\n      const prev = walker.prev\n      del(self, walker)\n      walker = prev\n    }\n  }\n}\n\nconst del = (self, node) => {\n  if (node) {\n    const hit = node.value\n    if (self[DISPOSE])\n      self[DISPOSE](hit.key, hit.value)\n\n    self[LENGTH] -= hit.length\n    self[CACHE].delete(hit.key)\n    self[LRU_LIST].removeNode(node)\n  }\n}\n\nclass Entry {\n  constructor (key, value, length, now, maxAge) {\n    this.key = key\n    this.value = value\n    this.length = length\n    this.now = now\n    this.maxAge = maxAge || 0\n  }\n}\n\nconst forEachStep = (self, fn, node, thisp) => {\n  let hit = node.value\n  if (isStale(self, hit)) {\n    del(self, node)\n    if (!self[ALLOW_STALE])\n      hit = undefined\n  }\n  if (hit)\n    fn.call(thisp, hit.value, hit.key, self)\n}\n\nmodule.exports = LRUCache\n\n\n//# sourceURL=webpack:///../node_modules/lru-cache/index.js?");

/***/ }),

/***/ "../node_modules/ms/index.js":
/*!***********************************!*\
  !*** ../node_modules/ms/index.js ***!
  \***********************************/
/***/ ((module) => {

eval("/**\n * Helpers.\n */\n\nvar s = 1000;\nvar m = s * 60;\nvar h = m * 60;\nvar d = h * 24;\nvar w = d * 7;\nvar y = d * 365.25;\n\n/**\n * Parse or format the given `val`.\n *\n * Options:\n *\n *  - `long` verbose formatting [false]\n *\n * @param {String|Number} val\n * @param {Object} [options]\n * @throws {Error} throw an error if val is not a non-empty string or a number\n * @return {String|Number}\n * @api public\n */\n\nmodule.exports = function(val, options) {\n  options = options || {};\n  var type = typeof val;\n  if (type === 'string' && val.length > 0) {\n    return parse(val);\n  } else if (type === 'number' && isFinite(val)) {\n    return options.long ? fmtLong(val) : fmtShort(val);\n  }\n  throw new Error(\n    'val is not a non-empty string or a valid number. val=' +\n      JSON.stringify(val)\n  );\n};\n\n/**\n * Parse the given `str` and return milliseconds.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction parse(str) {\n  str = String(str);\n  if (str.length > 100) {\n    return;\n  }\n  var match = /^(-?(?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(\n    str\n  );\n  if (!match) {\n    return;\n  }\n  var n = parseFloat(match[1]);\n  var type = (match[2] || 'ms').toLowerCase();\n  switch (type) {\n    case 'years':\n    case 'year':\n    case 'yrs':\n    case 'yr':\n    case 'y':\n      return n * y;\n    case 'weeks':\n    case 'week':\n    case 'w':\n      return n * w;\n    case 'days':\n    case 'day':\n    case 'd':\n      return n * d;\n    case 'hours':\n    case 'hour':\n    case 'hrs':\n    case 'hr':\n    case 'h':\n      return n * h;\n    case 'minutes':\n    case 'minute':\n    case 'mins':\n    case 'min':\n    case 'm':\n      return n * m;\n    case 'seconds':\n    case 'second':\n    case 'secs':\n    case 'sec':\n    case 's':\n      return n * s;\n    case 'milliseconds':\n    case 'millisecond':\n    case 'msecs':\n    case 'msec':\n    case 'ms':\n      return n;\n    default:\n      return undefined;\n  }\n}\n\n/**\n * Short format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtShort(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return Math.round(ms / d) + 'd';\n  }\n  if (msAbs >= h) {\n    return Math.round(ms / h) + 'h';\n  }\n  if (msAbs >= m) {\n    return Math.round(ms / m) + 'm';\n  }\n  if (msAbs >= s) {\n    return Math.round(ms / s) + 's';\n  }\n  return ms + 'ms';\n}\n\n/**\n * Long format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtLong(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return plural(ms, msAbs, d, 'day');\n  }\n  if (msAbs >= h) {\n    return plural(ms, msAbs, h, 'hour');\n  }\n  if (msAbs >= m) {\n    return plural(ms, msAbs, m, 'minute');\n  }\n  if (msAbs >= s) {\n    return plural(ms, msAbs, s, 'second');\n  }\n  return ms + ' ms';\n}\n\n/**\n * Pluralization helper.\n */\n\nfunction plural(ms, msAbs, n, name) {\n  var isPlural = msAbs >= n * 1.5;\n  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');\n}\n\n\n//# sourceURL=webpack:///../node_modules/ms/index.js?");

/***/ }),

/***/ "../node_modules/observable-fns/dist.esm/_scheduler.js":
/*!*************************************************************!*\
  !*** ../node_modules/observable-fns/dist.esm/_scheduler.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AsyncSerialScheduler\": () => (/* binding */ AsyncSerialScheduler)\n/* harmony export */ });\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nclass AsyncSerialScheduler {\n    constructor(observer) {\n        this._baseObserver = observer;\n        this._pendingPromises = new Set();\n    }\n    complete() {\n        Promise.all(this._pendingPromises)\n            .then(() => this._baseObserver.complete())\n            .catch(error => this._baseObserver.error(error));\n    }\n    error(error) {\n        this._baseObserver.error(error);\n    }\n    schedule(task) {\n        const prevPromisesCompletion = Promise.all(this._pendingPromises);\n        const values = [];\n        const next = (value) => values.push(value);\n        const promise = Promise.resolve()\n            .then(() => __awaiter(this, void 0, void 0, function* () {\n            yield prevPromisesCompletion;\n            yield task(next);\n            this._pendingPromises.delete(promise);\n            for (const value of values) {\n                this._baseObserver.next(value);\n            }\n        }))\n            .catch(error => {\n            this._pendingPromises.delete(promise);\n            this._baseObserver.error(error);\n        });\n        this._pendingPromises.add(promise);\n    }\n}\n\n\n//# sourceURL=webpack:///../node_modules/observable-fns/dist.esm/_scheduler.js?");

/***/ }),

/***/ "../node_modules/observable-fns/dist.esm/_symbols.js":
/*!***********************************************************!*\
  !*** ../node_modules/observable-fns/dist.esm/_symbols.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"hasSymbols\": () => (/* binding */ hasSymbols),\n/* harmony export */   \"hasSymbol\": () => (/* binding */ hasSymbol),\n/* harmony export */   \"getSymbol\": () => (/* binding */ getSymbol),\n/* harmony export */   \"registerObservableSymbol\": () => (/* binding */ registerObservableSymbol)\n/* harmony export */ });\nconst hasSymbols = () => typeof Symbol === \"function\";\nconst hasSymbol = (name) => hasSymbols() && Boolean(Symbol[name]);\nconst getSymbol = (name) => hasSymbol(name) ? Symbol[name] : \"@@\" + name;\nfunction registerObservableSymbol() {\n    if (hasSymbols() && !hasSymbol(\"observable\")) {\n        Symbol.observable = Symbol(\"observable\");\n    }\n}\nif (!hasSymbol(\"asyncIterator\")) {\n    Symbol.asyncIterator = Symbol.asyncIterator || Symbol.for(\"Symbol.asyncIterator\");\n}\n\n\n//# sourceURL=webpack:///../node_modules/observable-fns/dist.esm/_symbols.js?");

/***/ }),

/***/ "../node_modules/observable-fns/dist.esm/_util.js":
/*!********************************************************!*\
  !*** ../node_modules/observable-fns/dist.esm/_util.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isAsyncIterator\": () => (/* binding */ isAsyncIterator),\n/* harmony export */   \"isIterator\": () => (/* binding */ isIterator)\n/* harmony export */ });\n/* harmony import */ var _symbols__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./_symbols */ \"../node_modules/observable-fns/dist.esm/_symbols.js\");\n/// <reference lib=\"es2018\" />\n\nfunction isAsyncIterator(thing) {\n    return thing && (0,_symbols__WEBPACK_IMPORTED_MODULE_0__.hasSymbol)(\"asyncIterator\") && thing[Symbol.asyncIterator];\n}\nfunction isIterator(thing) {\n    return thing && (0,_symbols__WEBPACK_IMPORTED_MODULE_0__.hasSymbol)(\"iterator\") && thing[Symbol.iterator];\n}\n\n\n//# sourceURL=webpack:///../node_modules/observable-fns/dist.esm/_util.js?");

/***/ }),

/***/ "../node_modules/observable-fns/dist.esm/filter.js":
/*!*********************************************************!*\
  !*** ../node_modules/observable-fns/dist.esm/filter.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _scheduler__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./_scheduler */ \"../node_modules/observable-fns/dist.esm/_scheduler.js\");\n/* harmony import */ var _observable__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./observable */ \"../node_modules/observable-fns/dist.esm/observable.js\");\n/* harmony import */ var _unsubscribe__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./unsubscribe */ \"../node_modules/observable-fns/dist.esm/unsubscribe.js\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n/**\n * Filters the values emitted by another observable.\n * To be applied to an input observable using `pipe()`.\n */\nfunction filter(test) {\n    return (observable) => {\n        return new _observable__WEBPACK_IMPORTED_MODULE_0__.default(observer => {\n            const scheduler = new _scheduler__WEBPACK_IMPORTED_MODULE_1__.AsyncSerialScheduler(observer);\n            const subscription = observable.subscribe({\n                complete() {\n                    scheduler.complete();\n                },\n                error(error) {\n                    scheduler.error(error);\n                },\n                next(input) {\n                    scheduler.schedule((next) => __awaiter(this, void 0, void 0, function* () {\n                        if (yield test(input)) {\n                            next(input);\n                        }\n                    }));\n                }\n            });\n            return () => (0,_unsubscribe__WEBPACK_IMPORTED_MODULE_2__.default)(subscription);\n        });\n    };\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (filter);\n\n\n//# sourceURL=webpack:///../node_modules/observable-fns/dist.esm/filter.js?");

/***/ }),

/***/ "../node_modules/observable-fns/dist.esm/flatMap.js":
/*!**********************************************************!*\
  !*** ../node_modules/observable-fns/dist.esm/flatMap.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _scheduler__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./_scheduler */ \"../node_modules/observable-fns/dist.esm/_scheduler.js\");\n/* harmony import */ var _util__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./_util */ \"../node_modules/observable-fns/dist.esm/_util.js\");\n/* harmony import */ var _observable__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./observable */ \"../node_modules/observable-fns/dist.esm/observable.js\");\n/* harmony import */ var _unsubscribe__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./unsubscribe */ \"../node_modules/observable-fns/dist.esm/unsubscribe.js\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __asyncValues = (undefined && undefined.__asyncValues) || function (o) {\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n    var m = o[Symbol.asyncIterator], i;\n    return m ? m.call(o) : (o = typeof __values === \"function\" ? __values(o) : o[Symbol.iterator](), i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i);\n    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }\n    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }\n};\n\n\n\n\n/**\n * Maps the values emitted by another observable. In contrast to `map()`\n * the `mapper` function returns an array of values that will be emitted\n * separately.\n * Use `flatMap()` to map input values to zero, one or multiple output\n * values. To be applied to an input observable using `pipe()`.\n */\nfunction flatMap(mapper) {\n    return (observable) => {\n        return new _observable__WEBPACK_IMPORTED_MODULE_0__.default(observer => {\n            const scheduler = new _scheduler__WEBPACK_IMPORTED_MODULE_1__.AsyncSerialScheduler(observer);\n            const subscription = observable.subscribe({\n                complete() {\n                    scheduler.complete();\n                },\n                error(error) {\n                    scheduler.error(error);\n                },\n                next(input) {\n                    scheduler.schedule((next) => __awaiter(this, void 0, void 0, function* () {\n                        var e_1, _a;\n                        const mapped = yield mapper(input);\n                        if ((0,_util__WEBPACK_IMPORTED_MODULE_2__.isIterator)(mapped) || (0,_util__WEBPACK_IMPORTED_MODULE_2__.isAsyncIterator)(mapped)) {\n                            try {\n                                for (var mapped_1 = __asyncValues(mapped), mapped_1_1; mapped_1_1 = yield mapped_1.next(), !mapped_1_1.done;) {\n                                    const element = mapped_1_1.value;\n                                    next(element);\n                                }\n                            }\n                            catch (e_1_1) { e_1 = { error: e_1_1 }; }\n                            finally {\n                                try {\n                                    if (mapped_1_1 && !mapped_1_1.done && (_a = mapped_1.return)) yield _a.call(mapped_1);\n                                }\n                                finally { if (e_1) throw e_1.error; }\n                            }\n                        }\n                        else {\n                            mapped.map(output => next(output));\n                        }\n                    }));\n                }\n            });\n            return () => (0,_unsubscribe__WEBPACK_IMPORTED_MODULE_3__.default)(subscription);\n        });\n    };\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (flatMap);\n\n\n//# sourceURL=webpack:///../node_modules/observable-fns/dist.esm/flatMap.js?");

/***/ }),

/***/ "../node_modules/observable-fns/dist.esm/index.js":
/*!********************************************************!*\
  !*** ../node_modules/observable-fns/dist.esm/index.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"filter\": () => (/* reexport safe */ _filter__WEBPACK_IMPORTED_MODULE_0__.default),\n/* harmony export */   \"flatMap\": () => (/* reexport safe */ _flatMap__WEBPACK_IMPORTED_MODULE_1__.default),\n/* harmony export */   \"interval\": () => (/* reexport safe */ _interval__WEBPACK_IMPORTED_MODULE_2__.default),\n/* harmony export */   \"map\": () => (/* reexport safe */ _map__WEBPACK_IMPORTED_MODULE_3__.default),\n/* harmony export */   \"merge\": () => (/* reexport safe */ _merge__WEBPACK_IMPORTED_MODULE_4__.default),\n/* harmony export */   \"multicast\": () => (/* reexport safe */ _multicast__WEBPACK_IMPORTED_MODULE_5__.default),\n/* harmony export */   \"Observable\": () => (/* reexport safe */ _observable__WEBPACK_IMPORTED_MODULE_6__.default),\n/* harmony export */   \"scan\": () => (/* reexport safe */ _scan__WEBPACK_IMPORTED_MODULE_7__.default),\n/* harmony export */   \"Subject\": () => (/* reexport safe */ _subject__WEBPACK_IMPORTED_MODULE_8__.default),\n/* harmony export */   \"unsubscribe\": () => (/* reexport safe */ _unsubscribe__WEBPACK_IMPORTED_MODULE_9__.default)\n/* harmony export */ });\n/* harmony import */ var _filter__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./filter */ \"../node_modules/observable-fns/dist.esm/filter.js\");\n/* harmony import */ var _flatMap__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./flatMap */ \"../node_modules/observable-fns/dist.esm/flatMap.js\");\n/* harmony import */ var _interval__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./interval */ \"../node_modules/observable-fns/dist.esm/interval.js\");\n/* harmony import */ var _map__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./map */ \"../node_modules/observable-fns/dist.esm/map.js\");\n/* harmony import */ var _merge__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./merge */ \"../node_modules/observable-fns/dist.esm/merge.js\");\n/* harmony import */ var _multicast__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./multicast */ \"../node_modules/observable-fns/dist.esm/multicast.js\");\n/* harmony import */ var _observable__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./observable */ \"../node_modules/observable-fns/dist.esm/observable.js\");\n/* harmony import */ var _scan__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./scan */ \"../node_modules/observable-fns/dist.esm/scan.js\");\n/* harmony import */ var _subject__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./subject */ \"../node_modules/observable-fns/dist.esm/subject.js\");\n/* harmony import */ var _unsubscribe__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./unsubscribe */ \"../node_modules/observable-fns/dist.esm/unsubscribe.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceURL=webpack:///../node_modules/observable-fns/dist.esm/index.js?");

/***/ }),

/***/ "../node_modules/observable-fns/dist.esm/interval.js":
/*!***********************************************************!*\
  !*** ../node_modules/observable-fns/dist.esm/interval.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ interval)\n/* harmony export */ });\n/* harmony import */ var _observable__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./observable */ \"../node_modules/observable-fns/dist.esm/observable.js\");\n\n/**\n * Creates an observable that yields a new value every `period` milliseconds.\n * The first value emitted is 0, then 1, 2, etc. The first value is not emitted\n * immediately, but after the first interval.\n */\nfunction interval(period) {\n    return new _observable__WEBPACK_IMPORTED_MODULE_0__.Observable(observer => {\n        let counter = 0;\n        const handle = setInterval(() => {\n            observer.next(counter++);\n        }, period);\n        return () => clearInterval(handle);\n    });\n}\n\n\n//# sourceURL=webpack:///../node_modules/observable-fns/dist.esm/interval.js?");

/***/ }),

/***/ "../node_modules/observable-fns/dist.esm/map.js":
/*!******************************************************!*\
  !*** ../node_modules/observable-fns/dist.esm/map.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _scheduler__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./_scheduler */ \"../node_modules/observable-fns/dist.esm/_scheduler.js\");\n/* harmony import */ var _observable__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./observable */ \"../node_modules/observable-fns/dist.esm/observable.js\");\n/* harmony import */ var _unsubscribe__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./unsubscribe */ \"../node_modules/observable-fns/dist.esm/unsubscribe.js\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n/**\n * Maps the values emitted by another observable to different values.\n * To be applied to an input observable using `pipe()`.\n */\nfunction map(mapper) {\n    return (observable) => {\n        return new _observable__WEBPACK_IMPORTED_MODULE_0__.default(observer => {\n            const scheduler = new _scheduler__WEBPACK_IMPORTED_MODULE_1__.AsyncSerialScheduler(observer);\n            const subscription = observable.subscribe({\n                complete() {\n                    scheduler.complete();\n                },\n                error(error) {\n                    scheduler.error(error);\n                },\n                next(input) {\n                    scheduler.schedule((next) => __awaiter(this, void 0, void 0, function* () {\n                        const mapped = yield mapper(input);\n                        next(mapped);\n                    }));\n                }\n            });\n            return () => (0,_unsubscribe__WEBPACK_IMPORTED_MODULE_2__.default)(subscription);\n        });\n    };\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (map);\n\n\n//# sourceURL=webpack:///../node_modules/observable-fns/dist.esm/map.js?");

/***/ }),

/***/ "../node_modules/observable-fns/dist.esm/merge.js":
/*!********************************************************!*\
  !*** ../node_modules/observable-fns/dist.esm/merge.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _observable__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./observable */ \"../node_modules/observable-fns/dist.esm/observable.js\");\n/* harmony import */ var _unsubscribe__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./unsubscribe */ \"../node_modules/observable-fns/dist.esm/unsubscribe.js\");\n\n\nfunction merge(...observables) {\n    if (observables.length === 0) {\n        return _observable__WEBPACK_IMPORTED_MODULE_0__.Observable.from([]);\n    }\n    return new _observable__WEBPACK_IMPORTED_MODULE_0__.Observable(observer => {\n        let completed = 0;\n        const subscriptions = observables.map(input => {\n            return input.subscribe({\n                error(error) {\n                    observer.error(error);\n                    unsubscribeAll();\n                },\n                next(value) {\n                    observer.next(value);\n                },\n                complete() {\n                    if (++completed === observables.length) {\n                        observer.complete();\n                        unsubscribeAll();\n                    }\n                }\n            });\n        });\n        const unsubscribeAll = () => {\n            subscriptions.forEach(subscription => (0,_unsubscribe__WEBPACK_IMPORTED_MODULE_1__.default)(subscription));\n        };\n        return unsubscribeAll;\n    });\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (merge);\n\n\n//# sourceURL=webpack:///../node_modules/observable-fns/dist.esm/merge.js?");

/***/ }),

/***/ "../node_modules/observable-fns/dist.esm/multicast.js":
/*!************************************************************!*\
  !*** ../node_modules/observable-fns/dist.esm/multicast.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _observable__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./observable */ \"../node_modules/observable-fns/dist.esm/observable.js\");\n/* harmony import */ var _subject__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./subject */ \"../node_modules/observable-fns/dist.esm/subject.js\");\n/* harmony import */ var _unsubscribe__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./unsubscribe */ \"../node_modules/observable-fns/dist.esm/unsubscribe.js\");\n\n\n\n// TODO: Subject already creates additional observables \"under the hood\",\n//       now we introduce even more. A true native MulticastObservable\n//       would be preferable.\n/**\n * Takes a \"cold\" observable and returns a wrapping \"hot\" observable that\n * proxies the input observable's values and errors.\n *\n * An observable is called \"cold\" when its initialization function is run\n * for each new subscriber. This is how observable-fns's `Observable`\n * implementation works.\n *\n * A hot observable is an observable where new subscribers subscribe to\n * the upcoming values of an already-initialiazed observable.\n *\n * The multicast observable will lazily subscribe to the source observable\n * once it has its first own subscriber and will unsubscribe from the\n * source observable when its last own subscriber unsubscribed.\n */\nfunction multicast(coldObservable) {\n    const subject = new _subject__WEBPACK_IMPORTED_MODULE_0__.default();\n    let sourceSubscription;\n    let subscriberCount = 0;\n    return new _observable__WEBPACK_IMPORTED_MODULE_1__.default(observer => {\n        // Init source subscription lazily\n        if (!sourceSubscription) {\n            sourceSubscription = coldObservable.subscribe(subject);\n        }\n        // Pipe all events from `subject` into this observable\n        const subscription = subject.subscribe(observer);\n        subscriberCount++;\n        return () => {\n            subscriberCount--;\n            subscription.unsubscribe();\n            // Close source subscription once last subscriber has unsubscribed\n            if (subscriberCount === 0) {\n                (0,_unsubscribe__WEBPACK_IMPORTED_MODULE_2__.default)(sourceSubscription);\n                sourceSubscription = undefined;\n            }\n        };\n    });\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (multicast);\n\n\n//# sourceURL=webpack:///../node_modules/observable-fns/dist.esm/multicast.js?");

/***/ }),

/***/ "../node_modules/observable-fns/dist.esm/observable.js":
/*!*************************************************************!*\
  !*** ../node_modules/observable-fns/dist.esm/observable.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Subscription\": () => (/* binding */ Subscription),\n/* harmony export */   \"SubscriptionObserver\": () => (/* binding */ SubscriptionObserver),\n/* harmony export */   \"Observable\": () => (/* binding */ Observable),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _symbols__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./_symbols */ \"../node_modules/observable-fns/dist.esm/_symbols.js\");\n/**\n * Based on <https://raw.githubusercontent.com/zenparsing/zen-observable/master/src/Observable.js>\n * At commit: f63849a8c60af5d514efc8e9d6138d8273c49ad6\n */\n\n\nconst SymbolIterator = (0,_symbols__WEBPACK_IMPORTED_MODULE_0__.getSymbol)(\"iterator\");\nconst SymbolObservable = (0,_symbols__WEBPACK_IMPORTED_MODULE_0__.getSymbol)(\"observable\");\nconst SymbolSpecies = (0,_symbols__WEBPACK_IMPORTED_MODULE_0__.getSymbol)(\"species\");\n// === Abstract Operations ===\nfunction getMethod(obj, key) {\n    const value = obj[key];\n    if (value == null) {\n        return undefined;\n    }\n    if (typeof value !== \"function\") {\n        throw new TypeError(value + \" is not a function\");\n    }\n    return value;\n}\nfunction getSpecies(obj) {\n    let ctor = obj.constructor;\n    if (ctor !== undefined) {\n        ctor = ctor[SymbolSpecies];\n        if (ctor === null) {\n            ctor = undefined;\n        }\n    }\n    return ctor !== undefined ? ctor : Observable;\n}\nfunction isObservable(x) {\n    return x instanceof Observable; // SPEC: Brand check\n}\nfunction hostReportError(error) {\n    if (hostReportError.log) {\n        hostReportError.log(error);\n    }\n    else {\n        setTimeout(() => { throw error; }, 0);\n    }\n}\nfunction enqueue(fn) {\n    Promise.resolve().then(() => {\n        try {\n            fn();\n        }\n        catch (e) {\n            hostReportError(e);\n        }\n    });\n}\nfunction cleanupSubscription(subscription) {\n    const cleanup = subscription._cleanup;\n    if (cleanup === undefined) {\n        return;\n    }\n    subscription._cleanup = undefined;\n    if (!cleanup) {\n        return;\n    }\n    try {\n        if (typeof cleanup === \"function\") {\n            cleanup();\n        }\n        else {\n            const unsubscribe = getMethod(cleanup, \"unsubscribe\");\n            if (unsubscribe) {\n                unsubscribe.call(cleanup);\n            }\n        }\n    }\n    catch (e) {\n        hostReportError(e);\n    }\n}\nfunction closeSubscription(subscription) {\n    subscription._observer = undefined;\n    subscription._queue = undefined;\n    subscription._state = \"closed\";\n}\nfunction flushSubscription(subscription) {\n    const queue = subscription._queue;\n    if (!queue) {\n        return;\n    }\n    subscription._queue = undefined;\n    subscription._state = \"ready\";\n    for (const item of queue) {\n        notifySubscription(subscription, item.type, item.value);\n        if (subscription._state === \"closed\") {\n            break;\n        }\n    }\n}\nfunction notifySubscription(subscription, type, value) {\n    subscription._state = \"running\";\n    const observer = subscription._observer;\n    try {\n        const m = observer ? getMethod(observer, type) : undefined;\n        switch (type) {\n            case \"next\":\n                if (m)\n                    m.call(observer, value);\n                break;\n            case \"error\":\n                closeSubscription(subscription);\n                if (m)\n                    m.call(observer, value);\n                else\n                    throw value;\n                break;\n            case \"complete\":\n                closeSubscription(subscription);\n                if (m)\n                    m.call(observer);\n                break;\n        }\n    }\n    catch (e) {\n        hostReportError(e);\n    }\n    if (subscription._state === \"closed\") {\n        cleanupSubscription(subscription);\n    }\n    else if (subscription._state === \"running\") {\n        subscription._state = \"ready\";\n    }\n}\nfunction onNotify(subscription, type, value) {\n    if (subscription._state === \"closed\") {\n        return;\n    }\n    if (subscription._state === \"buffering\") {\n        subscription._queue = subscription._queue || [];\n        subscription._queue.push({ type, value });\n        return;\n    }\n    if (subscription._state !== \"ready\") {\n        subscription._state = \"buffering\";\n        subscription._queue = [{ type, value }];\n        enqueue(() => flushSubscription(subscription));\n        return;\n    }\n    notifySubscription(subscription, type, value);\n}\nclass Subscription {\n    constructor(observer, subscriber) {\n        // ASSERT: observer is an object\n        // ASSERT: subscriber is callable\n        this._cleanup = undefined;\n        this._observer = observer;\n        this._queue = undefined;\n        this._state = \"initializing\";\n        const subscriptionObserver = new SubscriptionObserver(this);\n        try {\n            this._cleanup = subscriber.call(undefined, subscriptionObserver);\n        }\n        catch (e) {\n            subscriptionObserver.error(e);\n        }\n        if (this._state === \"initializing\") {\n            this._state = \"ready\";\n        }\n    }\n    get closed() {\n        return this._state === \"closed\";\n    }\n    unsubscribe() {\n        if (this._state !== \"closed\") {\n            closeSubscription(this);\n            cleanupSubscription(this);\n        }\n    }\n}\nclass SubscriptionObserver {\n    constructor(subscription) { this._subscription = subscription; }\n    get closed() { return this._subscription._state === \"closed\"; }\n    next(value) { onNotify(this._subscription, \"next\", value); }\n    error(value) { onNotify(this._subscription, \"error\", value); }\n    complete() { onNotify(this._subscription, \"complete\"); }\n}\n/**\n * The basic Observable class. This primitive is used to wrap asynchronous\n * data streams in a common standardized data type that is interoperable\n * between libraries and can be composed to represent more complex processes.\n */\nclass Observable {\n    constructor(subscriber) {\n        if (!(this instanceof Observable)) {\n            throw new TypeError(\"Observable cannot be called as a function\");\n        }\n        if (typeof subscriber !== \"function\") {\n            throw new TypeError(\"Observable initializer must be a function\");\n        }\n        this._subscriber = subscriber;\n    }\n    subscribe(nextOrObserver, onError, onComplete) {\n        if (typeof nextOrObserver !== \"object\" || nextOrObserver === null) {\n            nextOrObserver = {\n                next: nextOrObserver,\n                error: onError,\n                complete: onComplete\n            };\n        }\n        return new Subscription(nextOrObserver, this._subscriber);\n    }\n    pipe(first, ...mappers) {\n        // tslint:disable-next-line no-this-assignment\n        let intermediate = this;\n        for (const mapper of [first, ...mappers]) {\n            intermediate = mapper(intermediate);\n        }\n        return intermediate;\n    }\n    tap(nextOrObserver, onError, onComplete) {\n        const tapObserver = typeof nextOrObserver !== \"object\" || nextOrObserver === null\n            ? {\n                next: nextOrObserver,\n                error: onError,\n                complete: onComplete\n            }\n            : nextOrObserver;\n        return new Observable(observer => {\n            return this.subscribe({\n                next(value) {\n                    tapObserver.next && tapObserver.next(value);\n                    observer.next(value);\n                },\n                error(error) {\n                    tapObserver.error && tapObserver.error(error);\n                    observer.error(error);\n                },\n                complete() {\n                    tapObserver.complete && tapObserver.complete();\n                    observer.complete();\n                },\n                start(subscription) {\n                    tapObserver.start && tapObserver.start(subscription);\n                }\n            });\n        });\n    }\n    forEach(fn) {\n        return new Promise((resolve, reject) => {\n            if (typeof fn !== \"function\") {\n                reject(new TypeError(fn + \" is not a function\"));\n                return;\n            }\n            function done() {\n                subscription.unsubscribe();\n                resolve(undefined);\n            }\n            const subscription = this.subscribe({\n                next(value) {\n                    try {\n                        fn(value, done);\n                    }\n                    catch (e) {\n                        reject(e);\n                        subscription.unsubscribe();\n                    }\n                },\n                error(error) {\n                    reject(error);\n                },\n                complete() {\n                    resolve(undefined);\n                }\n            });\n        });\n    }\n    map(fn) {\n        if (typeof fn !== \"function\") {\n            throw new TypeError(fn + \" is not a function\");\n        }\n        const C = getSpecies(this);\n        return new C(observer => this.subscribe({\n            next(value) {\n                let propagatedValue = value;\n                try {\n                    propagatedValue = fn(value);\n                }\n                catch (e) {\n                    return observer.error(e);\n                }\n                observer.next(propagatedValue);\n            },\n            error(e) { observer.error(e); },\n            complete() { observer.complete(); },\n        }));\n    }\n    filter(fn) {\n        if (typeof fn !== \"function\") {\n            throw new TypeError(fn + \" is not a function\");\n        }\n        const C = getSpecies(this);\n        return new C(observer => this.subscribe({\n            next(value) {\n                try {\n                    if (!fn(value))\n                        return;\n                }\n                catch (e) {\n                    return observer.error(e);\n                }\n                observer.next(value);\n            },\n            error(e) { observer.error(e); },\n            complete() { observer.complete(); },\n        }));\n    }\n    reduce(fn, seed) {\n        if (typeof fn !== \"function\") {\n            throw new TypeError(fn + \" is not a function\");\n        }\n        const C = getSpecies(this);\n        const hasSeed = arguments.length > 1;\n        let hasValue = false;\n        let acc = seed;\n        return new C(observer => this.subscribe({\n            next(value) {\n                const first = !hasValue;\n                hasValue = true;\n                if (!first || hasSeed) {\n                    try {\n                        acc = fn(acc, value);\n                    }\n                    catch (e) {\n                        return observer.error(e);\n                    }\n                }\n                else {\n                    acc = value;\n                }\n            },\n            error(e) { observer.error(e); },\n            complete() {\n                if (!hasValue && !hasSeed) {\n                    return observer.error(new TypeError(\"Cannot reduce an empty sequence\"));\n                }\n                observer.next(acc);\n                observer.complete();\n            },\n        }));\n    }\n    concat(...sources) {\n        const C = getSpecies(this);\n        return new C(observer => {\n            let subscription;\n            let index = 0;\n            function startNext(next) {\n                subscription = next.subscribe({\n                    next(v) { observer.next(v); },\n                    error(e) { observer.error(e); },\n                    complete() {\n                        if (index === sources.length) {\n                            subscription = undefined;\n                            observer.complete();\n                        }\n                        else {\n                            startNext(C.from(sources[index++]));\n                        }\n                    },\n                });\n            }\n            startNext(this);\n            return () => {\n                if (subscription) {\n                    subscription.unsubscribe();\n                    subscription = undefined;\n                }\n            };\n        });\n    }\n    flatMap(fn) {\n        if (typeof fn !== \"function\") {\n            throw new TypeError(fn + \" is not a function\");\n        }\n        const C = getSpecies(this);\n        return new C(observer => {\n            const subscriptions = [];\n            const outer = this.subscribe({\n                next(value) {\n                    let normalizedValue;\n                    if (fn) {\n                        try {\n                            normalizedValue = fn(value);\n                        }\n                        catch (e) {\n                            return observer.error(e);\n                        }\n                    }\n                    else {\n                        normalizedValue = value;\n                    }\n                    const inner = C.from(normalizedValue).subscribe({\n                        next(innerValue) { observer.next(innerValue); },\n                        error(e) { observer.error(e); },\n                        complete() {\n                            const i = subscriptions.indexOf(inner);\n                            if (i >= 0)\n                                subscriptions.splice(i, 1);\n                            completeIfDone();\n                        },\n                    });\n                    subscriptions.push(inner);\n                },\n                error(e) { observer.error(e); },\n                complete() { completeIfDone(); },\n            });\n            function completeIfDone() {\n                if (outer.closed && subscriptions.length === 0) {\n                    observer.complete();\n                }\n            }\n            return () => {\n                subscriptions.forEach(s => s.unsubscribe());\n                outer.unsubscribe();\n            };\n        });\n    }\n    [(Symbol.observable, SymbolObservable)]() { return this; }\n    static from(x) {\n        const C = (typeof this === \"function\" ? this : Observable);\n        if (x == null) {\n            throw new TypeError(x + \" is not an object\");\n        }\n        const observableMethod = getMethod(x, SymbolObservable);\n        if (observableMethod) {\n            const observable = observableMethod.call(x);\n            if (Object(observable) !== observable) {\n                throw new TypeError(observable + \" is not an object\");\n            }\n            if (isObservable(observable) && observable.constructor === C) {\n                return observable;\n            }\n            return new C(observer => observable.subscribe(observer));\n        }\n        if ((0,_symbols__WEBPACK_IMPORTED_MODULE_0__.hasSymbol)(\"iterator\")) {\n            const iteratorMethod = getMethod(x, SymbolIterator);\n            if (iteratorMethod) {\n                return new C(observer => {\n                    enqueue(() => {\n                        if (observer.closed)\n                            return;\n                        for (const item of iteratorMethod.call(x)) {\n                            observer.next(item);\n                            if (observer.closed)\n                                return;\n                        }\n                        observer.complete();\n                    });\n                });\n            }\n        }\n        if (Array.isArray(x)) {\n            return new C(observer => {\n                enqueue(() => {\n                    if (observer.closed)\n                        return;\n                    for (const item of x) {\n                        observer.next(item);\n                        if (observer.closed)\n                            return;\n                    }\n                    observer.complete();\n                });\n            });\n        }\n        throw new TypeError(x + \" is not observable\");\n    }\n    static of(...items) {\n        const C = (typeof this === \"function\" ? this : Observable);\n        return new C(observer => {\n            enqueue(() => {\n                if (observer.closed)\n                    return;\n                for (const item of items) {\n                    observer.next(item);\n                    if (observer.closed)\n                        return;\n                }\n                observer.complete();\n            });\n        });\n    }\n    static get [SymbolSpecies]() { return this; }\n}\nif ((0,_symbols__WEBPACK_IMPORTED_MODULE_0__.hasSymbols)()) {\n    Object.defineProperty(Observable, Symbol(\"extensions\"), {\n        value: {\n            symbol: SymbolObservable,\n            hostReportError,\n        },\n        configurable: true,\n    });\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Observable);\n\n\n//# sourceURL=webpack:///../node_modules/observable-fns/dist.esm/observable.js?");

/***/ }),

/***/ "../node_modules/observable-fns/dist.esm/scan.js":
/*!*******************************************************!*\
  !*** ../node_modules/observable-fns/dist.esm/scan.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _scheduler__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./_scheduler */ \"../node_modules/observable-fns/dist.esm/_scheduler.js\");\n/* harmony import */ var _observable__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./observable */ \"../node_modules/observable-fns/dist.esm/observable.js\");\n/* harmony import */ var _unsubscribe__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./unsubscribe */ \"../node_modules/observable-fns/dist.esm/unsubscribe.js\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\nfunction scan(accumulator, seed) {\n    return (observable) => {\n        return new _observable__WEBPACK_IMPORTED_MODULE_0__.default(observer => {\n            let accumulated;\n            let index = 0;\n            const scheduler = new _scheduler__WEBPACK_IMPORTED_MODULE_1__.AsyncSerialScheduler(observer);\n            const subscription = observable.subscribe({\n                complete() {\n                    scheduler.complete();\n                },\n                error(error) {\n                    scheduler.error(error);\n                },\n                next(value) {\n                    scheduler.schedule((next) => __awaiter(this, void 0, void 0, function* () {\n                        const prevAcc = index === 0\n                            ? (typeof seed === \"undefined\" ? value : seed)\n                            : accumulated;\n                        accumulated = yield accumulator(prevAcc, value, index++);\n                        next(accumulated);\n                    }));\n                }\n            });\n            return () => (0,_unsubscribe__WEBPACK_IMPORTED_MODULE_2__.default)(subscription);\n        });\n    };\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (scan);\n\n\n//# sourceURL=webpack:///../node_modules/observable-fns/dist.esm/scan.js?");

/***/ }),

/***/ "../node_modules/observable-fns/dist.esm/subject.js":
/*!**********************************************************!*\
  !*** ../node_modules/observable-fns/dist.esm/subject.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _observable__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./observable */ \"../node_modules/observable-fns/dist.esm/observable.js\");\n\n// TODO: This observer iteration approach looks inelegant and expensive\n// Idea: Come up with super class for Subscription that contains the\n//       notify*, ... methods and use it here\n/**\n * A subject is a \"hot\" observable (see `multicast`) that has its observer\n * methods (`.next(value)`, `.error(error)`, `.complete()`) exposed.\n *\n * Be careful, though! With great power comes great responsibility. Only use\n * the `Subject` when you really need to trigger updates \"from the outside\" and\n * try to keep the code that can access it to a minimum. Return\n * `Observable.from(mySubject)` to not allow other code to mutate.\n */\nclass MulticastSubject extends _observable__WEBPACK_IMPORTED_MODULE_0__.default {\n    constructor() {\n        super(observer => {\n            this._observers.add(observer);\n            return () => this._observers.delete(observer);\n        });\n        this._observers = new Set();\n    }\n    next(value) {\n        for (const observer of this._observers) {\n            observer.next(value);\n        }\n    }\n    error(error) {\n        for (const observer of this._observers) {\n            observer.error(error);\n        }\n    }\n    complete() {\n        for (const observer of this._observers) {\n            observer.complete();\n        }\n    }\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (MulticastSubject);\n\n\n//# sourceURL=webpack:///../node_modules/observable-fns/dist.esm/subject.js?");

/***/ }),

/***/ "../node_modules/observable-fns/dist.esm/unsubscribe.js":
/*!**************************************************************!*\
  !*** ../node_modules/observable-fns/dist.esm/unsubscribe.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/**\n * Unsubscribe from a subscription returned by something that looks like an observable,\n * but is not necessarily our observable implementation.\n */\nfunction unsubscribe(subscription) {\n    if (typeof subscription === \"function\") {\n        subscription();\n    }\n    else if (subscription && typeof subscription.unsubscribe === \"function\") {\n        subscription.unsubscribe();\n    }\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (unsubscribe);\n\n\n//# sourceURL=webpack:///../node_modules/observable-fns/dist.esm/unsubscribe.js?");

/***/ }),

/***/ "../node_modules/pako/lib/inflate.js":
/*!*******************************************!*\
  !*** ../node_modules/pako/lib/inflate.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\n\nvar zlib_inflate = __webpack_require__(/*! ./zlib/inflate */ \"../node_modules/pako/lib/zlib/inflate.js\");\nvar utils        = __webpack_require__(/*! ./utils/common */ \"../node_modules/pako/lib/utils/common.js\");\nvar strings      = __webpack_require__(/*! ./utils/strings */ \"../node_modules/pako/lib/utils/strings.js\");\nvar c            = __webpack_require__(/*! ./zlib/constants */ \"../node_modules/pako/lib/zlib/constants.js\");\nvar msg          = __webpack_require__(/*! ./zlib/messages */ \"../node_modules/pako/lib/zlib/messages.js\");\nvar ZStream      = __webpack_require__(/*! ./zlib/zstream */ \"../node_modules/pako/lib/zlib/zstream.js\");\nvar GZheader     = __webpack_require__(/*! ./zlib/gzheader */ \"../node_modules/pako/lib/zlib/gzheader.js\");\n\nvar toString = Object.prototype.toString;\n\n/**\n * class Inflate\n *\n * Generic JS-style wrapper for zlib calls. If you don't need\n * streaming behaviour - use more simple functions: [[inflate]]\n * and [[inflateRaw]].\n **/\n\n/* internal\n * inflate.chunks -> Array\n *\n * Chunks of output data, if [[Inflate#onData]] not overridden.\n **/\n\n/**\n * Inflate.result -> Uint8Array|Array|String\n *\n * Uncompressed result, generated by default [[Inflate#onData]]\n * and [[Inflate#onEnd]] handlers. Filled after you push last chunk\n * (call [[Inflate#push]] with `Z_FINISH` / `true` param) or if you\n * push a chunk with explicit flush (call [[Inflate#push]] with\n * `Z_SYNC_FLUSH` param).\n **/\n\n/**\n * Inflate.err -> Number\n *\n * Error code after inflate finished. 0 (Z_OK) on success.\n * Should be checked if broken data possible.\n **/\n\n/**\n * Inflate.msg -> String\n *\n * Error message, if [[Inflate.err]] != 0\n **/\n\n\n/**\n * new Inflate(options)\n * - options (Object): zlib inflate options.\n *\n * Creates new inflator instance with specified params. Throws exception\n * on bad params. Supported options:\n *\n * - `windowBits`\n * - `dictionary`\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information on these.\n *\n * Additional options, for internal needs:\n *\n * - `chunkSize` - size of generated data chunks (16K by default)\n * - `raw` (Boolean) - do raw inflate\n * - `to` (String) - if equal to 'string', then result will be converted\n *   from utf8 to utf16 (javascript) string. When string output requested,\n *   chunk length can differ from `chunkSize`, depending on content.\n *\n * By default, when no options set, autodetect deflate/gzip data format via\n * wrapper header.\n *\n * ##### Example:\n *\n * ```javascript\n * var pako = require('pako')\n *   , chunk1 = Uint8Array([1,2,3,4,5,6,7,8,9])\n *   , chunk2 = Uint8Array([10,11,12,13,14,15,16,17,18,19]);\n *\n * var inflate = new pako.Inflate({ level: 3});\n *\n * inflate.push(chunk1, false);\n * inflate.push(chunk2, true);  // true -> last chunk\n *\n * if (inflate.err) { throw new Error(inflate.err); }\n *\n * console.log(inflate.result);\n * ```\n **/\nfunction Inflate(options) {\n  if (!(this instanceof Inflate)) return new Inflate(options);\n\n  this.options = utils.assign({\n    chunkSize: 16384,\n    windowBits: 0,\n    to: ''\n  }, options || {});\n\n  var opt = this.options;\n\n  // Force window size for `raw` data, if not set directly,\n  // because we have no header for autodetect.\n  if (opt.raw && (opt.windowBits >= 0) && (opt.windowBits < 16)) {\n    opt.windowBits = -opt.windowBits;\n    if (opt.windowBits === 0) { opt.windowBits = -15; }\n  }\n\n  // If `windowBits` not defined (and mode not raw) - set autodetect flag for gzip/deflate\n  if ((opt.windowBits >= 0) && (opt.windowBits < 16) &&\n      !(options && options.windowBits)) {\n    opt.windowBits += 32;\n  }\n\n  // Gzip header has no info about windows size, we can do autodetect only\n  // for deflate. So, if window size not set, force it to max when gzip possible\n  if ((opt.windowBits > 15) && (opt.windowBits < 48)) {\n    // bit 3 (16) -> gzipped data\n    // bit 4 (32) -> autodetect gzip/deflate\n    if ((opt.windowBits & 15) === 0) {\n      opt.windowBits |= 15;\n    }\n  }\n\n  this.err    = 0;      // error code, if happens (0 = Z_OK)\n  this.msg    = '';     // error message\n  this.ended  = false;  // used to avoid multiple onEnd() calls\n  this.chunks = [];     // chunks of compressed data\n\n  this.strm   = new ZStream();\n  this.strm.avail_out = 0;\n\n  var status  = zlib_inflate.inflateInit2(\n    this.strm,\n    opt.windowBits\n  );\n\n  if (status !== c.Z_OK) {\n    throw new Error(msg[status]);\n  }\n\n  this.header = new GZheader();\n\n  zlib_inflate.inflateGetHeader(this.strm, this.header);\n\n  // Setup dictionary\n  if (opt.dictionary) {\n    // Convert data if needed\n    if (typeof opt.dictionary === 'string') {\n      opt.dictionary = strings.string2buf(opt.dictionary);\n    } else if (toString.call(opt.dictionary) === '[object ArrayBuffer]') {\n      opt.dictionary = new Uint8Array(opt.dictionary);\n    }\n    if (opt.raw) { //In raw mode we need to set the dictionary early\n      status = zlib_inflate.inflateSetDictionary(this.strm, opt.dictionary);\n      if (status !== c.Z_OK) {\n        throw new Error(msg[status]);\n      }\n    }\n  }\n}\n\n/**\n * Inflate#push(data[, mode]) -> Boolean\n * - data (Uint8Array|Array|ArrayBuffer|String): input data\n * - mode (Number|Boolean): 0..6 for corresponding Z_NO_FLUSH..Z_TREE modes.\n *   See constants. Skipped or `false` means Z_NO_FLUSH, `true` means Z_FINISH.\n *\n * Sends input data to inflate pipe, generating [[Inflate#onData]] calls with\n * new output chunks. Returns `true` on success. The last data block must have\n * mode Z_FINISH (or `true`). That will flush internal pending buffers and call\n * [[Inflate#onEnd]]. For interim explicit flushes (without ending the stream) you\n * can use mode Z_SYNC_FLUSH, keeping the decompression context.\n *\n * On fail call [[Inflate#onEnd]] with error code and return false.\n *\n * We strongly recommend to use `Uint8Array` on input for best speed (output\n * format is detected automatically). Also, don't skip last param and always\n * use the same type in your code (boolean or number). That will improve JS speed.\n *\n * For regular `Array`-s make sure all elements are [0..255].\n *\n * ##### Example\n *\n * ```javascript\n * push(chunk, false); // push one of data chunks\n * ...\n * push(chunk, true);  // push last chunk\n * ```\n **/\nInflate.prototype.push = function (data, mode) {\n  var strm = this.strm;\n  var chunkSize = this.options.chunkSize;\n  var dictionary = this.options.dictionary;\n  var status, _mode;\n  var next_out_utf8, tail, utf8str;\n\n  // Flag to properly process Z_BUF_ERROR on testing inflate call\n  // when we check that all output data was flushed.\n  var allowBufError = false;\n\n  if (this.ended) { return false; }\n  _mode = (mode === ~~mode) ? mode : ((mode === true) ? c.Z_FINISH : c.Z_NO_FLUSH);\n\n  // Convert data if needed\n  if (typeof data === 'string') {\n    // Only binary strings can be decompressed on practice\n    strm.input = strings.binstring2buf(data);\n  } else if (toString.call(data) === '[object ArrayBuffer]') {\n    strm.input = new Uint8Array(data);\n  } else {\n    strm.input = data;\n  }\n\n  strm.next_in = 0;\n  strm.avail_in = strm.input.length;\n\n  do {\n    if (strm.avail_out === 0) {\n      strm.output = new utils.Buf8(chunkSize);\n      strm.next_out = 0;\n      strm.avail_out = chunkSize;\n    }\n\n    status = zlib_inflate.inflate(strm, c.Z_NO_FLUSH);    /* no bad return value */\n\n    if (status === c.Z_NEED_DICT && dictionary) {\n      status = zlib_inflate.inflateSetDictionary(this.strm, dictionary);\n    }\n\n    if (status === c.Z_BUF_ERROR && allowBufError === true) {\n      status = c.Z_OK;\n      allowBufError = false;\n    }\n\n    if (status !== c.Z_STREAM_END && status !== c.Z_OK) {\n      this.onEnd(status);\n      this.ended = true;\n      return false;\n    }\n\n    if (strm.next_out) {\n      if (strm.avail_out === 0 || status === c.Z_STREAM_END || (strm.avail_in === 0 && (_mode === c.Z_FINISH || _mode === c.Z_SYNC_FLUSH))) {\n\n        if (this.options.to === 'string') {\n\n          next_out_utf8 = strings.utf8border(strm.output, strm.next_out);\n\n          tail = strm.next_out - next_out_utf8;\n          utf8str = strings.buf2string(strm.output, next_out_utf8);\n\n          // move tail\n          strm.next_out = tail;\n          strm.avail_out = chunkSize - tail;\n          if (tail) { utils.arraySet(strm.output, strm.output, next_out_utf8, tail, 0); }\n\n          this.onData(utf8str);\n\n        } else {\n          this.onData(utils.shrinkBuf(strm.output, strm.next_out));\n        }\n      }\n    }\n\n    // When no more input data, we should check that internal inflate buffers\n    // are flushed. The only way to do it when avail_out = 0 - run one more\n    // inflate pass. But if output data not exists, inflate return Z_BUF_ERROR.\n    // Here we set flag to process this error properly.\n    //\n    // NOTE. Deflate does not return error in this case and does not needs such\n    // logic.\n    if (strm.avail_in === 0 && strm.avail_out === 0) {\n      allowBufError = true;\n    }\n\n  } while ((strm.avail_in > 0 || strm.avail_out === 0) && status !== c.Z_STREAM_END);\n\n  if (status === c.Z_STREAM_END) {\n    _mode = c.Z_FINISH;\n  }\n\n  // Finalize on the last chunk.\n  if (_mode === c.Z_FINISH) {\n    status = zlib_inflate.inflateEnd(this.strm);\n    this.onEnd(status);\n    this.ended = true;\n    return status === c.Z_OK;\n  }\n\n  // callback interim results if Z_SYNC_FLUSH.\n  if (_mode === c.Z_SYNC_FLUSH) {\n    this.onEnd(c.Z_OK);\n    strm.avail_out = 0;\n    return true;\n  }\n\n  return true;\n};\n\n\n/**\n * Inflate#onData(chunk) -> Void\n * - chunk (Uint8Array|Array|String): output data. Type of array depends\n *   on js engine support. When string output requested, each chunk\n *   will be string.\n *\n * By default, stores data blocks in `chunks[]` property and glue\n * those in `onEnd`. Override this handler, if you need another behaviour.\n **/\nInflate.prototype.onData = function (chunk) {\n  this.chunks.push(chunk);\n};\n\n\n/**\n * Inflate#onEnd(status) -> Void\n * - status (Number): inflate status. 0 (Z_OK) on success,\n *   other if not.\n *\n * Called either after you tell inflate that the input stream is\n * complete (Z_FINISH) or should be flushed (Z_SYNC_FLUSH)\n * or if an error happened. By default - join collected chunks,\n * free memory and fill `results` / `err` properties.\n **/\nInflate.prototype.onEnd = function (status) {\n  // On success - join\n  if (status === c.Z_OK) {\n    if (this.options.to === 'string') {\n      // Glue & convert here, until we teach pako to send\n      // utf8 aligned strings to onData\n      this.result = this.chunks.join('');\n    } else {\n      this.result = utils.flattenChunks(this.chunks);\n    }\n  }\n  this.chunks = [];\n  this.err = status;\n  this.msg = this.strm.msg;\n};\n\n\n/**\n * inflate(data[, options]) -> Uint8Array|Array|String\n * - data (Uint8Array|Array|String): input data to decompress.\n * - options (Object): zlib inflate options.\n *\n * Decompress `data` with inflate/ungzip and `options`. Autodetect\n * format via wrapper header by default. That's why we don't provide\n * separate `ungzip` method.\n *\n * Supported options are:\n *\n * - windowBits\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information.\n *\n * Sugar (options):\n *\n * - `raw` (Boolean) - say that we work with raw stream, if you don't wish to specify\n *   negative windowBits implicitly.\n * - `to` (String) - if equal to 'string', then result will be converted\n *   from utf8 to utf16 (javascript) string. When string output requested,\n *   chunk length can differ from `chunkSize`, depending on content.\n *\n *\n * ##### Example:\n *\n * ```javascript\n * var pako = require('pako')\n *   , input = pako.deflate([1,2,3,4,5,6,7,8,9])\n *   , output;\n *\n * try {\n *   output = pako.inflate(input);\n * } catch (err)\n *   console.log(err);\n * }\n * ```\n **/\nfunction inflate(input, options) {\n  var inflator = new Inflate(options);\n\n  inflator.push(input, true);\n\n  // That will never happens, if you don't cheat with options :)\n  if (inflator.err) { throw inflator.msg || msg[inflator.err]; }\n\n  return inflator.result;\n}\n\n\n/**\n * inflateRaw(data[, options]) -> Uint8Array|Array|String\n * - data (Uint8Array|Array|String): input data to decompress.\n * - options (Object): zlib inflate options.\n *\n * The same as [[inflate]], but creates raw data, without wrapper\n * (header and adler32 crc).\n **/\nfunction inflateRaw(input, options) {\n  options = options || {};\n  options.raw = true;\n  return inflate(input, options);\n}\n\n\n/**\n * ungzip(data[, options]) -> Uint8Array|Array|String\n * - data (Uint8Array|Array|String): input data to decompress.\n * - options (Object): zlib inflate options.\n *\n * Just shortcut to [[inflate]], because it autodetects format\n * by header.content. Done for convenience.\n **/\n\n\nexports.Inflate = Inflate;\nexports.inflate = inflate;\nexports.inflateRaw = inflateRaw;\nexports.ungzip  = inflate;\n\n\n//# sourceURL=webpack:///../node_modules/pako/lib/inflate.js?");

/***/ }),

/***/ "../node_modules/pako/lib/utils/common.js":
/*!************************************************!*\
  !*** ../node_modules/pako/lib/utils/common.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\n\nvar TYPED_OK =  (typeof Uint8Array !== 'undefined') &&\n                (typeof Uint16Array !== 'undefined') &&\n                (typeof Int32Array !== 'undefined');\n\nfunction _has(obj, key) {\n  return Object.prototype.hasOwnProperty.call(obj, key);\n}\n\nexports.assign = function (obj /*from1, from2, from3, ...*/) {\n  var sources = Array.prototype.slice.call(arguments, 1);\n  while (sources.length) {\n    var source = sources.shift();\n    if (!source) { continue; }\n\n    if (typeof source !== 'object') {\n      throw new TypeError(source + 'must be non-object');\n    }\n\n    for (var p in source) {\n      if (_has(source, p)) {\n        obj[p] = source[p];\n      }\n    }\n  }\n\n  return obj;\n};\n\n\n// reduce buffer size, avoiding mem copy\nexports.shrinkBuf = function (buf, size) {\n  if (buf.length === size) { return buf; }\n  if (buf.subarray) { return buf.subarray(0, size); }\n  buf.length = size;\n  return buf;\n};\n\n\nvar fnTyped = {\n  arraySet: function (dest, src, src_offs, len, dest_offs) {\n    if (src.subarray && dest.subarray) {\n      dest.set(src.subarray(src_offs, src_offs + len), dest_offs);\n      return;\n    }\n    // Fallback to ordinary array\n    for (var i = 0; i < len; i++) {\n      dest[dest_offs + i] = src[src_offs + i];\n    }\n  },\n  // Join array of chunks to single array.\n  flattenChunks: function (chunks) {\n    var i, l, len, pos, chunk, result;\n\n    // calculate data length\n    len = 0;\n    for (i = 0, l = chunks.length; i < l; i++) {\n      len += chunks[i].length;\n    }\n\n    // join chunks\n    result = new Uint8Array(len);\n    pos = 0;\n    for (i = 0, l = chunks.length; i < l; i++) {\n      chunk = chunks[i];\n      result.set(chunk, pos);\n      pos += chunk.length;\n    }\n\n    return result;\n  }\n};\n\nvar fnUntyped = {\n  arraySet: function (dest, src, src_offs, len, dest_offs) {\n    for (var i = 0; i < len; i++) {\n      dest[dest_offs + i] = src[src_offs + i];\n    }\n  },\n  // Join array of chunks to single array.\n  flattenChunks: function (chunks) {\n    return [].concat.apply([], chunks);\n  }\n};\n\n\n// Enable/Disable typed arrays use, for testing\n//\nexports.setTyped = function (on) {\n  if (on) {\n    exports.Buf8  = Uint8Array;\n    exports.Buf16 = Uint16Array;\n    exports.Buf32 = Int32Array;\n    exports.assign(exports, fnTyped);\n  } else {\n    exports.Buf8  = Array;\n    exports.Buf16 = Array;\n    exports.Buf32 = Array;\n    exports.assign(exports, fnUntyped);\n  }\n};\n\nexports.setTyped(TYPED_OK);\n\n\n//# sourceURL=webpack:///../node_modules/pako/lib/utils/common.js?");

/***/ }),

/***/ "../node_modules/pako/lib/utils/strings.js":
/*!*************************************************!*\
  !*** ../node_modules/pako/lib/utils/strings.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("// String encode/decode helpers\n\n\n\nvar utils = __webpack_require__(/*! ./common */ \"../node_modules/pako/lib/utils/common.js\");\n\n\n// Quick check if we can use fast array to bin string conversion\n//\n// - apply(Array) can fail on Android 2.2\n// - apply(Uint8Array) can fail on iOS 5.1 Safari\n//\nvar STR_APPLY_OK = true;\nvar STR_APPLY_UIA_OK = true;\n\ntry { String.fromCharCode.apply(null, [ 0 ]); } catch (__) { STR_APPLY_OK = false; }\ntry { String.fromCharCode.apply(null, new Uint8Array(1)); } catch (__) { STR_APPLY_UIA_OK = false; }\n\n\n// Table with utf8 lengths (calculated by first byte of sequence)\n// Note, that 5 & 6-byte values and some 4-byte values can not be represented in JS,\n// because max possible codepoint is 0x10ffff\nvar _utf8len = new utils.Buf8(256);\nfor (var q = 0; q < 256; q++) {\n  _utf8len[q] = (q >= 252 ? 6 : q >= 248 ? 5 : q >= 240 ? 4 : q >= 224 ? 3 : q >= 192 ? 2 : 1);\n}\n_utf8len[254] = _utf8len[254] = 1; // Invalid sequence start\n\n\n// convert string to array (typed, when possible)\nexports.string2buf = function (str) {\n  var buf, c, c2, m_pos, i, str_len = str.length, buf_len = 0;\n\n  // count binary size\n  for (m_pos = 0; m_pos < str_len; m_pos++) {\n    c = str.charCodeAt(m_pos);\n    if ((c & 0xfc00) === 0xd800 && (m_pos + 1 < str_len)) {\n      c2 = str.charCodeAt(m_pos + 1);\n      if ((c2 & 0xfc00) === 0xdc00) {\n        c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);\n        m_pos++;\n      }\n    }\n    buf_len += c < 0x80 ? 1 : c < 0x800 ? 2 : c < 0x10000 ? 3 : 4;\n  }\n\n  // allocate buffer\n  buf = new utils.Buf8(buf_len);\n\n  // convert\n  for (i = 0, m_pos = 0; i < buf_len; m_pos++) {\n    c = str.charCodeAt(m_pos);\n    if ((c & 0xfc00) === 0xd800 && (m_pos + 1 < str_len)) {\n      c2 = str.charCodeAt(m_pos + 1);\n      if ((c2 & 0xfc00) === 0xdc00) {\n        c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);\n        m_pos++;\n      }\n    }\n    if (c < 0x80) {\n      /* one byte */\n      buf[i++] = c;\n    } else if (c < 0x800) {\n      /* two bytes */\n      buf[i++] = 0xC0 | (c >>> 6);\n      buf[i++] = 0x80 | (c & 0x3f);\n    } else if (c < 0x10000) {\n      /* three bytes */\n      buf[i++] = 0xE0 | (c >>> 12);\n      buf[i++] = 0x80 | (c >>> 6 & 0x3f);\n      buf[i++] = 0x80 | (c & 0x3f);\n    } else {\n      /* four bytes */\n      buf[i++] = 0xf0 | (c >>> 18);\n      buf[i++] = 0x80 | (c >>> 12 & 0x3f);\n      buf[i++] = 0x80 | (c >>> 6 & 0x3f);\n      buf[i++] = 0x80 | (c & 0x3f);\n    }\n  }\n\n  return buf;\n};\n\n// Helper (used in 2 places)\nfunction buf2binstring(buf, len) {\n  // On Chrome, the arguments in a function call that are allowed is `65534`.\n  // If the length of the buffer is smaller than that, we can use this optimization,\n  // otherwise we will take a slower path.\n  if (len < 65534) {\n    if ((buf.subarray && STR_APPLY_UIA_OK) || (!buf.subarray && STR_APPLY_OK)) {\n      return String.fromCharCode.apply(null, utils.shrinkBuf(buf, len));\n    }\n  }\n\n  var result = '';\n  for (var i = 0; i < len; i++) {\n    result += String.fromCharCode(buf[i]);\n  }\n  return result;\n}\n\n\n// Convert byte array to binary string\nexports.buf2binstring = function (buf) {\n  return buf2binstring(buf, buf.length);\n};\n\n\n// Convert binary string (typed, when possible)\nexports.binstring2buf = function (str) {\n  var buf = new utils.Buf8(str.length);\n  for (var i = 0, len = buf.length; i < len; i++) {\n    buf[i] = str.charCodeAt(i);\n  }\n  return buf;\n};\n\n\n// convert array to string\nexports.buf2string = function (buf, max) {\n  var i, out, c, c_len;\n  var len = max || buf.length;\n\n  // Reserve max possible length (2 words per char)\n  // NB: by unknown reasons, Array is significantly faster for\n  //     String.fromCharCode.apply than Uint16Array.\n  var utf16buf = new Array(len * 2);\n\n  for (out = 0, i = 0; i < len;) {\n    c = buf[i++];\n    // quick process ascii\n    if (c < 0x80) { utf16buf[out++] = c; continue; }\n\n    c_len = _utf8len[c];\n    // skip 5 & 6 byte codes\n    if (c_len > 4) { utf16buf[out++] = 0xfffd; i += c_len - 1; continue; }\n\n    // apply mask on first byte\n    c &= c_len === 2 ? 0x1f : c_len === 3 ? 0x0f : 0x07;\n    // join the rest\n    while (c_len > 1 && i < len) {\n      c = (c << 6) | (buf[i++] & 0x3f);\n      c_len--;\n    }\n\n    // terminated by end of string?\n    if (c_len > 1) { utf16buf[out++] = 0xfffd; continue; }\n\n    if (c < 0x10000) {\n      utf16buf[out++] = c;\n    } else {\n      c -= 0x10000;\n      utf16buf[out++] = 0xd800 | ((c >> 10) & 0x3ff);\n      utf16buf[out++] = 0xdc00 | (c & 0x3ff);\n    }\n  }\n\n  return buf2binstring(utf16buf, out);\n};\n\n\n// Calculate max possible position in utf8 buffer,\n// that will not break sequence. If that's not possible\n// - (very small limits) return max size as is.\n//\n// buf[] - utf8 bytes array\n// max   - length limit (mandatory);\nexports.utf8border = function (buf, max) {\n  var pos;\n\n  max = max || buf.length;\n  if (max > buf.length) { max = buf.length; }\n\n  // go back from last position, until start of sequence found\n  pos = max - 1;\n  while (pos >= 0 && (buf[pos] & 0xC0) === 0x80) { pos--; }\n\n  // Very small and broken sequence,\n  // return max, because we should return something anyway.\n  if (pos < 0) { return max; }\n\n  // If we came to start of buffer - that means buffer is too small,\n  // return max too.\n  if (pos === 0) { return max; }\n\n  return (pos + _utf8len[buf[pos]] > max) ? pos : max;\n};\n\n\n//# sourceURL=webpack:///../node_modules/pako/lib/utils/strings.js?");

/***/ }),

/***/ "../node_modules/pako/lib/zlib/adler32.js":
/*!************************************************!*\
  !*** ../node_modules/pako/lib/zlib/adler32.js ***!
  \************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n// Note: adler32 takes 12% for level 0 and 2% for level 6.\n// It isn't worth it to make additional optimizations as in original.\n// Small size is preferable.\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nfunction adler32(adler, buf, len, pos) {\n  var s1 = (adler & 0xffff) |0,\n      s2 = ((adler >>> 16) & 0xffff) |0,\n      n = 0;\n\n  while (len !== 0) {\n    // Set limit ~ twice less than 5552, to keep\n    // s2 in 31-bits, because we force signed ints.\n    // in other case %= will fail.\n    n = len > 2000 ? 2000 : len;\n    len -= n;\n\n    do {\n      s1 = (s1 + buf[pos++]) |0;\n      s2 = (s2 + s1) |0;\n    } while (--n);\n\n    s1 %= 65521;\n    s2 %= 65521;\n  }\n\n  return (s1 | (s2 << 16)) |0;\n}\n\n\nmodule.exports = adler32;\n\n\n//# sourceURL=webpack:///../node_modules/pako/lib/zlib/adler32.js?");

/***/ }),

/***/ "../node_modules/pako/lib/zlib/constants.js":
/*!**************************************************!*\
  !*** ../node_modules/pako/lib/zlib/constants.js ***!
  \**************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nmodule.exports = {\n\n  /* Allowed flush values; see deflate() and inflate() below for details */\n  Z_NO_FLUSH:         0,\n  Z_PARTIAL_FLUSH:    1,\n  Z_SYNC_FLUSH:       2,\n  Z_FULL_FLUSH:       3,\n  Z_FINISH:           4,\n  Z_BLOCK:            5,\n  Z_TREES:            6,\n\n  /* Return codes for the compression/decompression functions. Negative values\n  * are errors, positive values are used for special but normal events.\n  */\n  Z_OK:               0,\n  Z_STREAM_END:       1,\n  Z_NEED_DICT:        2,\n  Z_ERRNO:           -1,\n  Z_STREAM_ERROR:    -2,\n  Z_DATA_ERROR:      -3,\n  //Z_MEM_ERROR:     -4,\n  Z_BUF_ERROR:       -5,\n  //Z_VERSION_ERROR: -6,\n\n  /* compression levels */\n  Z_NO_COMPRESSION:         0,\n  Z_BEST_SPEED:             1,\n  Z_BEST_COMPRESSION:       9,\n  Z_DEFAULT_COMPRESSION:   -1,\n\n\n  Z_FILTERED:               1,\n  Z_HUFFMAN_ONLY:           2,\n  Z_RLE:                    3,\n  Z_FIXED:                  4,\n  Z_DEFAULT_STRATEGY:       0,\n\n  /* Possible values of the data_type field (though see inflate()) */\n  Z_BINARY:                 0,\n  Z_TEXT:                   1,\n  //Z_ASCII:                1, // = Z_TEXT (deprecated)\n  Z_UNKNOWN:                2,\n\n  /* The deflate compression method */\n  Z_DEFLATED:               8\n  //Z_NULL:                 null // Use -1 or null inline, depending on var type\n};\n\n\n//# sourceURL=webpack:///../node_modules/pako/lib/zlib/constants.js?");

/***/ }),

/***/ "../node_modules/pako/lib/zlib/crc32.js":
/*!**********************************************!*\
  !*** ../node_modules/pako/lib/zlib/crc32.js ***!
  \**********************************************/
/***/ ((module) => {

"use strict";
eval("\n\n// Note: we can't get significant speed boost here.\n// So write code to minimize size - no pregenerated tables\n// and array tools dependencies.\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n// Use ordinary array, since untyped makes no boost here\nfunction makeTable() {\n  var c, table = [];\n\n  for (var n = 0; n < 256; n++) {\n    c = n;\n    for (var k = 0; k < 8; k++) {\n      c = ((c & 1) ? (0xEDB88320 ^ (c >>> 1)) : (c >>> 1));\n    }\n    table[n] = c;\n  }\n\n  return table;\n}\n\n// Create table on load. Just 255 signed longs. Not a problem.\nvar crcTable = makeTable();\n\n\nfunction crc32(crc, buf, len, pos) {\n  var t = crcTable,\n      end = pos + len;\n\n  crc ^= -1;\n\n  for (var i = pos; i < end; i++) {\n    crc = (crc >>> 8) ^ t[(crc ^ buf[i]) & 0xFF];\n  }\n\n  return (crc ^ (-1)); // >>> 0;\n}\n\n\nmodule.exports = crc32;\n\n\n//# sourceURL=webpack:///../node_modules/pako/lib/zlib/crc32.js?");

/***/ }),

/***/ "../node_modules/pako/lib/zlib/gzheader.js":
/*!*************************************************!*\
  !*** ../node_modules/pako/lib/zlib/gzheader.js ***!
  \*************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nfunction GZheader() {\n  /* true if compressed data believed to be text */\n  this.text       = 0;\n  /* modification time */\n  this.time       = 0;\n  /* extra flags (not used when writing a gzip file) */\n  this.xflags     = 0;\n  /* operating system */\n  this.os         = 0;\n  /* pointer to extra field or Z_NULL if none */\n  this.extra      = null;\n  /* extra field length (valid if extra != Z_NULL) */\n  this.extra_len  = 0; // Actually, we don't need it in JS,\n                       // but leave for few code modifications\n\n  //\n  // Setup limits is not necessary because in js we should not preallocate memory\n  // for inflate use constant limit in 65536 bytes\n  //\n\n  /* space at extra (only when reading header) */\n  // this.extra_max  = 0;\n  /* pointer to zero-terminated file name or Z_NULL */\n  this.name       = '';\n  /* space at name (only when reading header) */\n  // this.name_max   = 0;\n  /* pointer to zero-terminated comment or Z_NULL */\n  this.comment    = '';\n  /* space at comment (only when reading header) */\n  // this.comm_max   = 0;\n  /* true if there was or will be a header crc */\n  this.hcrc       = 0;\n  /* true when done reading gzip header (not used when writing a gzip file) */\n  this.done       = false;\n}\n\nmodule.exports = GZheader;\n\n\n//# sourceURL=webpack:///../node_modules/pako/lib/zlib/gzheader.js?");

/***/ }),

/***/ "../node_modules/pako/lib/zlib/inffast.js":
/*!************************************************!*\
  !*** ../node_modules/pako/lib/zlib/inffast.js ***!
  \************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n// See state defs from inflate.js\nvar BAD = 30;       /* got a data error -- remain here until reset */\nvar TYPE = 12;      /* i: waiting for type bits, including last-flag bit */\n\n/*\n   Decode literal, length, and distance codes and write out the resulting\n   literal and match bytes until either not enough input or output is\n   available, an end-of-block is encountered, or a data error is encountered.\n   When large enough input and output buffers are supplied to inflate(), for\n   example, a 16K input buffer and a 64K output buffer, more than 95% of the\n   inflate execution time is spent in this routine.\n\n   Entry assumptions:\n\n        state.mode === LEN\n        strm.avail_in >= 6\n        strm.avail_out >= 258\n        start >= strm.avail_out\n        state.bits < 8\n\n   On return, state.mode is one of:\n\n        LEN -- ran out of enough output space or enough available input\n        TYPE -- reached end of block code, inflate() to interpret next block\n        BAD -- error in block data\n\n   Notes:\n\n    - The maximum input bits used by a length/distance pair is 15 bits for the\n      length code, 5 bits for the length extra, 15 bits for the distance code,\n      and 13 bits for the distance extra.  This totals 48 bits, or six bytes.\n      Therefore if strm.avail_in >= 6, then there is enough input to avoid\n      checking for available input while decoding.\n\n    - The maximum bytes that a single length/distance pair can output is 258\n      bytes, which is the maximum length that can be coded.  inflate_fast()\n      requires strm.avail_out >= 258 for each loop to avoid checking for\n      output space.\n */\nmodule.exports = function inflate_fast(strm, start) {\n  var state;\n  var _in;                    /* local strm.input */\n  var last;                   /* have enough input while in < last */\n  var _out;                   /* local strm.output */\n  var beg;                    /* inflate()'s initial strm.output */\n  var end;                    /* while out < end, enough space available */\n//#ifdef INFLATE_STRICT\n  var dmax;                   /* maximum distance from zlib header */\n//#endif\n  var wsize;                  /* window size or zero if not using window */\n  var whave;                  /* valid bytes in the window */\n  var wnext;                  /* window write index */\n  // Use `s_window` instead `window`, avoid conflict with instrumentation tools\n  var s_window;               /* allocated sliding window, if wsize != 0 */\n  var hold;                   /* local strm.hold */\n  var bits;                   /* local strm.bits */\n  var lcode;                  /* local strm.lencode */\n  var dcode;                  /* local strm.distcode */\n  var lmask;                  /* mask for first level of length codes */\n  var dmask;                  /* mask for first level of distance codes */\n  var here;                   /* retrieved table entry */\n  var op;                     /* code bits, operation, extra bits, or */\n                              /*  window position, window bytes to copy */\n  var len;                    /* match length, unused bytes */\n  var dist;                   /* match distance */\n  var from;                   /* where to copy match from */\n  var from_source;\n\n\n  var input, output; // JS specific, because we have no pointers\n\n  /* copy state to local variables */\n  state = strm.state;\n  //here = state.here;\n  _in = strm.next_in;\n  input = strm.input;\n  last = _in + (strm.avail_in - 5);\n  _out = strm.next_out;\n  output = strm.output;\n  beg = _out - (start - strm.avail_out);\n  end = _out + (strm.avail_out - 257);\n//#ifdef INFLATE_STRICT\n  dmax = state.dmax;\n//#endif\n  wsize = state.wsize;\n  whave = state.whave;\n  wnext = state.wnext;\n  s_window = state.window;\n  hold = state.hold;\n  bits = state.bits;\n  lcode = state.lencode;\n  dcode = state.distcode;\n  lmask = (1 << state.lenbits) - 1;\n  dmask = (1 << state.distbits) - 1;\n\n\n  /* decode literals and length/distances until end-of-block or not enough\n     input data or output space */\n\n  top:\n  do {\n    if (bits < 15) {\n      hold += input[_in++] << bits;\n      bits += 8;\n      hold += input[_in++] << bits;\n      bits += 8;\n    }\n\n    here = lcode[hold & lmask];\n\n    dolen:\n    for (;;) { // Goto emulation\n      op = here >>> 24/*here.bits*/;\n      hold >>>= op;\n      bits -= op;\n      op = (here >>> 16) & 0xff/*here.op*/;\n      if (op === 0) {                          /* literal */\n        //Tracevv((stderr, here.val >= 0x20 && here.val < 0x7f ?\n        //        \"inflate:         literal '%c'\\n\" :\n        //        \"inflate:         literal 0x%02x\\n\", here.val));\n        output[_out++] = here & 0xffff/*here.val*/;\n      }\n      else if (op & 16) {                     /* length base */\n        len = here & 0xffff/*here.val*/;\n        op &= 15;                           /* number of extra bits */\n        if (op) {\n          if (bits < op) {\n            hold += input[_in++] << bits;\n            bits += 8;\n          }\n          len += hold & ((1 << op) - 1);\n          hold >>>= op;\n          bits -= op;\n        }\n        //Tracevv((stderr, \"inflate:         length %u\\n\", len));\n        if (bits < 15) {\n          hold += input[_in++] << bits;\n          bits += 8;\n          hold += input[_in++] << bits;\n          bits += 8;\n        }\n        here = dcode[hold & dmask];\n\n        dodist:\n        for (;;) { // goto emulation\n          op = here >>> 24/*here.bits*/;\n          hold >>>= op;\n          bits -= op;\n          op = (here >>> 16) & 0xff/*here.op*/;\n\n          if (op & 16) {                      /* distance base */\n            dist = here & 0xffff/*here.val*/;\n            op &= 15;                       /* number of extra bits */\n            if (bits < op) {\n              hold += input[_in++] << bits;\n              bits += 8;\n              if (bits < op) {\n                hold += input[_in++] << bits;\n                bits += 8;\n              }\n            }\n            dist += hold & ((1 << op) - 1);\n//#ifdef INFLATE_STRICT\n            if (dist > dmax) {\n              strm.msg = 'invalid distance too far back';\n              state.mode = BAD;\n              break top;\n            }\n//#endif\n            hold >>>= op;\n            bits -= op;\n            //Tracevv((stderr, \"inflate:         distance %u\\n\", dist));\n            op = _out - beg;                /* max distance in output */\n            if (dist > op) {                /* see if copy from window */\n              op = dist - op;               /* distance back in window */\n              if (op > whave) {\n                if (state.sane) {\n                  strm.msg = 'invalid distance too far back';\n                  state.mode = BAD;\n                  break top;\n                }\n\n// (!) This block is disabled in zlib defaults,\n// don't enable it for binary compatibility\n//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR\n//                if (len <= op - whave) {\n//                  do {\n//                    output[_out++] = 0;\n//                  } while (--len);\n//                  continue top;\n//                }\n//                len -= op - whave;\n//                do {\n//                  output[_out++] = 0;\n//                } while (--op > whave);\n//                if (op === 0) {\n//                  from = _out - dist;\n//                  do {\n//                    output[_out++] = output[from++];\n//                  } while (--len);\n//                  continue top;\n//                }\n//#endif\n              }\n              from = 0; // window index\n              from_source = s_window;\n              if (wnext === 0) {           /* very common case */\n                from += wsize - op;\n                if (op < len) {         /* some from window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = _out - dist;  /* rest from output */\n                  from_source = output;\n                }\n              }\n              else if (wnext < op) {      /* wrap around window */\n                from += wsize + wnext - op;\n                op -= wnext;\n                if (op < len) {         /* some from end of window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = 0;\n                  if (wnext < len) {  /* some from start of window */\n                    op = wnext;\n                    len -= op;\n                    do {\n                      output[_out++] = s_window[from++];\n                    } while (--op);\n                    from = _out - dist;      /* rest from output */\n                    from_source = output;\n                  }\n                }\n              }\n              else {                      /* contiguous in window */\n                from += wnext - op;\n                if (op < len) {         /* some from window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = _out - dist;  /* rest from output */\n                  from_source = output;\n                }\n              }\n              while (len > 2) {\n                output[_out++] = from_source[from++];\n                output[_out++] = from_source[from++];\n                output[_out++] = from_source[from++];\n                len -= 3;\n              }\n              if (len) {\n                output[_out++] = from_source[from++];\n                if (len > 1) {\n                  output[_out++] = from_source[from++];\n                }\n              }\n            }\n            else {\n              from = _out - dist;          /* copy direct from output */\n              do {                        /* minimum length is three */\n                output[_out++] = output[from++];\n                output[_out++] = output[from++];\n                output[_out++] = output[from++];\n                len -= 3;\n              } while (len > 2);\n              if (len) {\n                output[_out++] = output[from++];\n                if (len > 1) {\n                  output[_out++] = output[from++];\n                }\n              }\n            }\n          }\n          else if ((op & 64) === 0) {          /* 2nd level distance code */\n            here = dcode[(here & 0xffff)/*here.val*/ + (hold & ((1 << op) - 1))];\n            continue dodist;\n          }\n          else {\n            strm.msg = 'invalid distance code';\n            state.mode = BAD;\n            break top;\n          }\n\n          break; // need to emulate goto via \"continue\"\n        }\n      }\n      else if ((op & 64) === 0) {              /* 2nd level length code */\n        here = lcode[(here & 0xffff)/*here.val*/ + (hold & ((1 << op) - 1))];\n        continue dolen;\n      }\n      else if (op & 32) {                     /* end-of-block */\n        //Tracevv((stderr, \"inflate:         end of block\\n\"));\n        state.mode = TYPE;\n        break top;\n      }\n      else {\n        strm.msg = 'invalid literal/length code';\n        state.mode = BAD;\n        break top;\n      }\n\n      break; // need to emulate goto via \"continue\"\n    }\n  } while (_in < last && _out < end);\n\n  /* return unused bytes (on entry, bits < 8, so in won't go too far back) */\n  len = bits >> 3;\n  _in -= len;\n  bits -= len << 3;\n  hold &= (1 << bits) - 1;\n\n  /* update state and return */\n  strm.next_in = _in;\n  strm.next_out = _out;\n  strm.avail_in = (_in < last ? 5 + (last - _in) : 5 - (_in - last));\n  strm.avail_out = (_out < end ? 257 + (end - _out) : 257 - (_out - end));\n  state.hold = hold;\n  state.bits = bits;\n  return;\n};\n\n\n//# sourceURL=webpack:///../node_modules/pako/lib/zlib/inffast.js?");

/***/ }),

/***/ "../node_modules/pako/lib/zlib/inflate.js":
/*!************************************************!*\
  !*** ../node_modules/pako/lib/zlib/inflate.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nvar utils         = __webpack_require__(/*! ../utils/common */ \"../node_modules/pako/lib/utils/common.js\");\nvar adler32       = __webpack_require__(/*! ./adler32 */ \"../node_modules/pako/lib/zlib/adler32.js\");\nvar crc32         = __webpack_require__(/*! ./crc32 */ \"../node_modules/pako/lib/zlib/crc32.js\");\nvar inflate_fast  = __webpack_require__(/*! ./inffast */ \"../node_modules/pako/lib/zlib/inffast.js\");\nvar inflate_table = __webpack_require__(/*! ./inftrees */ \"../node_modules/pako/lib/zlib/inftrees.js\");\n\nvar CODES = 0;\nvar LENS = 1;\nvar DISTS = 2;\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\n\n/* Allowed flush values; see deflate() and inflate() below for details */\n//var Z_NO_FLUSH      = 0;\n//var Z_PARTIAL_FLUSH = 1;\n//var Z_SYNC_FLUSH    = 2;\n//var Z_FULL_FLUSH    = 3;\nvar Z_FINISH        = 4;\nvar Z_BLOCK         = 5;\nvar Z_TREES         = 6;\n\n\n/* Return codes for the compression/decompression functions. Negative values\n * are errors, positive values are used for special but normal events.\n */\nvar Z_OK            = 0;\nvar Z_STREAM_END    = 1;\nvar Z_NEED_DICT     = 2;\n//var Z_ERRNO         = -1;\nvar Z_STREAM_ERROR  = -2;\nvar Z_DATA_ERROR    = -3;\nvar Z_MEM_ERROR     = -4;\nvar Z_BUF_ERROR     = -5;\n//var Z_VERSION_ERROR = -6;\n\n/* The deflate compression method */\nvar Z_DEFLATED  = 8;\n\n\n/* STATES ====================================================================*/\n/* ===========================================================================*/\n\n\nvar    HEAD = 1;       /* i: waiting for magic header */\nvar    FLAGS = 2;      /* i: waiting for method and flags (gzip) */\nvar    TIME = 3;       /* i: waiting for modification time (gzip) */\nvar    OS = 4;         /* i: waiting for extra flags and operating system (gzip) */\nvar    EXLEN = 5;      /* i: waiting for extra length (gzip) */\nvar    EXTRA = 6;      /* i: waiting for extra bytes (gzip) */\nvar    NAME = 7;       /* i: waiting for end of file name (gzip) */\nvar    COMMENT = 8;    /* i: waiting for end of comment (gzip) */\nvar    HCRC = 9;       /* i: waiting for header crc (gzip) */\nvar    DICTID = 10;    /* i: waiting for dictionary check value */\nvar    DICT = 11;      /* waiting for inflateSetDictionary() call */\nvar        TYPE = 12;      /* i: waiting for type bits, including last-flag bit */\nvar        TYPEDO = 13;    /* i: same, but skip check to exit inflate on new block */\nvar        STORED = 14;    /* i: waiting for stored size (length and complement) */\nvar        COPY_ = 15;     /* i/o: same as COPY below, but only first time in */\nvar        COPY = 16;      /* i/o: waiting for input or output to copy stored block */\nvar        TABLE = 17;     /* i: waiting for dynamic block table lengths */\nvar        LENLENS = 18;   /* i: waiting for code length code lengths */\nvar        CODELENS = 19;  /* i: waiting for length/lit and distance code lengths */\nvar            LEN_ = 20;      /* i: same as LEN below, but only first time in */\nvar            LEN = 21;       /* i: waiting for length/lit/eob code */\nvar            LENEXT = 22;    /* i: waiting for length extra bits */\nvar            DIST = 23;      /* i: waiting for distance code */\nvar            DISTEXT = 24;   /* i: waiting for distance extra bits */\nvar            MATCH = 25;     /* o: waiting for output space to copy string */\nvar            LIT = 26;       /* o: waiting for output space to write literal */\nvar    CHECK = 27;     /* i: waiting for 32-bit check value */\nvar    LENGTH = 28;    /* i: waiting for 32-bit length (gzip) */\nvar    DONE = 29;      /* finished check, done -- remain here until reset */\nvar    BAD = 30;       /* got a data error -- remain here until reset */\nvar    MEM = 31;       /* got an inflate() memory error -- remain here until reset */\nvar    SYNC = 32;      /* looking for synchronization bytes to restart inflate() */\n\n/* ===========================================================================*/\n\n\n\nvar ENOUGH_LENS = 852;\nvar ENOUGH_DISTS = 592;\n//var ENOUGH =  (ENOUGH_LENS+ENOUGH_DISTS);\n\nvar MAX_WBITS = 15;\n/* 32K LZ77 window */\nvar DEF_WBITS = MAX_WBITS;\n\n\nfunction zswap32(q) {\n  return  (((q >>> 24) & 0xff) +\n          ((q >>> 8) & 0xff00) +\n          ((q & 0xff00) << 8) +\n          ((q & 0xff) << 24));\n}\n\n\nfunction InflateState() {\n  this.mode = 0;             /* current inflate mode */\n  this.last = false;          /* true if processing last block */\n  this.wrap = 0;              /* bit 0 true for zlib, bit 1 true for gzip */\n  this.havedict = false;      /* true if dictionary provided */\n  this.flags = 0;             /* gzip header method and flags (0 if zlib) */\n  this.dmax = 0;              /* zlib header max distance (INFLATE_STRICT) */\n  this.check = 0;             /* protected copy of check value */\n  this.total = 0;             /* protected copy of output count */\n  // TODO: may be {}\n  this.head = null;           /* where to save gzip header information */\n\n  /* sliding window */\n  this.wbits = 0;             /* log base 2 of requested window size */\n  this.wsize = 0;             /* window size or zero if not using window */\n  this.whave = 0;             /* valid bytes in the window */\n  this.wnext = 0;             /* window write index */\n  this.window = null;         /* allocated sliding window, if needed */\n\n  /* bit accumulator */\n  this.hold = 0;              /* input bit accumulator */\n  this.bits = 0;              /* number of bits in \"in\" */\n\n  /* for string and stored block copying */\n  this.length = 0;            /* literal or length of data to copy */\n  this.offset = 0;            /* distance back to copy string from */\n\n  /* for table and code decoding */\n  this.extra = 0;             /* extra bits needed */\n\n  /* fixed and dynamic code tables */\n  this.lencode = null;          /* starting table for length/literal codes */\n  this.distcode = null;         /* starting table for distance codes */\n  this.lenbits = 0;           /* index bits for lencode */\n  this.distbits = 0;          /* index bits for distcode */\n\n  /* dynamic table building */\n  this.ncode = 0;             /* number of code length code lengths */\n  this.nlen = 0;              /* number of length code lengths */\n  this.ndist = 0;             /* number of distance code lengths */\n  this.have = 0;              /* number of code lengths in lens[] */\n  this.next = null;              /* next available space in codes[] */\n\n  this.lens = new utils.Buf16(320); /* temporary storage for code lengths */\n  this.work = new utils.Buf16(288); /* work area for code table building */\n\n  /*\n   because we don't have pointers in js, we use lencode and distcode directly\n   as buffers so we don't need codes\n  */\n  //this.codes = new utils.Buf32(ENOUGH);       /* space for code tables */\n  this.lendyn = null;              /* dynamic table for length/literal codes (JS specific) */\n  this.distdyn = null;             /* dynamic table for distance codes (JS specific) */\n  this.sane = 0;                   /* if false, allow invalid distance too far */\n  this.back = 0;                   /* bits back of last unprocessed length/lit */\n  this.was = 0;                    /* initial length of match */\n}\n\nfunction inflateResetKeep(strm) {\n  var state;\n\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  state = strm.state;\n  strm.total_in = strm.total_out = state.total = 0;\n  strm.msg = ''; /*Z_NULL*/\n  if (state.wrap) {       /* to support ill-conceived Java test suite */\n    strm.adler = state.wrap & 1;\n  }\n  state.mode = HEAD;\n  state.last = 0;\n  state.havedict = 0;\n  state.dmax = 32768;\n  state.head = null/*Z_NULL*/;\n  state.hold = 0;\n  state.bits = 0;\n  //state.lencode = state.distcode = state.next = state.codes;\n  state.lencode = state.lendyn = new utils.Buf32(ENOUGH_LENS);\n  state.distcode = state.distdyn = new utils.Buf32(ENOUGH_DISTS);\n\n  state.sane = 1;\n  state.back = -1;\n  //Tracev((stderr, \"inflate: reset\\n\"));\n  return Z_OK;\n}\n\nfunction inflateReset(strm) {\n  var state;\n\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  state = strm.state;\n  state.wsize = 0;\n  state.whave = 0;\n  state.wnext = 0;\n  return inflateResetKeep(strm);\n\n}\n\nfunction inflateReset2(strm, windowBits) {\n  var wrap;\n  var state;\n\n  /* get the state */\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  state = strm.state;\n\n  /* extract wrap request from windowBits parameter */\n  if (windowBits < 0) {\n    wrap = 0;\n    windowBits = -windowBits;\n  }\n  else {\n    wrap = (windowBits >> 4) + 1;\n    if (windowBits < 48) {\n      windowBits &= 15;\n    }\n  }\n\n  /* set number of window bits, free window if different */\n  if (windowBits && (windowBits < 8 || windowBits > 15)) {\n    return Z_STREAM_ERROR;\n  }\n  if (state.window !== null && state.wbits !== windowBits) {\n    state.window = null;\n  }\n\n  /* update state and reset the rest of it */\n  state.wrap = wrap;\n  state.wbits = windowBits;\n  return inflateReset(strm);\n}\n\nfunction inflateInit2(strm, windowBits) {\n  var ret;\n  var state;\n\n  if (!strm) { return Z_STREAM_ERROR; }\n  //strm.msg = Z_NULL;                 /* in case we return an error */\n\n  state = new InflateState();\n\n  //if (state === Z_NULL) return Z_MEM_ERROR;\n  //Tracev((stderr, \"inflate: allocated\\n\"));\n  strm.state = state;\n  state.window = null/*Z_NULL*/;\n  ret = inflateReset2(strm, windowBits);\n  if (ret !== Z_OK) {\n    strm.state = null/*Z_NULL*/;\n  }\n  return ret;\n}\n\nfunction inflateInit(strm) {\n  return inflateInit2(strm, DEF_WBITS);\n}\n\n\n/*\n Return state with length and distance decoding tables and index sizes set to\n fixed code decoding.  Normally this returns fixed tables from inffixed.h.\n If BUILDFIXED is defined, then instead this routine builds the tables the\n first time it's called, and returns those tables the first time and\n thereafter.  This reduces the size of the code by about 2K bytes, in\n exchange for a little execution time.  However, BUILDFIXED should not be\n used for threaded applications, since the rewriting of the tables and virgin\n may not be thread-safe.\n */\nvar virgin = true;\n\nvar lenfix, distfix; // We have no pointers in JS, so keep tables separate\n\nfunction fixedtables(state) {\n  /* build fixed huffman tables if first call (may not be thread safe) */\n  if (virgin) {\n    var sym;\n\n    lenfix = new utils.Buf32(512);\n    distfix = new utils.Buf32(32);\n\n    /* literal/length table */\n    sym = 0;\n    while (sym < 144) { state.lens[sym++] = 8; }\n    while (sym < 256) { state.lens[sym++] = 9; }\n    while (sym < 280) { state.lens[sym++] = 7; }\n    while (sym < 288) { state.lens[sym++] = 8; }\n\n    inflate_table(LENS,  state.lens, 0, 288, lenfix,   0, state.work, { bits: 9 });\n\n    /* distance table */\n    sym = 0;\n    while (sym < 32) { state.lens[sym++] = 5; }\n\n    inflate_table(DISTS, state.lens, 0, 32,   distfix, 0, state.work, { bits: 5 });\n\n    /* do this just once */\n    virgin = false;\n  }\n\n  state.lencode = lenfix;\n  state.lenbits = 9;\n  state.distcode = distfix;\n  state.distbits = 5;\n}\n\n\n/*\n Update the window with the last wsize (normally 32K) bytes written before\n returning.  If window does not exist yet, create it.  This is only called\n when a window is already in use, or when output has been written during this\n inflate call, but the end of the deflate stream has not been reached yet.\n It is also called to create a window for dictionary data when a dictionary\n is loaded.\n\n Providing output buffers larger than 32K to inflate() should provide a speed\n advantage, since only the last 32K of output is copied to the sliding window\n upon return from inflate(), and since all distances after the first 32K of\n output will fall in the output data, making match copies simpler and faster.\n The advantage may be dependent on the size of the processor's data caches.\n */\nfunction updatewindow(strm, src, end, copy) {\n  var dist;\n  var state = strm.state;\n\n  /* if it hasn't been done already, allocate space for the window */\n  if (state.window === null) {\n    state.wsize = 1 << state.wbits;\n    state.wnext = 0;\n    state.whave = 0;\n\n    state.window = new utils.Buf8(state.wsize);\n  }\n\n  /* copy state->wsize or less output bytes into the circular window */\n  if (copy >= state.wsize) {\n    utils.arraySet(state.window, src, end - state.wsize, state.wsize, 0);\n    state.wnext = 0;\n    state.whave = state.wsize;\n  }\n  else {\n    dist = state.wsize - state.wnext;\n    if (dist > copy) {\n      dist = copy;\n    }\n    //zmemcpy(state->window + state->wnext, end - copy, dist);\n    utils.arraySet(state.window, src, end - copy, dist, state.wnext);\n    copy -= dist;\n    if (copy) {\n      //zmemcpy(state->window, end - copy, copy);\n      utils.arraySet(state.window, src, end - copy, copy, 0);\n      state.wnext = copy;\n      state.whave = state.wsize;\n    }\n    else {\n      state.wnext += dist;\n      if (state.wnext === state.wsize) { state.wnext = 0; }\n      if (state.whave < state.wsize) { state.whave += dist; }\n    }\n  }\n  return 0;\n}\n\nfunction inflate(strm, flush) {\n  var state;\n  var input, output;          // input/output buffers\n  var next;                   /* next input INDEX */\n  var put;                    /* next output INDEX */\n  var have, left;             /* available input and output */\n  var hold;                   /* bit buffer */\n  var bits;                   /* bits in bit buffer */\n  var _in, _out;              /* save starting available input and output */\n  var copy;                   /* number of stored or match bytes to copy */\n  var from;                   /* where to copy match bytes from */\n  var from_source;\n  var here = 0;               /* current decoding table entry */\n  var here_bits, here_op, here_val; // paked \"here\" denormalized (JS specific)\n  //var last;                   /* parent table entry */\n  var last_bits, last_op, last_val; // paked \"last\" denormalized (JS specific)\n  var len;                    /* length to copy for repeats, bits to drop */\n  var ret;                    /* return code */\n  var hbuf = new utils.Buf8(4);    /* buffer for gzip header crc calculation */\n  var opts;\n\n  var n; // temporary var for NEED_BITS\n\n  var order = /* permutation of code lengths */\n    [ 16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15 ];\n\n\n  if (!strm || !strm.state || !strm.output ||\n      (!strm.input && strm.avail_in !== 0)) {\n    return Z_STREAM_ERROR;\n  }\n\n  state = strm.state;\n  if (state.mode === TYPE) { state.mode = TYPEDO; }    /* skip check */\n\n\n  //--- LOAD() ---\n  put = strm.next_out;\n  output = strm.output;\n  left = strm.avail_out;\n  next = strm.next_in;\n  input = strm.input;\n  have = strm.avail_in;\n  hold = state.hold;\n  bits = state.bits;\n  //---\n\n  _in = have;\n  _out = left;\n  ret = Z_OK;\n\n  inf_leave: // goto emulation\n  for (;;) {\n    switch (state.mode) {\n      case HEAD:\n        if (state.wrap === 0) {\n          state.mode = TYPEDO;\n          break;\n        }\n        //=== NEEDBITS(16);\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if ((state.wrap & 2) && hold === 0x8b1f) {  /* gzip header */\n          state.check = 0/*crc32(0L, Z_NULL, 0)*/;\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32(state.check, hbuf, 2, 0);\n          //===//\n\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          state.mode = FLAGS;\n          break;\n        }\n        state.flags = 0;           /* expect zlib header */\n        if (state.head) {\n          state.head.done = false;\n        }\n        if (!(state.wrap & 1) ||   /* check if zlib header allowed */\n          (((hold & 0xff)/*BITS(8)*/ << 8) + (hold >> 8)) % 31) {\n          strm.msg = 'incorrect header check';\n          state.mode = BAD;\n          break;\n        }\n        if ((hold & 0x0f)/*BITS(4)*/ !== Z_DEFLATED) {\n          strm.msg = 'unknown compression method';\n          state.mode = BAD;\n          break;\n        }\n        //--- DROPBITS(4) ---//\n        hold >>>= 4;\n        bits -= 4;\n        //---//\n        len = (hold & 0x0f)/*BITS(4)*/ + 8;\n        if (state.wbits === 0) {\n          state.wbits = len;\n        }\n        else if (len > state.wbits) {\n          strm.msg = 'invalid window size';\n          state.mode = BAD;\n          break;\n        }\n        state.dmax = 1 << len;\n        //Tracev((stderr, \"inflate:   zlib header ok\\n\"));\n        strm.adler = state.check = 1/*adler32(0L, Z_NULL, 0)*/;\n        state.mode = hold & 0x200 ? DICTID : TYPE;\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        break;\n      case FLAGS:\n        //=== NEEDBITS(16); */\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.flags = hold;\n        if ((state.flags & 0xff) !== Z_DEFLATED) {\n          strm.msg = 'unknown compression method';\n          state.mode = BAD;\n          break;\n        }\n        if (state.flags & 0xe000) {\n          strm.msg = 'unknown header flags set';\n          state.mode = BAD;\n          break;\n        }\n        if (state.head) {\n          state.head.text = ((hold >> 8) & 1);\n        }\n        if (state.flags & 0x0200) {\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32(state.check, hbuf, 2, 0);\n          //===//\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = TIME;\n        /* falls through */\n      case TIME:\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if (state.head) {\n          state.head.time = hold;\n        }\n        if (state.flags & 0x0200) {\n          //=== CRC4(state.check, hold)\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          hbuf[2] = (hold >>> 16) & 0xff;\n          hbuf[3] = (hold >>> 24) & 0xff;\n          state.check = crc32(state.check, hbuf, 4, 0);\n          //===\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = OS;\n        /* falls through */\n      case OS:\n        //=== NEEDBITS(16); */\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if (state.head) {\n          state.head.xflags = (hold & 0xff);\n          state.head.os = (hold >> 8);\n        }\n        if (state.flags & 0x0200) {\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32(state.check, hbuf, 2, 0);\n          //===//\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = EXLEN;\n        /* falls through */\n      case EXLEN:\n        if (state.flags & 0x0400) {\n          //=== NEEDBITS(16); */\n          while (bits < 16) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.length = hold;\n          if (state.head) {\n            state.head.extra_len = hold;\n          }\n          if (state.flags & 0x0200) {\n            //=== CRC2(state.check, hold);\n            hbuf[0] = hold & 0xff;\n            hbuf[1] = (hold >>> 8) & 0xff;\n            state.check = crc32(state.check, hbuf, 2, 0);\n            //===//\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n        }\n        else if (state.head) {\n          state.head.extra = null/*Z_NULL*/;\n        }\n        state.mode = EXTRA;\n        /* falls through */\n      case EXTRA:\n        if (state.flags & 0x0400) {\n          copy = state.length;\n          if (copy > have) { copy = have; }\n          if (copy) {\n            if (state.head) {\n              len = state.head.extra_len - state.length;\n              if (!state.head.extra) {\n                // Use untyped array for more convenient processing later\n                state.head.extra = new Array(state.head.extra_len);\n              }\n              utils.arraySet(\n                state.head.extra,\n                input,\n                next,\n                // extra field is limited to 65536 bytes\n                // - no need for additional size check\n                copy,\n                /*len + copy > state.head.extra_max - len ? state.head.extra_max : copy,*/\n                len\n              );\n              //zmemcpy(state.head.extra + len, next,\n              //        len + copy > state.head.extra_max ?\n              //        state.head.extra_max - len : copy);\n            }\n            if (state.flags & 0x0200) {\n              state.check = crc32(state.check, input, copy, next);\n            }\n            have -= copy;\n            next += copy;\n            state.length -= copy;\n          }\n          if (state.length) { break inf_leave; }\n        }\n        state.length = 0;\n        state.mode = NAME;\n        /* falls through */\n      case NAME:\n        if (state.flags & 0x0800) {\n          if (have === 0) { break inf_leave; }\n          copy = 0;\n          do {\n            // TODO: 2 or 1 bytes?\n            len = input[next + copy++];\n            /* use constant limit because in js we should not preallocate memory */\n            if (state.head && len &&\n                (state.length < 65536 /*state.head.name_max*/)) {\n              state.head.name += String.fromCharCode(len);\n            }\n          } while (len && copy < have);\n\n          if (state.flags & 0x0200) {\n            state.check = crc32(state.check, input, copy, next);\n          }\n          have -= copy;\n          next += copy;\n          if (len) { break inf_leave; }\n        }\n        else if (state.head) {\n          state.head.name = null;\n        }\n        state.length = 0;\n        state.mode = COMMENT;\n        /* falls through */\n      case COMMENT:\n        if (state.flags & 0x1000) {\n          if (have === 0) { break inf_leave; }\n          copy = 0;\n          do {\n            len = input[next + copy++];\n            /* use constant limit because in js we should not preallocate memory */\n            if (state.head && len &&\n                (state.length < 65536 /*state.head.comm_max*/)) {\n              state.head.comment += String.fromCharCode(len);\n            }\n          } while (len && copy < have);\n          if (state.flags & 0x0200) {\n            state.check = crc32(state.check, input, copy, next);\n          }\n          have -= copy;\n          next += copy;\n          if (len) { break inf_leave; }\n        }\n        else if (state.head) {\n          state.head.comment = null;\n        }\n        state.mode = HCRC;\n        /* falls through */\n      case HCRC:\n        if (state.flags & 0x0200) {\n          //=== NEEDBITS(16); */\n          while (bits < 16) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          if (hold !== (state.check & 0xffff)) {\n            strm.msg = 'header crc mismatch';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n        }\n        if (state.head) {\n          state.head.hcrc = ((state.flags >> 9) & 1);\n          state.head.done = true;\n        }\n        strm.adler = state.check = 0;\n        state.mode = TYPE;\n        break;\n      case DICTID:\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        strm.adler = state.check = zswap32(hold);\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = DICT;\n        /* falls through */\n      case DICT:\n        if (state.havedict === 0) {\n          //--- RESTORE() ---\n          strm.next_out = put;\n          strm.avail_out = left;\n          strm.next_in = next;\n          strm.avail_in = have;\n          state.hold = hold;\n          state.bits = bits;\n          //---\n          return Z_NEED_DICT;\n        }\n        strm.adler = state.check = 1/*adler32(0L, Z_NULL, 0)*/;\n        state.mode = TYPE;\n        /* falls through */\n      case TYPE:\n        if (flush === Z_BLOCK || flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case TYPEDO:\n        if (state.last) {\n          //--- BYTEBITS() ---//\n          hold >>>= bits & 7;\n          bits -= bits & 7;\n          //---//\n          state.mode = CHECK;\n          break;\n        }\n        //=== NEEDBITS(3); */\n        while (bits < 3) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.last = (hold & 0x01)/*BITS(1)*/;\n        //--- DROPBITS(1) ---//\n        hold >>>= 1;\n        bits -= 1;\n        //---//\n\n        switch ((hold & 0x03)/*BITS(2)*/) {\n          case 0:                             /* stored block */\n            //Tracev((stderr, \"inflate:     stored block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = STORED;\n            break;\n          case 1:                             /* fixed block */\n            fixedtables(state);\n            //Tracev((stderr, \"inflate:     fixed codes block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = LEN_;             /* decode codes */\n            if (flush === Z_TREES) {\n              //--- DROPBITS(2) ---//\n              hold >>>= 2;\n              bits -= 2;\n              //---//\n              break inf_leave;\n            }\n            break;\n          case 2:                             /* dynamic block */\n            //Tracev((stderr, \"inflate:     dynamic codes block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = TABLE;\n            break;\n          case 3:\n            strm.msg = 'invalid block type';\n            state.mode = BAD;\n        }\n        //--- DROPBITS(2) ---//\n        hold >>>= 2;\n        bits -= 2;\n        //---//\n        break;\n      case STORED:\n        //--- BYTEBITS() ---// /* go to byte boundary */\n        hold >>>= bits & 7;\n        bits -= bits & 7;\n        //---//\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if ((hold & 0xffff) !== ((hold >>> 16) ^ 0xffff)) {\n          strm.msg = 'invalid stored block lengths';\n          state.mode = BAD;\n          break;\n        }\n        state.length = hold & 0xffff;\n        //Tracev((stderr, \"inflate:       stored length %u\\n\",\n        //        state.length));\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = COPY_;\n        if (flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case COPY_:\n        state.mode = COPY;\n        /* falls through */\n      case COPY:\n        copy = state.length;\n        if (copy) {\n          if (copy > have) { copy = have; }\n          if (copy > left) { copy = left; }\n          if (copy === 0) { break inf_leave; }\n          //--- zmemcpy(put, next, copy); ---\n          utils.arraySet(output, input, next, copy, put);\n          //---//\n          have -= copy;\n          next += copy;\n          left -= copy;\n          put += copy;\n          state.length -= copy;\n          break;\n        }\n        //Tracev((stderr, \"inflate:       stored end\\n\"));\n        state.mode = TYPE;\n        break;\n      case TABLE:\n        //=== NEEDBITS(14); */\n        while (bits < 14) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.nlen = (hold & 0x1f)/*BITS(5)*/ + 257;\n        //--- DROPBITS(5) ---//\n        hold >>>= 5;\n        bits -= 5;\n        //---//\n        state.ndist = (hold & 0x1f)/*BITS(5)*/ + 1;\n        //--- DROPBITS(5) ---//\n        hold >>>= 5;\n        bits -= 5;\n        //---//\n        state.ncode = (hold & 0x0f)/*BITS(4)*/ + 4;\n        //--- DROPBITS(4) ---//\n        hold >>>= 4;\n        bits -= 4;\n        //---//\n//#ifndef PKZIP_BUG_WORKAROUND\n        if (state.nlen > 286 || state.ndist > 30) {\n          strm.msg = 'too many length or distance symbols';\n          state.mode = BAD;\n          break;\n        }\n//#endif\n        //Tracev((stderr, \"inflate:       table sizes ok\\n\"));\n        state.have = 0;\n        state.mode = LENLENS;\n        /* falls through */\n      case LENLENS:\n        while (state.have < state.ncode) {\n          //=== NEEDBITS(3);\n          while (bits < 3) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.lens[order[state.have++]] = (hold & 0x07);//BITS(3);\n          //--- DROPBITS(3) ---//\n          hold >>>= 3;\n          bits -= 3;\n          //---//\n        }\n        while (state.have < 19) {\n          state.lens[order[state.have++]] = 0;\n        }\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        //state.next = state.codes;\n        //state.lencode = state.next;\n        // Switch to use dynamic table\n        state.lencode = state.lendyn;\n        state.lenbits = 7;\n\n        opts = { bits: state.lenbits };\n        ret = inflate_table(CODES, state.lens, 0, 19, state.lencode, 0, state.work, opts);\n        state.lenbits = opts.bits;\n\n        if (ret) {\n          strm.msg = 'invalid code lengths set';\n          state.mode = BAD;\n          break;\n        }\n        //Tracev((stderr, \"inflate:       code lengths ok\\n\"));\n        state.have = 0;\n        state.mode = CODELENS;\n        /* falls through */\n      case CODELENS:\n        while (state.have < state.nlen + state.ndist) {\n          for (;;) {\n            here = state.lencode[hold & ((1 << state.lenbits) - 1)];/*BITS(state.lenbits)*/\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          if (here_val < 16) {\n            //--- DROPBITS(here.bits) ---//\n            hold >>>= here_bits;\n            bits -= here_bits;\n            //---//\n            state.lens[state.have++] = here_val;\n          }\n          else {\n            if (here_val === 16) {\n              //=== NEEDBITS(here.bits + 2);\n              n = here_bits + 2;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              if (state.have === 0) {\n                strm.msg = 'invalid bit length repeat';\n                state.mode = BAD;\n                break;\n              }\n              len = state.lens[state.have - 1];\n              copy = 3 + (hold & 0x03);//BITS(2);\n              //--- DROPBITS(2) ---//\n              hold >>>= 2;\n              bits -= 2;\n              //---//\n            }\n            else if (here_val === 17) {\n              //=== NEEDBITS(here.bits + 3);\n              n = here_bits + 3;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              len = 0;\n              copy = 3 + (hold & 0x07);//BITS(3);\n              //--- DROPBITS(3) ---//\n              hold >>>= 3;\n              bits -= 3;\n              //---//\n            }\n            else {\n              //=== NEEDBITS(here.bits + 7);\n              n = here_bits + 7;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              len = 0;\n              copy = 11 + (hold & 0x7f);//BITS(7);\n              //--- DROPBITS(7) ---//\n              hold >>>= 7;\n              bits -= 7;\n              //---//\n            }\n            if (state.have + copy > state.nlen + state.ndist) {\n              strm.msg = 'invalid bit length repeat';\n              state.mode = BAD;\n              break;\n            }\n            while (copy--) {\n              state.lens[state.have++] = len;\n            }\n          }\n        }\n\n        /* handle error breaks in while */\n        if (state.mode === BAD) { break; }\n\n        /* check for end-of-block code (better have one) */\n        if (state.lens[256] === 0) {\n          strm.msg = 'invalid code -- missing end-of-block';\n          state.mode = BAD;\n          break;\n        }\n\n        /* build code tables -- note: do not change the lenbits or distbits\n           values here (9 and 6) without reading the comments in inftrees.h\n           concerning the ENOUGH constants, which depend on those values */\n        state.lenbits = 9;\n\n        opts = { bits: state.lenbits };\n        ret = inflate_table(LENS, state.lens, 0, state.nlen, state.lencode, 0, state.work, opts);\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        // state.next_index = opts.table_index;\n        state.lenbits = opts.bits;\n        // state.lencode = state.next;\n\n        if (ret) {\n          strm.msg = 'invalid literal/lengths set';\n          state.mode = BAD;\n          break;\n        }\n\n        state.distbits = 6;\n        //state.distcode.copy(state.codes);\n        // Switch to use dynamic table\n        state.distcode = state.distdyn;\n        opts = { bits: state.distbits };\n        ret = inflate_table(DISTS, state.lens, state.nlen, state.ndist, state.distcode, 0, state.work, opts);\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        // state.next_index = opts.table_index;\n        state.distbits = opts.bits;\n        // state.distcode = state.next;\n\n        if (ret) {\n          strm.msg = 'invalid distances set';\n          state.mode = BAD;\n          break;\n        }\n        //Tracev((stderr, 'inflate:       codes ok\\n'));\n        state.mode = LEN_;\n        if (flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case LEN_:\n        state.mode = LEN;\n        /* falls through */\n      case LEN:\n        if (have >= 6 && left >= 258) {\n          //--- RESTORE() ---\n          strm.next_out = put;\n          strm.avail_out = left;\n          strm.next_in = next;\n          strm.avail_in = have;\n          state.hold = hold;\n          state.bits = bits;\n          //---\n          inflate_fast(strm, _out);\n          //--- LOAD() ---\n          put = strm.next_out;\n          output = strm.output;\n          left = strm.avail_out;\n          next = strm.next_in;\n          input = strm.input;\n          have = strm.avail_in;\n          hold = state.hold;\n          bits = state.bits;\n          //---\n\n          if (state.mode === TYPE) {\n            state.back = -1;\n          }\n          break;\n        }\n        state.back = 0;\n        for (;;) {\n          here = state.lencode[hold & ((1 << state.lenbits) - 1)];  /*BITS(state.lenbits)*/\n          here_bits = here >>> 24;\n          here_op = (here >>> 16) & 0xff;\n          here_val = here & 0xffff;\n\n          if (here_bits <= bits) { break; }\n          //--- PULLBYTE() ---//\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n          //---//\n        }\n        if (here_op && (here_op & 0xf0) === 0) {\n          last_bits = here_bits;\n          last_op = here_op;\n          last_val = here_val;\n          for (;;) {\n            here = state.lencode[last_val +\n                    ((hold & ((1 << (last_bits + last_op)) - 1))/*BITS(last.bits + last.op)*/ >> last_bits)];\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((last_bits + here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          //--- DROPBITS(last.bits) ---//\n          hold >>>= last_bits;\n          bits -= last_bits;\n          //---//\n          state.back += last_bits;\n        }\n        //--- DROPBITS(here.bits) ---//\n        hold >>>= here_bits;\n        bits -= here_bits;\n        //---//\n        state.back += here_bits;\n        state.length = here_val;\n        if (here_op === 0) {\n          //Tracevv((stderr, here.val >= 0x20 && here.val < 0x7f ?\n          //        \"inflate:         literal '%c'\\n\" :\n          //        \"inflate:         literal 0x%02x\\n\", here.val));\n          state.mode = LIT;\n          break;\n        }\n        if (here_op & 32) {\n          //Tracevv((stderr, \"inflate:         end of block\\n\"));\n          state.back = -1;\n          state.mode = TYPE;\n          break;\n        }\n        if (here_op & 64) {\n          strm.msg = 'invalid literal/length code';\n          state.mode = BAD;\n          break;\n        }\n        state.extra = here_op & 15;\n        state.mode = LENEXT;\n        /* falls through */\n      case LENEXT:\n        if (state.extra) {\n          //=== NEEDBITS(state.extra);\n          n = state.extra;\n          while (bits < n) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.length += hold & ((1 << state.extra) - 1)/*BITS(state.extra)*/;\n          //--- DROPBITS(state.extra) ---//\n          hold >>>= state.extra;\n          bits -= state.extra;\n          //---//\n          state.back += state.extra;\n        }\n        //Tracevv((stderr, \"inflate:         length %u\\n\", state.length));\n        state.was = state.length;\n        state.mode = DIST;\n        /* falls through */\n      case DIST:\n        for (;;) {\n          here = state.distcode[hold & ((1 << state.distbits) - 1)];/*BITS(state.distbits)*/\n          here_bits = here >>> 24;\n          here_op = (here >>> 16) & 0xff;\n          here_val = here & 0xffff;\n\n          if ((here_bits) <= bits) { break; }\n          //--- PULLBYTE() ---//\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n          //---//\n        }\n        if ((here_op & 0xf0) === 0) {\n          last_bits = here_bits;\n          last_op = here_op;\n          last_val = here_val;\n          for (;;) {\n            here = state.distcode[last_val +\n                    ((hold & ((1 << (last_bits + last_op)) - 1))/*BITS(last.bits + last.op)*/ >> last_bits)];\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((last_bits + here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          //--- DROPBITS(last.bits) ---//\n          hold >>>= last_bits;\n          bits -= last_bits;\n          //---//\n          state.back += last_bits;\n        }\n        //--- DROPBITS(here.bits) ---//\n        hold >>>= here_bits;\n        bits -= here_bits;\n        //---//\n        state.back += here_bits;\n        if (here_op & 64) {\n          strm.msg = 'invalid distance code';\n          state.mode = BAD;\n          break;\n        }\n        state.offset = here_val;\n        state.extra = (here_op) & 15;\n        state.mode = DISTEXT;\n        /* falls through */\n      case DISTEXT:\n        if (state.extra) {\n          //=== NEEDBITS(state.extra);\n          n = state.extra;\n          while (bits < n) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.offset += hold & ((1 << state.extra) - 1)/*BITS(state.extra)*/;\n          //--- DROPBITS(state.extra) ---//\n          hold >>>= state.extra;\n          bits -= state.extra;\n          //---//\n          state.back += state.extra;\n        }\n//#ifdef INFLATE_STRICT\n        if (state.offset > state.dmax) {\n          strm.msg = 'invalid distance too far back';\n          state.mode = BAD;\n          break;\n        }\n//#endif\n        //Tracevv((stderr, \"inflate:         distance %u\\n\", state.offset));\n        state.mode = MATCH;\n        /* falls through */\n      case MATCH:\n        if (left === 0) { break inf_leave; }\n        copy = _out - left;\n        if (state.offset > copy) {         /* copy from window */\n          copy = state.offset - copy;\n          if (copy > state.whave) {\n            if (state.sane) {\n              strm.msg = 'invalid distance too far back';\n              state.mode = BAD;\n              break;\n            }\n// (!) This block is disabled in zlib defaults,\n// don't enable it for binary compatibility\n//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR\n//          Trace((stderr, \"inflate.c too far\\n\"));\n//          copy -= state.whave;\n//          if (copy > state.length) { copy = state.length; }\n//          if (copy > left) { copy = left; }\n//          left -= copy;\n//          state.length -= copy;\n//          do {\n//            output[put++] = 0;\n//          } while (--copy);\n//          if (state.length === 0) { state.mode = LEN; }\n//          break;\n//#endif\n          }\n          if (copy > state.wnext) {\n            copy -= state.wnext;\n            from = state.wsize - copy;\n          }\n          else {\n            from = state.wnext - copy;\n          }\n          if (copy > state.length) { copy = state.length; }\n          from_source = state.window;\n        }\n        else {                              /* copy from output */\n          from_source = output;\n          from = put - state.offset;\n          copy = state.length;\n        }\n        if (copy > left) { copy = left; }\n        left -= copy;\n        state.length -= copy;\n        do {\n          output[put++] = from_source[from++];\n        } while (--copy);\n        if (state.length === 0) { state.mode = LEN; }\n        break;\n      case LIT:\n        if (left === 0) { break inf_leave; }\n        output[put++] = state.length;\n        left--;\n        state.mode = LEN;\n        break;\n      case CHECK:\n        if (state.wrap) {\n          //=== NEEDBITS(32);\n          while (bits < 32) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            // Use '|' instead of '+' to make sure that result is signed\n            hold |= input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          _out -= left;\n          strm.total_out += _out;\n          state.total += _out;\n          if (_out) {\n            strm.adler = state.check =\n                /*UPDATE(state.check, put - _out, _out);*/\n                (state.flags ? crc32(state.check, output, _out, put - _out) : adler32(state.check, output, _out, put - _out));\n\n          }\n          _out = left;\n          // NB: crc32 stored as signed 32-bit int, zswap32 returns signed too\n          if ((state.flags ? hold : zswap32(hold)) !== state.check) {\n            strm.msg = 'incorrect data check';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          //Tracev((stderr, \"inflate:   check matches trailer\\n\"));\n        }\n        state.mode = LENGTH;\n        /* falls through */\n      case LENGTH:\n        if (state.wrap && state.flags) {\n          //=== NEEDBITS(32);\n          while (bits < 32) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          if (hold !== (state.total & 0xffffffff)) {\n            strm.msg = 'incorrect length check';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          //Tracev((stderr, \"inflate:   length matches trailer\\n\"));\n        }\n        state.mode = DONE;\n        /* falls through */\n      case DONE:\n        ret = Z_STREAM_END;\n        break inf_leave;\n      case BAD:\n        ret = Z_DATA_ERROR;\n        break inf_leave;\n      case MEM:\n        return Z_MEM_ERROR;\n      case SYNC:\n        /* falls through */\n      default:\n        return Z_STREAM_ERROR;\n    }\n  }\n\n  // inf_leave <- here is real place for \"goto inf_leave\", emulated via \"break inf_leave\"\n\n  /*\n     Return from inflate(), updating the total counts and the check value.\n     If there was no progress during the inflate() call, return a buffer\n     error.  Call updatewindow() to create and/or update the window state.\n     Note: a memory error from inflate() is non-recoverable.\n   */\n\n  //--- RESTORE() ---\n  strm.next_out = put;\n  strm.avail_out = left;\n  strm.next_in = next;\n  strm.avail_in = have;\n  state.hold = hold;\n  state.bits = bits;\n  //---\n\n  if (state.wsize || (_out !== strm.avail_out && state.mode < BAD &&\n                      (state.mode < CHECK || flush !== Z_FINISH))) {\n    if (updatewindow(strm, strm.output, strm.next_out, _out - strm.avail_out)) {\n      state.mode = MEM;\n      return Z_MEM_ERROR;\n    }\n  }\n  _in -= strm.avail_in;\n  _out -= strm.avail_out;\n  strm.total_in += _in;\n  strm.total_out += _out;\n  state.total += _out;\n  if (state.wrap && _out) {\n    strm.adler = state.check = /*UPDATE(state.check, strm.next_out - _out, _out);*/\n      (state.flags ? crc32(state.check, output, _out, strm.next_out - _out) : adler32(state.check, output, _out, strm.next_out - _out));\n  }\n  strm.data_type = state.bits + (state.last ? 64 : 0) +\n                    (state.mode === TYPE ? 128 : 0) +\n                    (state.mode === LEN_ || state.mode === COPY_ ? 256 : 0);\n  if (((_in === 0 && _out === 0) || flush === Z_FINISH) && ret === Z_OK) {\n    ret = Z_BUF_ERROR;\n  }\n  return ret;\n}\n\nfunction inflateEnd(strm) {\n\n  if (!strm || !strm.state /*|| strm->zfree == (free_func)0*/) {\n    return Z_STREAM_ERROR;\n  }\n\n  var state = strm.state;\n  if (state.window) {\n    state.window = null;\n  }\n  strm.state = null;\n  return Z_OK;\n}\n\nfunction inflateGetHeader(strm, head) {\n  var state;\n\n  /* check state */\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  state = strm.state;\n  if ((state.wrap & 2) === 0) { return Z_STREAM_ERROR; }\n\n  /* save header structure */\n  state.head = head;\n  head.done = false;\n  return Z_OK;\n}\n\nfunction inflateSetDictionary(strm, dictionary) {\n  var dictLength = dictionary.length;\n\n  var state;\n  var dictid;\n  var ret;\n\n  /* check state */\n  if (!strm /* == Z_NULL */ || !strm.state /* == Z_NULL */) { return Z_STREAM_ERROR; }\n  state = strm.state;\n\n  if (state.wrap !== 0 && state.mode !== DICT) {\n    return Z_STREAM_ERROR;\n  }\n\n  /* check for correct dictionary identifier */\n  if (state.mode === DICT) {\n    dictid = 1; /* adler32(0, null, 0)*/\n    /* dictid = adler32(dictid, dictionary, dictLength); */\n    dictid = adler32(dictid, dictionary, dictLength, 0);\n    if (dictid !== state.check) {\n      return Z_DATA_ERROR;\n    }\n  }\n  /* copy dictionary to window using updatewindow(), which will amend the\n   existing dictionary if appropriate */\n  ret = updatewindow(strm, dictionary, dictLength, dictLength);\n  if (ret) {\n    state.mode = MEM;\n    return Z_MEM_ERROR;\n  }\n  state.havedict = 1;\n  // Tracev((stderr, \"inflate:   dictionary set\\n\"));\n  return Z_OK;\n}\n\nexports.inflateReset = inflateReset;\nexports.inflateReset2 = inflateReset2;\nexports.inflateResetKeep = inflateResetKeep;\nexports.inflateInit = inflateInit;\nexports.inflateInit2 = inflateInit2;\nexports.inflate = inflate;\nexports.inflateEnd = inflateEnd;\nexports.inflateGetHeader = inflateGetHeader;\nexports.inflateSetDictionary = inflateSetDictionary;\nexports.inflateInfo = 'pako inflate (from Nodeca project)';\n\n/* Not implemented\nexports.inflateCopy = inflateCopy;\nexports.inflateGetDictionary = inflateGetDictionary;\nexports.inflateMark = inflateMark;\nexports.inflatePrime = inflatePrime;\nexports.inflateSync = inflateSync;\nexports.inflateSyncPoint = inflateSyncPoint;\nexports.inflateUndermine = inflateUndermine;\n*/\n\n\n//# sourceURL=webpack:///../node_modules/pako/lib/zlib/inflate.js?");

/***/ }),

/***/ "../node_modules/pako/lib/zlib/inftrees.js":
/*!*************************************************!*\
  !*** ../node_modules/pako/lib/zlib/inftrees.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nvar utils = __webpack_require__(/*! ../utils/common */ \"../node_modules/pako/lib/utils/common.js\");\n\nvar MAXBITS = 15;\nvar ENOUGH_LENS = 852;\nvar ENOUGH_DISTS = 592;\n//var ENOUGH = (ENOUGH_LENS+ENOUGH_DISTS);\n\nvar CODES = 0;\nvar LENS = 1;\nvar DISTS = 2;\n\nvar lbase = [ /* Length codes 257..285 base */\n  3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31,\n  35, 43, 51, 59, 67, 83, 99, 115, 131, 163, 195, 227, 258, 0, 0\n];\n\nvar lext = [ /* Length codes 257..285 extra */\n  16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18,\n  19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 16, 72, 78\n];\n\nvar dbase = [ /* Distance codes 0..29 base */\n  1, 2, 3, 4, 5, 7, 9, 13, 17, 25, 33, 49, 65, 97, 129, 193,\n  257, 385, 513, 769, 1025, 1537, 2049, 3073, 4097, 6145,\n  8193, 12289, 16385, 24577, 0, 0\n];\n\nvar dext = [ /* Distance codes 0..29 extra */\n  16, 16, 16, 16, 17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22,\n  23, 23, 24, 24, 25, 25, 26, 26, 27, 27,\n  28, 28, 29, 29, 64, 64\n];\n\nmodule.exports = function inflate_table(type, lens, lens_index, codes, table, table_index, work, opts)\n{\n  var bits = opts.bits;\n      //here = opts.here; /* table entry for duplication */\n\n  var len = 0;               /* a code's length in bits */\n  var sym = 0;               /* index of code symbols */\n  var min = 0, max = 0;          /* minimum and maximum code lengths */\n  var root = 0;              /* number of index bits for root table */\n  var curr = 0;              /* number of index bits for current table */\n  var drop = 0;              /* code bits to drop for sub-table */\n  var left = 0;                   /* number of prefix codes available */\n  var used = 0;              /* code entries in table used */\n  var huff = 0;              /* Huffman code */\n  var incr;              /* for incrementing code, index */\n  var fill;              /* index for replicating entries */\n  var low;               /* low bits for current root entry */\n  var mask;              /* mask for low root bits */\n  var next;             /* next available space in table */\n  var base = null;     /* base value table to use */\n  var base_index = 0;\n//  var shoextra;    /* extra bits table to use */\n  var end;                    /* use base and extra for symbol > end */\n  var count = new utils.Buf16(MAXBITS + 1); //[MAXBITS+1];    /* number of codes of each length */\n  var offs = new utils.Buf16(MAXBITS + 1); //[MAXBITS+1];     /* offsets in table for each length */\n  var extra = null;\n  var extra_index = 0;\n\n  var here_bits, here_op, here_val;\n\n  /*\n   Process a set of code lengths to create a canonical Huffman code.  The\n   code lengths are lens[0..codes-1].  Each length corresponds to the\n   symbols 0..codes-1.  The Huffman code is generated by first sorting the\n   symbols by length from short to long, and retaining the symbol order\n   for codes with equal lengths.  Then the code starts with all zero bits\n   for the first code of the shortest length, and the codes are integer\n   increments for the same length, and zeros are appended as the length\n   increases.  For the deflate format, these bits are stored backwards\n   from their more natural integer increment ordering, and so when the\n   decoding tables are built in the large loop below, the integer codes\n   are incremented backwards.\n\n   This routine assumes, but does not check, that all of the entries in\n   lens[] are in the range 0..MAXBITS.  The caller must assure this.\n   1..MAXBITS is interpreted as that code length.  zero means that that\n   symbol does not occur in this code.\n\n   The codes are sorted by computing a count of codes for each length,\n   creating from that a table of starting indices for each length in the\n   sorted table, and then entering the symbols in order in the sorted\n   table.  The sorted table is work[], with that space being provided by\n   the caller.\n\n   The length counts are used for other purposes as well, i.e. finding\n   the minimum and maximum length codes, determining if there are any\n   codes at all, checking for a valid set of lengths, and looking ahead\n   at length counts to determine sub-table sizes when building the\n   decoding tables.\n   */\n\n  /* accumulate lengths for codes (assumes lens[] all in 0..MAXBITS) */\n  for (len = 0; len <= MAXBITS; len++) {\n    count[len] = 0;\n  }\n  for (sym = 0; sym < codes; sym++) {\n    count[lens[lens_index + sym]]++;\n  }\n\n  /* bound code lengths, force root to be within code lengths */\n  root = bits;\n  for (max = MAXBITS; max >= 1; max--) {\n    if (count[max] !== 0) { break; }\n  }\n  if (root > max) {\n    root = max;\n  }\n  if (max === 0) {                     /* no symbols to code at all */\n    //table.op[opts.table_index] = 64;  //here.op = (var char)64;    /* invalid code marker */\n    //table.bits[opts.table_index] = 1;   //here.bits = (var char)1;\n    //table.val[opts.table_index++] = 0;   //here.val = (var short)0;\n    table[table_index++] = (1 << 24) | (64 << 16) | 0;\n\n\n    //table.op[opts.table_index] = 64;\n    //table.bits[opts.table_index] = 1;\n    //table.val[opts.table_index++] = 0;\n    table[table_index++] = (1 << 24) | (64 << 16) | 0;\n\n    opts.bits = 1;\n    return 0;     /* no symbols, but wait for decoding to report error */\n  }\n  for (min = 1; min < max; min++) {\n    if (count[min] !== 0) { break; }\n  }\n  if (root < min) {\n    root = min;\n  }\n\n  /* check for an over-subscribed or incomplete set of lengths */\n  left = 1;\n  for (len = 1; len <= MAXBITS; len++) {\n    left <<= 1;\n    left -= count[len];\n    if (left < 0) {\n      return -1;\n    }        /* over-subscribed */\n  }\n  if (left > 0 && (type === CODES || max !== 1)) {\n    return -1;                      /* incomplete set */\n  }\n\n  /* generate offsets into symbol table for each length for sorting */\n  offs[1] = 0;\n  for (len = 1; len < MAXBITS; len++) {\n    offs[len + 1] = offs[len] + count[len];\n  }\n\n  /* sort symbols by length, by symbol order within each length */\n  for (sym = 0; sym < codes; sym++) {\n    if (lens[lens_index + sym] !== 0) {\n      work[offs[lens[lens_index + sym]]++] = sym;\n    }\n  }\n\n  /*\n   Create and fill in decoding tables.  In this loop, the table being\n   filled is at next and has curr index bits.  The code being used is huff\n   with length len.  That code is converted to an index by dropping drop\n   bits off of the bottom.  For codes where len is less than drop + curr,\n   those top drop + curr - len bits are incremented through all values to\n   fill the table with replicated entries.\n\n   root is the number of index bits for the root table.  When len exceeds\n   root, sub-tables are created pointed to by the root entry with an index\n   of the low root bits of huff.  This is saved in low to check for when a\n   new sub-table should be started.  drop is zero when the root table is\n   being filled, and drop is root when sub-tables are being filled.\n\n   When a new sub-table is needed, it is necessary to look ahead in the\n   code lengths to determine what size sub-table is needed.  The length\n   counts are used for this, and so count[] is decremented as codes are\n   entered in the tables.\n\n   used keeps track of how many table entries have been allocated from the\n   provided *table space.  It is checked for LENS and DIST tables against\n   the constants ENOUGH_LENS and ENOUGH_DISTS to guard against changes in\n   the initial root table size constants.  See the comments in inftrees.h\n   for more information.\n\n   sym increments through all symbols, and the loop terminates when\n   all codes of length max, i.e. all codes, have been processed.  This\n   routine permits incomplete codes, so another loop after this one fills\n   in the rest of the decoding tables with invalid code markers.\n   */\n\n  /* set up for code type */\n  // poor man optimization - use if-else instead of switch,\n  // to avoid deopts in old v8\n  if (type === CODES) {\n    base = extra = work;    /* dummy value--not used */\n    end = 19;\n\n  } else if (type === LENS) {\n    base = lbase;\n    base_index -= 257;\n    extra = lext;\n    extra_index -= 257;\n    end = 256;\n\n  } else {                    /* DISTS */\n    base = dbase;\n    extra = dext;\n    end = -1;\n  }\n\n  /* initialize opts for loop */\n  huff = 0;                   /* starting code */\n  sym = 0;                    /* starting code symbol */\n  len = min;                  /* starting code length */\n  next = table_index;              /* current table to fill in */\n  curr = root;                /* current table index bits */\n  drop = 0;                   /* current bits to drop from code for index */\n  low = -1;                   /* trigger new sub-table when len > root */\n  used = 1 << root;          /* use root table entries */\n  mask = used - 1;            /* mask for comparing low */\n\n  /* check available table space */\n  if ((type === LENS && used > ENOUGH_LENS) ||\n    (type === DISTS && used > ENOUGH_DISTS)) {\n    return 1;\n  }\n\n  /* process all codes and make table entries */\n  for (;;) {\n    /* create table entry */\n    here_bits = len - drop;\n    if (work[sym] < end) {\n      here_op = 0;\n      here_val = work[sym];\n    }\n    else if (work[sym] > end) {\n      here_op = extra[extra_index + work[sym]];\n      here_val = base[base_index + work[sym]];\n    }\n    else {\n      here_op = 32 + 64;         /* end of block */\n      here_val = 0;\n    }\n\n    /* replicate for those indices with low len bits equal to huff */\n    incr = 1 << (len - drop);\n    fill = 1 << curr;\n    min = fill;                 /* save offset to next table */\n    do {\n      fill -= incr;\n      table[next + (huff >> drop) + fill] = (here_bits << 24) | (here_op << 16) | here_val |0;\n    } while (fill !== 0);\n\n    /* backwards increment the len-bit code huff */\n    incr = 1 << (len - 1);\n    while (huff & incr) {\n      incr >>= 1;\n    }\n    if (incr !== 0) {\n      huff &= incr - 1;\n      huff += incr;\n    } else {\n      huff = 0;\n    }\n\n    /* go to next symbol, update count, len */\n    sym++;\n    if (--count[len] === 0) {\n      if (len === max) { break; }\n      len = lens[lens_index + work[sym]];\n    }\n\n    /* create new sub-table if needed */\n    if (len > root && (huff & mask) !== low) {\n      /* if first time, transition to sub-tables */\n      if (drop === 0) {\n        drop = root;\n      }\n\n      /* increment past last table */\n      next += min;            /* here min is 1 << curr */\n\n      /* determine length of next table */\n      curr = len - drop;\n      left = 1 << curr;\n      while (curr + drop < max) {\n        left -= count[curr + drop];\n        if (left <= 0) { break; }\n        curr++;\n        left <<= 1;\n      }\n\n      /* check for enough space */\n      used += 1 << curr;\n      if ((type === LENS && used > ENOUGH_LENS) ||\n        (type === DISTS && used > ENOUGH_DISTS)) {\n        return 1;\n      }\n\n      /* point entry in root table to sub-table */\n      low = huff & mask;\n      /*table.op[low] = curr;\n      table.bits[low] = root;\n      table.val[low] = next - opts.table_index;*/\n      table[low] = (root << 24) | (curr << 16) | (next - table_index) |0;\n    }\n  }\n\n  /* fill in remaining table entry if code is incomplete (guaranteed to have\n   at most one remaining entry, since if the code is incomplete, the\n   maximum code length that was allowed to get this far is one bit) */\n  if (huff !== 0) {\n    //table.op[next + huff] = 64;            /* invalid code marker */\n    //table.bits[next + huff] = len - drop;\n    //table.val[next + huff] = 0;\n    table[next + huff] = ((len - drop) << 24) | (64 << 16) |0;\n  }\n\n  /* set return parameters */\n  //opts.table_index += used;\n  opts.bits = root;\n  return 0;\n};\n\n\n//# sourceURL=webpack:///../node_modules/pako/lib/zlib/inftrees.js?");

/***/ }),

/***/ "../node_modules/pako/lib/zlib/messages.js":
/*!*************************************************!*\
  !*** ../node_modules/pako/lib/zlib/messages.js ***!
  \*************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nmodule.exports = {\n  2:      'need dictionary',     /* Z_NEED_DICT       2  */\n  1:      'stream end',          /* Z_STREAM_END      1  */\n  0:      '',                    /* Z_OK              0  */\n  '-1':   'file error',          /* Z_ERRNO         (-1) */\n  '-2':   'stream error',        /* Z_STREAM_ERROR  (-2) */\n  '-3':   'data error',          /* Z_DATA_ERROR    (-3) */\n  '-4':   'insufficient memory', /* Z_MEM_ERROR     (-4) */\n  '-5':   'buffer error',        /* Z_BUF_ERROR     (-5) */\n  '-6':   'incompatible version' /* Z_VERSION_ERROR (-6) */\n};\n\n\n//# sourceURL=webpack:///../node_modules/pako/lib/zlib/messages.js?");

/***/ }),

/***/ "../node_modules/pako/lib/zlib/zstream.js":
/*!************************************************!*\
  !*** ../node_modules/pako/lib/zlib/zstream.js ***!
  \************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nfunction ZStream() {\n  /* next input byte */\n  this.input = null; // JS specific, because we have no pointers\n  this.next_in = 0;\n  /* number of bytes available at input */\n  this.avail_in = 0;\n  /* total number of input bytes read so far */\n  this.total_in = 0;\n  /* next output byte should be put there */\n  this.output = null; // JS specific, because we have no pointers\n  this.next_out = 0;\n  /* remaining free space at output */\n  this.avail_out = 0;\n  /* total number of bytes output so far */\n  this.total_out = 0;\n  /* last error message, NULL if no error */\n  this.msg = ''/*Z_NULL*/;\n  /* not visible by applications */\n  this.state = null;\n  /* best guess about the data type: binary or text */\n  this.data_type = 2/*Z_UNKNOWN*/;\n  /* adler32 value of the uncompressed data */\n  this.adler = 0;\n}\n\nmodule.exports = ZStream;\n\n\n//# sourceURL=webpack:///../node_modules/pako/lib/zlib/zstream.js?");

/***/ }),

/***/ "../node_modules/readable-stream/errors-browser.js":
/*!*********************************************************!*\
  !*** ../node_modules/readable-stream/errors-browser.js ***!
  \*********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\n\nvar codes = {};\n\nfunction createErrorType(code, message, Base) {\n  if (!Base) {\n    Base = Error;\n  }\n\n  function getMessage(arg1, arg2, arg3) {\n    if (typeof message === 'string') {\n      return message;\n    } else {\n      return message(arg1, arg2, arg3);\n    }\n  }\n\n  var NodeError =\n  /*#__PURE__*/\n  function (_Base) {\n    _inheritsLoose(NodeError, _Base);\n\n    function NodeError(arg1, arg2, arg3) {\n      return _Base.call(this, getMessage(arg1, arg2, arg3)) || this;\n    }\n\n    return NodeError;\n  }(Base);\n\n  NodeError.prototype.name = Base.name;\n  NodeError.prototype.code = code;\n  codes[code] = NodeError;\n} // https://github.com/nodejs/node/blob/v10.8.0/lib/internal/errors.js\n\n\nfunction oneOf(expected, thing) {\n  if (Array.isArray(expected)) {\n    var len = expected.length;\n    expected = expected.map(function (i) {\n      return String(i);\n    });\n\n    if (len > 2) {\n      return \"one of \".concat(thing, \" \").concat(expected.slice(0, len - 1).join(', '), \", or \") + expected[len - 1];\n    } else if (len === 2) {\n      return \"one of \".concat(thing, \" \").concat(expected[0], \" or \").concat(expected[1]);\n    } else {\n      return \"of \".concat(thing, \" \").concat(expected[0]);\n    }\n  } else {\n    return \"of \".concat(thing, \" \").concat(String(expected));\n  }\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/startsWith\n\n\nfunction startsWith(str, search, pos) {\n  return str.substr(!pos || pos < 0 ? 0 : +pos, search.length) === search;\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/endsWith\n\n\nfunction endsWith(str, search, this_len) {\n  if (this_len === undefined || this_len > str.length) {\n    this_len = str.length;\n  }\n\n  return str.substring(this_len - search.length, this_len) === search;\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/includes\n\n\nfunction includes(str, search, start) {\n  if (typeof start !== 'number') {\n    start = 0;\n  }\n\n  if (start + search.length > str.length) {\n    return false;\n  } else {\n    return str.indexOf(search, start) !== -1;\n  }\n}\n\ncreateErrorType('ERR_INVALID_OPT_VALUE', function (name, value) {\n  return 'The value \"' + value + '\" is invalid for option \"' + name + '\"';\n}, TypeError);\ncreateErrorType('ERR_INVALID_ARG_TYPE', function (name, expected, actual) {\n  // determiner: 'must be' or 'must not be'\n  var determiner;\n\n  if (typeof expected === 'string' && startsWith(expected, 'not ')) {\n    determiner = 'must not be';\n    expected = expected.replace(/^not /, '');\n  } else {\n    determiner = 'must be';\n  }\n\n  var msg;\n\n  if (endsWith(name, ' argument')) {\n    // For cases like 'first argument'\n    msg = \"The \".concat(name, \" \").concat(determiner, \" \").concat(oneOf(expected, 'type'));\n  } else {\n    var type = includes(name, '.') ? 'property' : 'argument';\n    msg = \"The \\\"\".concat(name, \"\\\" \").concat(type, \" \").concat(determiner, \" \").concat(oneOf(expected, 'type'));\n  }\n\n  msg += \". Received type \".concat(typeof actual);\n  return msg;\n}, TypeError);\ncreateErrorType('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF');\ncreateErrorType('ERR_METHOD_NOT_IMPLEMENTED', function (name) {\n  return 'The ' + name + ' method is not implemented';\n});\ncreateErrorType('ERR_STREAM_PREMATURE_CLOSE', 'Premature close');\ncreateErrorType('ERR_STREAM_DESTROYED', function (name) {\n  return 'Cannot call ' + name + ' after a stream was destroyed';\n});\ncreateErrorType('ERR_MULTIPLE_CALLBACK', 'Callback called multiple times');\ncreateErrorType('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable');\ncreateErrorType('ERR_STREAM_WRITE_AFTER_END', 'write after end');\ncreateErrorType('ERR_STREAM_NULL_VALUES', 'May not write null values to stream', TypeError);\ncreateErrorType('ERR_UNKNOWN_ENCODING', function (arg) {\n  return 'Unknown encoding: ' + arg;\n}, TypeError);\ncreateErrorType('ERR_STREAM_UNSHIFT_AFTER_END_EVENT', 'stream.unshift() after end event');\nmodule.exports.codes = codes;\n\n\n//# sourceURL=webpack:///../node_modules/readable-stream/errors-browser.js?");

/***/ }),

/***/ "../node_modules/readable-stream/lib/_stream_duplex.js":
/*!*************************************************************!*\
  !*** ../node_modules/readable-stream/lib/_stream_duplex.js ***!
  \*************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n/*<replacement>*/\n\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n\n  for (var key in obj) {\n    keys.push(key);\n  }\n\n  return keys;\n};\n/*</replacement>*/\n\n\nmodule.exports = Duplex;\n\nvar Readable = __webpack_require__(/*! ./_stream_readable */ \"../node_modules/readable-stream/lib/_stream_readable.js\");\n\nvar Writable = __webpack_require__(/*! ./_stream_writable */ \"../node_modules/readable-stream/lib/_stream_writable.js\");\n\n__webpack_require__(/*! inherits */ \"../node_modules/inherits/inherits_browser.js\")(Duplex, Readable);\n\n{\n  // Allow the keys array to be GC'ed.\n  var keys = objectKeys(Writable.prototype);\n\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n  Readable.call(this, options);\n  Writable.call(this, options);\n  this.allowHalfOpen = true;\n\n  if (options) {\n    if (options.readable === false) this.readable = false;\n    if (options.writable === false) this.writable = false;\n\n    if (options.allowHalfOpen === false) {\n      this.allowHalfOpen = false;\n      this.once('end', onend);\n    }\n  }\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.highWaterMark;\n  }\n});\nObject.defineProperty(Duplex.prototype, 'writableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState && this._writableState.getBuffer();\n  }\n});\nObject.defineProperty(Duplex.prototype, 'writableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.length;\n  }\n}); // the no-half-open enforcer\n\nfunction onend() {\n  // If the writable side ended, then we're ok.\n  if (this._writableState.ended) return; // no more data can be written.\n  // But allow more writes to happen in this tick.\n\n  process.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\n//# sourceURL=webpack:///../node_modules/readable-stream/lib/_stream_duplex.js?");

/***/ }),

/***/ "../node_modules/readable-stream/lib/_stream_passthrough.js":
/*!******************************************************************!*\
  !*** ../node_modules/readable-stream/lib/_stream_passthrough.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n\nmodule.exports = PassThrough;\n\nvar Transform = __webpack_require__(/*! ./_stream_transform */ \"../node_modules/readable-stream/lib/_stream_transform.js\");\n\n__webpack_require__(/*! inherits */ \"../node_modules/inherits/inherits_browser.js\")(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};\n\n//# sourceURL=webpack:///../node_modules/readable-stream/lib/_stream_passthrough.js?");

/***/ }),

/***/ "../node_modules/readable-stream/lib/_stream_readable.js":
/*!***************************************************************!*\
  !*** ../node_modules/readable-stream/lib/_stream_readable.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\nmodule.exports = Readable;\n/*<replacement>*/\n\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n/*<replacement>*/\n\nvar EE = __webpack_require__(/*! events */ \"../node_modules/events/events.js\").EventEmitter;\n\nvar EElistenerCount = function EElistenerCount(emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\n\n\nvar Stream = __webpack_require__(/*! ./internal/streams/stream */ \"../node_modules/readable-stream/lib/internal/streams/stream-browser.js\");\n/*</replacement>*/\n\n\nvar Buffer = __webpack_require__(/*! buffer */ \"?5f0e\").Buffer;\n\nvar OurUint8Array = __webpack_require__.g.Uint8Array || function () {};\n\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\n\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n/*<replacement>*/\n\n\nvar debugUtil = __webpack_require__(/*! util */ \"?af24\");\n\nvar debug;\n\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function debug() {};\n}\n/*</replacement>*/\n\n\nvar BufferList = __webpack_require__(/*! ./internal/streams/buffer_list */ \"../node_modules/readable-stream/lib/internal/streams/buffer_list.js\");\n\nvar destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ \"../node_modules/readable-stream/lib/internal/streams/destroy.js\");\n\nvar _require = __webpack_require__(/*! ./internal/streams/state */ \"../node_modules/readable-stream/lib/internal/streams/state.js\"),\n    getHighWaterMark = _require.getHighWaterMark;\n\nvar _require$codes = __webpack_require__(/*! ../errors */ \"../node_modules/readable-stream/errors-browser.js\").codes,\n    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n    ERR_STREAM_PUSH_AFTER_EOF = _require$codes.ERR_STREAM_PUSH_AFTER_EOF,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_STREAM_UNSHIFT_AFTER_END_EVENT = _require$codes.ERR_STREAM_UNSHIFT_AFTER_END_EVENT; // Lazy loaded to improve the startup performance.\n\n\nvar StringDecoder;\nvar createReadableStreamAsyncIterator;\nvar from;\n\n__webpack_require__(/*! inherits */ \"../node_modules/inherits/inherits_browser.js\")(Readable, Stream);\n\nvar errorOrDestroy = destroyImpl.errorOrDestroy;\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn); // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (Array.isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream, isDuplex) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"../node_modules/readable-stream/lib/_stream_duplex.js\");\n  options = options || {}; // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode; // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n\n  this.highWaterMark = getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex); // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false; // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n\n  this.sync = true; // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n  this.paused = true; // Should close be emitted on destroy. Defaults to true.\n\n  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'end' (and potentially 'finish')\n\n  this.autoDestroy = !!options.autoDestroy; // has it been destroyed\n\n  this.destroyed = false; // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n\n  this.defaultEncoding = options.defaultEncoding || 'utf8'; // the number of writers that are awaiting a drain event in .pipe()s\n\n  this.awaitDrain = 0; // if true, a maybeReadMore has been scheduled\n\n  this.readingMore = false;\n  this.decoder = null;\n  this.encoding = null;\n\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = __webpack_require__(/*! string_decoder/ */ \"../node_modules/string_decoder/lib/string_decoder.js\").StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"../node_modules/readable-stream/lib/_stream_duplex.js\");\n  if (!(this instanceof Readable)) return new Readable(options); // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the ReadableState constructor, at least with V8 6.5\n\n  var isDuplex = this instanceof Duplex;\n  this._readableState = new ReadableState(options, this, isDuplex); // legacy\n\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined) {\n      return false;\n    }\n\n    return this._readableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._readableState.destroyed = value;\n  }\n});\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\n\nReadable.prototype._destroy = function (err, cb) {\n  cb(err);\n}; // Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\n\n\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n}; // Unshift should *always* be something directly out of read()\n\n\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  debug('readableAddChunk', chunk);\n  var state = stream._readableState;\n\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n\n    if (er) {\n      errorOrDestroy(stream, er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF());\n      } else if (state.destroyed) {\n        return false;\n      } else {\n        state.reading = false;\n\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n      maybeReadMore(stream, state);\n    }\n  } // We can push more data if we are below the highWaterMark.\n  // Also, if we have no data yet, we can stand some more bytes.\n  // This is to work around cases where hwm=0, such as the repl.\n\n\n  return !state.ended && (state.length < state.highWaterMark || state.length === 0);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    state.awaitDrain = 0;\n    stream.emit('data', chunk);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n    if (state.needReadable) emitReadable(stream);\n  }\n\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);\n  }\n\n  return er;\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n}; // backwards compatibility.\n\n\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = __webpack_require__(/*! string_decoder/ */ \"../node_modules/string_decoder/lib/string_decoder.js\").StringDecoder;\n  var decoder = new StringDecoder(enc);\n  this._readableState.decoder = decoder; // If setEncoding(null), decoder.encoding equals utf8\n\n  this._readableState.encoding = this._readableState.decoder.encoding; // Iterate over current buffer to convert already stored Buffers:\n\n  var p = this._readableState.buffer.head;\n  var content = '';\n\n  while (p !== null) {\n    content += decoder.write(p.data);\n    p = p.next;\n  }\n\n  this._readableState.buffer.clear();\n\n  if (content !== '') this._readableState.buffer.push(content);\n  this._readableState.length = content.length;\n  return this;\n}; // Don't raise the hwm > 1GB\n\n\nvar MAX_HWM = 0x40000000;\n\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    // TODO(ronag): Throw ERR_VALUE_OUT_OF_RANGE.\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n\n  return n;\n} // This function is designed to be inlinable, so please take care when making\n// changes to the function body.\n\n\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  } // If we're asking for more than the current hwm, then raise the hwm.\n\n\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n; // Don't have enough\n\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n\n  return state.length;\n} // you can override either this method, or the async _read(n) below.\n\n\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n  if (n !== 0) state.emittedReadable = false; // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n\n  if (n === 0 && state.needReadable && ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state); // if we've ended, and we're now clear, then finish it up.\n\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  } // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n  // if we need a readable event, then we need to do some reading.\n\n\n  var doRead = state.needReadable;\n  debug('need readable', doRead); // if we currently have less than the highWaterMark, then also read some\n\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  } // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n\n\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true; // if the length is currently zero, then we *need* a readable event.\n\n    if (state.length === 0) state.needReadable = true; // call internal read method\n\n    this._read(state.highWaterMark);\n\n    state.sync = false; // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = state.length <= state.highWaterMark;\n    n = 0;\n  } else {\n    state.length -= n;\n    state.awaitDrain = 0;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true; // If we tried to read() past the EOF, then emit end on the next tick.\n\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  debug('onEofChunk');\n  if (state.ended) return;\n\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n\n  state.ended = true;\n\n  if (state.sync) {\n    // if we are sync, wait until next tick to emit the data.\n    // Otherwise we risk emitting data in the flow()\n    // the readable code triggers during a read() call\n    emitReadable(stream);\n  } else {\n    // emit 'readable' now to make sure it gets picked up.\n    state.needReadable = false;\n\n    if (!state.emittedReadable) {\n      state.emittedReadable = true;\n      emitReadable_(stream);\n    }\n  }\n} // Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\n\n\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  debug('emitReadable', state.needReadable, state.emittedReadable);\n  state.needReadable = false;\n\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    process.nextTick(emitReadable_, stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  var state = stream._readableState;\n  debug('emitReadable_', state.destroyed, state.length, state.ended);\n\n  if (!state.destroyed && (state.length || state.ended)) {\n    stream.emit('readable');\n    state.emittedReadable = false;\n  } // The stream needs another readable event if\n  // 1. It is not flowing, as the flow mechanism will take\n  //    care of it.\n  // 2. It is not ended.\n  // 3. It is below the highWaterMark, so we can schedule\n  //    another readable later.\n\n\n  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;\n  flow(stream);\n} // at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\n\n\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    process.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  // Attempt to read more data if we should.\n  //\n  // The conditions for reading more data are (one of):\n  // - Not enough data buffered (state.length < state.highWaterMark). The loop\n  //   is responsible for filling the buffer with enough data if such data\n  //   is available. If highWaterMark is 0 and we are not in the flowing mode\n  //   we should _not_ attempt to buffer any extra data. We'll get more data\n  //   when the stream consumer calls read() instead.\n  // - No data in the buffer, and the stream is in flowing mode. In this mode\n  //   the loop below is responsible for ensuring read() is called. Failing to\n  //   call read here would abort the flow and there's no other mechanism for\n  //   continuing the flow if the stream consumer has just subscribed to the\n  //   'data' event.\n  //\n  // In addition to the above conditions to keep reading data, the following\n  // conditions prevent the data from being read:\n  // - The stream has ended (state.ended).\n  // - There is already a pending 'read' operation (state.reading). This is a\n  //   case where the the stream has called the implementation defined _read()\n  //   method, but they are processing the call asynchronously and have _not_\n  //   called push() with new data. In this case we skip performing more\n  //   read()s. The execution ends in this method again after the _read() ends\n  //   up calling push() with more data.\n  while (!state.reading && !state.ended && (state.length < state.highWaterMark || state.flowing && state.length === 0)) {\n    var len = state.length;\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length) // didn't get any data, stop spinning.\n      break;\n  }\n\n  state.readingMore = false;\n} // abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\n\n\nReadable.prototype._read = function (n) {\n  errorOrDestroy(this, new ERR_METHOD_NOT_IMPLEMENTED('_read()'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) process.nextTick(endFn);else src.once('end', endFn);\n  dest.on('unpipe', onunpipe);\n\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  } // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n\n\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n  var cleanedUp = false;\n\n  function cleanup() {\n    debug('cleanup'); // cleanup event handlers once the pipe is broken\n\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n    cleanedUp = true; // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  src.on('data', ondata);\n\n  function ondata(chunk) {\n    debug('ondata');\n    var ret = dest.write(chunk);\n    debug('dest.write', ret);\n\n    if (ret === false) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', state.awaitDrain);\n        state.awaitDrain++;\n      }\n\n      src.pause();\n    }\n  } // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n\n\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) errorOrDestroy(dest, er);\n  } // Make sure our error handler is attached before userland ones.\n\n\n  prependListener(dest, 'error', onerror); // Both close and finish should trigger unpipe, but only once.\n\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n\n  dest.once('close', onclose);\n\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  } // tell the dest that it's being piped to\n\n\n  dest.emit('pipe', src); // start the flow if it hasn't been started already.\n\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function pipeOnDrainFunctionResult() {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = {\n    hasUnpiped: false\n  }; // if we're not piping anywhere, then do nothing.\n\n  if (state.pipesCount === 0) return this; // just one destination.  most common case.\n\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n    if (!dest) dest = state.pipes; // got a match.\n\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  } // slow case. multiple pipe destinations.\n\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, {\n        hasUnpiped: false\n      });\n    }\n\n    return this;\n  } // try to find the right one.\n\n\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n  dest.emit('unpipe', this, unpipeInfo);\n  return this;\n}; // set up data events if they are asked for\n// Ensure readable listeners eventually get something\n\n\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n  var state = this._readableState;\n\n  if (ev === 'data') {\n    // update readableListening so that resume() may be a no-op\n    // a few lines down. This is needed to support once('readable').\n    state.readableListening = this.listenerCount('readable') > 0; // Try start flowing on next tick if stream isn't explicitly paused\n\n    if (state.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.flowing = false;\n      state.emittedReadable = false;\n      debug('on readable', state.length, state.reading);\n\n      if (state.length) {\n        emitReadable(this);\n      } else if (!state.reading) {\n        process.nextTick(nReadingNextTick, this);\n      }\n    }\n  }\n\n  return res;\n};\n\nReadable.prototype.addListener = Readable.prototype.on;\n\nReadable.prototype.removeListener = function (ev, fn) {\n  var res = Stream.prototype.removeListener.call(this, ev, fn);\n\n  if (ev === 'readable') {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n\n  return res;\n};\n\nReadable.prototype.removeAllListeners = function (ev) {\n  var res = Stream.prototype.removeAllListeners.apply(this, arguments);\n\n  if (ev === 'readable' || ev === undefined) {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n\n  return res;\n};\n\nfunction updateReadableListening(self) {\n  var state = self._readableState;\n  state.readableListening = self.listenerCount('readable') > 0;\n\n  if (state.resumeScheduled && !state.paused) {\n    // flowing needs to be set to true now, otherwise\n    // the upcoming resume will not flow.\n    state.flowing = true; // crude way to check if we should resume\n  } else if (self.listenerCount('data') > 0) {\n    self.resume();\n  }\n}\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n} // pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\n\n\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n\n  if (!state.flowing) {\n    debug('resume'); // we flow only if there is no one listening\n    // for readable, but we still have to call\n    // resume()\n\n    state.flowing = !state.readableListening;\n    resume(this, state);\n  }\n\n  state.paused = false;\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    process.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  debug('resume', state.reading);\n\n  if (!state.reading) {\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n\n  if (this._readableState.flowing !== false) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n\n  this._readableState.paused = true;\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n\n  while (state.flowing && stream.read() !== null) {\n    ;\n  }\n} // wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\n\n\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n  stream.on('end', function () {\n    debug('wrapped end');\n\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk); // don't skip over falsy values in objectMode\n\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  }); // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function methodWrap(method) {\n        return function methodWrapReturnFunction() {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  } // proxy certain important events.\n\n\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  } // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n\n\n  this._read = function (n) {\n    debug('wrapped _read', n);\n\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nif (typeof Symbol === 'function') {\n  Readable.prototype[Symbol.asyncIterator] = function () {\n    if (createReadableStreamAsyncIterator === undefined) {\n      createReadableStreamAsyncIterator = __webpack_require__(/*! ./internal/streams/async_iterator */ \"../node_modules/readable-stream/lib/internal/streams/async_iterator.js\");\n    }\n\n    return createReadableStreamAsyncIterator(this);\n  };\n}\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.highWaterMark;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState && this._readableState.buffer;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableFlowing', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.flowing;\n  },\n  set: function set(state) {\n    if (this._readableState) {\n      this._readableState.flowing = state;\n    }\n  }\n}); // exposed for testing purposes only.\n\nReadable._fromList = fromList;\nObject.defineProperty(Readable.prototype, 'readableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.length;\n  }\n}); // Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\n\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.first();else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = state.buffer.consume(n, state.decoder);\n  }\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n  debug('endReadable', state.endEmitted);\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    process.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  debug('endReadableNT', state.endEmitted, state.length); // Check that we didn't get one last unshift.\n\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n\n    if (state.autoDestroy) {\n      // In case of duplex streams we need a way to detect\n      // if the writable side is ready for autoDestroy as well\n      var wState = stream._writableState;\n\n      if (!wState || wState.autoDestroy && wState.finished) {\n        stream.destroy();\n      }\n    }\n  }\n}\n\nif (typeof Symbol === 'function') {\n  Readable.from = function (iterable, opts) {\n    if (from === undefined) {\n      from = __webpack_require__(/*! ./internal/streams/from */ \"../node_modules/readable-stream/lib/internal/streams/from-browser.js\");\n    }\n\n    return from(Readable, iterable, opts);\n  };\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n\n  return -1;\n}\n\n//# sourceURL=webpack:///../node_modules/readable-stream/lib/_stream_readable.js?");

/***/ }),

/***/ "../node_modules/readable-stream/lib/_stream_transform.js":
/*!****************************************************************!*\
  !*** ../node_modules/readable-stream/lib/_stream_transform.js ***!
  \****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n\nmodule.exports = Transform;\n\nvar _require$codes = __webpack_require__(/*! ../errors */ \"../node_modules/readable-stream/errors-browser.js\").codes,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,\n    ERR_TRANSFORM_ALREADY_TRANSFORMING = _require$codes.ERR_TRANSFORM_ALREADY_TRANSFORMING,\n    ERR_TRANSFORM_WITH_LENGTH_0 = _require$codes.ERR_TRANSFORM_WITH_LENGTH_0;\n\nvar Duplex = __webpack_require__(/*! ./_stream_duplex */ \"../node_modules/readable-stream/lib/_stream_duplex.js\");\n\n__webpack_require__(/*! inherits */ \"../node_modules/inherits/inherits_browser.js\")(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n  var cb = ts.writecb;\n\n  if (cb === null) {\n    return this.emit('error', new ERR_MULTIPLE_CALLBACK());\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n  cb(er);\n  var rs = this._readableState;\n  rs.reading = false;\n\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n  Duplex.call(this, options);\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  }; // start out asking for a readable event once data is transformed.\n\n  this._readableState.needReadable = true; // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  } // When the writable side finishes, then flush out anything remaining.\n\n\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function' && !this._readableState.destroyed) {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n}; // This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\n\n\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  cb(new ERR_METHOD_NOT_IMPLEMENTED('_transform()'));\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n}; // Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\n\n\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && !ts.transforming) {\n    ts.transforming = true;\n\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data); // TODO(BridgeAR): Write a test for these two error cases\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n\n  if (stream._writableState.length) throw new ERR_TRANSFORM_WITH_LENGTH_0();\n  if (stream._transformState.transforming) throw new ERR_TRANSFORM_ALREADY_TRANSFORMING();\n  return stream.push(null);\n}\n\n//# sourceURL=webpack:///../node_modules/readable-stream/lib/_stream_transform.js?");

/***/ }),

/***/ "../node_modules/readable-stream/lib/_stream_writable.js":
/*!***************************************************************!*\
  !*** ../node_modules/readable-stream/lib/_stream_writable.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n\nmodule.exports = Writable;\n/* <replacement> */\n\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n} // It seems a linked list but it is not\n// there will be only 2 of these for each stream\n\n\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\n\n\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n/*<replacement>*/\n\nvar internalUtil = {\n  deprecate: __webpack_require__(/*! util-deprecate */ \"../node_modules/util-deprecate/browser.js\")\n};\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Stream = __webpack_require__(/*! ./internal/streams/stream */ \"../node_modules/readable-stream/lib/internal/streams/stream-browser.js\");\n/*</replacement>*/\n\n\nvar Buffer = __webpack_require__(/*! buffer */ \"?5f0e\").Buffer;\n\nvar OurUint8Array = __webpack_require__.g.Uint8Array || function () {};\n\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\n\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\nvar destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ \"../node_modules/readable-stream/lib/internal/streams/destroy.js\");\n\nvar _require = __webpack_require__(/*! ./internal/streams/state */ \"../node_modules/readable-stream/lib/internal/streams/state.js\"),\n    getHighWaterMark = _require.getHighWaterMark;\n\nvar _require$codes = __webpack_require__(/*! ../errors */ \"../node_modules/readable-stream/errors-browser.js\").codes,\n    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,\n    ERR_STREAM_CANNOT_PIPE = _require$codes.ERR_STREAM_CANNOT_PIPE,\n    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED,\n    ERR_STREAM_NULL_VALUES = _require$codes.ERR_STREAM_NULL_VALUES,\n    ERR_STREAM_WRITE_AFTER_END = _require$codes.ERR_STREAM_WRITE_AFTER_END,\n    ERR_UNKNOWN_ENCODING = _require$codes.ERR_UNKNOWN_ENCODING;\n\nvar errorOrDestroy = destroyImpl.errorOrDestroy;\n\n__webpack_require__(/*! inherits */ \"../node_modules/inherits/inherits_browser.js\")(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream, isDuplex) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"../node_modules/readable-stream/lib/_stream_duplex.js\");\n  options = options || {}; // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream,\n  // e.g. options.readableObjectMode vs. options.writableObjectMode, etc.\n\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode; // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n\n  this.highWaterMark = getHighWaterMark(this, options, 'writableHighWaterMark', isDuplex); // if _final has been called\n\n  this.finalCalled = false; // drain event flag.\n\n  this.needDrain = false; // at the start of calling end()\n\n  this.ending = false; // when end() has been called, and returned\n\n  this.ended = false; // when 'finish' is emitted\n\n  this.finished = false; // has it been destroyed\n\n  this.destroyed = false; // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode; // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n\n  this.defaultEncoding = options.defaultEncoding || 'utf8'; // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n\n  this.length = 0; // a flag to see when we're in the middle of a write.\n\n  this.writing = false; // when true all writes will be buffered until .uncork() call\n\n  this.corked = 0; // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n\n  this.sync = true; // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n\n  this.bufferProcessing = false; // the callback that's passed to _write(chunk,cb)\n\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  }; // the callback that the user supplies to write(chunk,encoding,cb)\n\n\n  this.writecb = null; // the amount that is being written when _write is called.\n\n  this.writelen = 0;\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null; // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n\n  this.pendingcb = 0; // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n\n  this.prefinished = false; // True if the error was already emitted and should not be thrown again\n\n  this.errorEmitted = false; // Should close be emitted on destroy. Defaults to true.\n\n  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'finish' (and potentially 'end')\n\n  this.autoDestroy = !!options.autoDestroy; // count buffered requests\n\n  this.bufferedRequestCount = 0; // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function writableStateBufferGetter() {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})(); // Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\n\n\nvar realHasInstance;\n\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function value(object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function realHasInstance(object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"../node_modules/readable-stream/lib/_stream_duplex.js\"); // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the WritableState constructor, at least with V8 6.5\n\n  var isDuplex = this instanceof Duplex;\n  if (!isDuplex && !realHasInstance.call(Writable, this)) return new Writable(options);\n  this._writableState = new WritableState(options, this, isDuplex); // legacy.\n\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n    if (typeof options.writev === 'function') this._writev = options.writev;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n} // Otherwise people can pipe Writable streams, which is just wrong.\n\n\nWritable.prototype.pipe = function () {\n  errorOrDestroy(this, new ERR_STREAM_CANNOT_PIPE());\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new ERR_STREAM_WRITE_AFTER_END(); // TODO: defer error events consistently everywhere, not just the cb\n\n  errorOrDestroy(stream, er);\n  process.nextTick(cb, er);\n} // Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\n\n\nfunction validChunk(stream, state, chunk, cb) {\n  var er;\n\n  if (chunk === null) {\n    er = new ERR_STREAM_NULL_VALUES();\n  } else if (typeof chunk !== 'string' && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer'], chunk);\n  }\n\n  if (er) {\n    errorOrDestroy(stream, er);\n    process.nextTick(cb, er);\n    return false;\n  }\n\n  return true;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n  if (typeof cb !== 'function') cb = nop;\n  if (state.ending) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  this._writableState.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n    if (!state.writing && !state.corked && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new ERR_UNKNOWN_ENCODING(encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nObject.defineProperty(Writable.prototype, 'writableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState && this._writableState.getBuffer();\n  }\n});\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.highWaterMark;\n  }\n}); // if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\n\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n\n  var len = state.objectMode ? 1 : chunk.length;\n  state.length += len;\n  var ret = state.length < state.highWaterMark; // we must ensure that previous needDrain will not be reset to false.\n\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (state.destroyed) state.onwrite(new ERR_STREAM_DESTROYED('write'));else if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    process.nextTick(cb, er); // this can emit finish, and it will always happen\n    // after error\n\n    process.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    errorOrDestroy(stream, er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    errorOrDestroy(stream, er); // this can emit finish, but finish must\n    // always follow error\n\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n  if (typeof cb !== 'function') throw new ERR_MULTIPLE_CALLBACK();\n  onwriteStateUpdate(state);\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state) || stream.destroyed;\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      process.nextTick(afterWrite, stream, state, finished, cb);\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n} // Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\n\n\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n} // if there's something in the buffer waiting, then process it\n\n\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n    var count = 0;\n    var allBuffers = true;\n\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n\n    buffer.allBuffers = allBuffers;\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish); // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--; // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new ERR_METHOD_NOT_IMPLEMENTED('_write()'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding); // .end() fully uncorks\n\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  } // ignore unnecessary end() calls.\n\n\n  if (!state.ending) endWritable(this, state, cb);\n  return this;\n};\n\nObject.defineProperty(Writable.prototype, 'writableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.length;\n  }\n});\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\n\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n\n    if (err) {\n      errorOrDestroy(stream, err);\n    }\n\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\n\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function' && !state.destroyed) {\n      state.pendingcb++;\n      state.finalCalled = true;\n      process.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n\n  if (need) {\n    prefinish(stream, state);\n\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n\n      if (state.autoDestroy) {\n        // In case of duplex streams we need a way to detect\n        // if the readable side is ready for autoDestroy as well\n        var rState = stream._readableState;\n\n        if (!rState || rState.autoDestroy && rState.endEmitted) {\n          stream.destroy();\n        }\n      }\n    }\n  }\n\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n\n  if (cb) {\n    if (state.finished) process.nextTick(cb);else stream.once('finish', cb);\n  }\n\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  } // reuse the free corkReq.\n\n\n  state.corkedRequestsFree.next = corkReq;\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._writableState === undefined) {\n      return false;\n    }\n\n    return this._writableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._writableState.destroyed = value;\n  }\n});\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\n\nWritable.prototype._destroy = function (err, cb) {\n  cb(err);\n};\n\n//# sourceURL=webpack:///../node_modules/readable-stream/lib/_stream_writable.js?");

/***/ }),

/***/ "../node_modules/readable-stream/lib/internal/streams/async_iterator.js":
/*!******************************************************************************!*\
  !*** ../node_modules/readable-stream/lib/internal/streams/async_iterator.js ***!
  \******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar _Object$setPrototypeO;\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nvar finished = __webpack_require__(/*! ./end-of-stream */ \"../node_modules/readable-stream/lib/internal/streams/end-of-stream.js\");\n\nvar kLastResolve = Symbol('lastResolve');\nvar kLastReject = Symbol('lastReject');\nvar kError = Symbol('error');\nvar kEnded = Symbol('ended');\nvar kLastPromise = Symbol('lastPromise');\nvar kHandlePromise = Symbol('handlePromise');\nvar kStream = Symbol('stream');\n\nfunction createIterResult(value, done) {\n  return {\n    value: value,\n    done: done\n  };\n}\n\nfunction readAndResolve(iter) {\n  var resolve = iter[kLastResolve];\n\n  if (resolve !== null) {\n    var data = iter[kStream].read(); // we defer if data is null\n    // we can be expecting either 'end' or\n    // 'error'\n\n    if (data !== null) {\n      iter[kLastPromise] = null;\n      iter[kLastResolve] = null;\n      iter[kLastReject] = null;\n      resolve(createIterResult(data, false));\n    }\n  }\n}\n\nfunction onReadable(iter) {\n  // we wait for the next tick, because it might\n  // emit an error with process.nextTick\n  process.nextTick(readAndResolve, iter);\n}\n\nfunction wrapForNext(lastPromise, iter) {\n  return function (resolve, reject) {\n    lastPromise.then(function () {\n      if (iter[kEnded]) {\n        resolve(createIterResult(undefined, true));\n        return;\n      }\n\n      iter[kHandlePromise](resolve, reject);\n    }, reject);\n  };\n}\n\nvar AsyncIteratorPrototype = Object.getPrototypeOf(function () {});\nvar ReadableStreamAsyncIteratorPrototype = Object.setPrototypeOf((_Object$setPrototypeO = {\n  get stream() {\n    return this[kStream];\n  },\n\n  next: function next() {\n    var _this = this;\n\n    // if we have detected an error in the meanwhile\n    // reject straight away\n    var error = this[kError];\n\n    if (error !== null) {\n      return Promise.reject(error);\n    }\n\n    if (this[kEnded]) {\n      return Promise.resolve(createIterResult(undefined, true));\n    }\n\n    if (this[kStream].destroyed) {\n      // We need to defer via nextTick because if .destroy(err) is\n      // called, the error will be emitted via nextTick, and\n      // we cannot guarantee that there is no error lingering around\n      // waiting to be emitted.\n      return new Promise(function (resolve, reject) {\n        process.nextTick(function () {\n          if (_this[kError]) {\n            reject(_this[kError]);\n          } else {\n            resolve(createIterResult(undefined, true));\n          }\n        });\n      });\n    } // if we have multiple next() calls\n    // we will wait for the previous Promise to finish\n    // this logic is optimized to support for await loops,\n    // where next() is only called once at a time\n\n\n    var lastPromise = this[kLastPromise];\n    var promise;\n\n    if (lastPromise) {\n      promise = new Promise(wrapForNext(lastPromise, this));\n    } else {\n      // fast path needed to support multiple this.push()\n      // without triggering the next() queue\n      var data = this[kStream].read();\n\n      if (data !== null) {\n        return Promise.resolve(createIterResult(data, false));\n      }\n\n      promise = new Promise(this[kHandlePromise]);\n    }\n\n    this[kLastPromise] = promise;\n    return promise;\n  }\n}, _defineProperty(_Object$setPrototypeO, Symbol.asyncIterator, function () {\n  return this;\n}), _defineProperty(_Object$setPrototypeO, \"return\", function _return() {\n  var _this2 = this;\n\n  // destroy(err, cb) is a private API\n  // we can guarantee we have that here, because we control the\n  // Readable class this is attached to\n  return new Promise(function (resolve, reject) {\n    _this2[kStream].destroy(null, function (err) {\n      if (err) {\n        reject(err);\n        return;\n      }\n\n      resolve(createIterResult(undefined, true));\n    });\n  });\n}), _Object$setPrototypeO), AsyncIteratorPrototype);\n\nvar createReadableStreamAsyncIterator = function createReadableStreamAsyncIterator(stream) {\n  var _Object$create;\n\n  var iterator = Object.create(ReadableStreamAsyncIteratorPrototype, (_Object$create = {}, _defineProperty(_Object$create, kStream, {\n    value: stream,\n    writable: true\n  }), _defineProperty(_Object$create, kLastResolve, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kLastReject, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kError, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kEnded, {\n    value: stream._readableState.endEmitted,\n    writable: true\n  }), _defineProperty(_Object$create, kHandlePromise, {\n    value: function value(resolve, reject) {\n      var data = iterator[kStream].read();\n\n      if (data) {\n        iterator[kLastPromise] = null;\n        iterator[kLastResolve] = null;\n        iterator[kLastReject] = null;\n        resolve(createIterResult(data, false));\n      } else {\n        iterator[kLastResolve] = resolve;\n        iterator[kLastReject] = reject;\n      }\n    },\n    writable: true\n  }), _Object$create));\n  iterator[kLastPromise] = null;\n  finished(stream, function (err) {\n    if (err && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {\n      var reject = iterator[kLastReject]; // reject if we are waiting for data in the Promise\n      // returned by next() and store the error\n\n      if (reject !== null) {\n        iterator[kLastPromise] = null;\n        iterator[kLastResolve] = null;\n        iterator[kLastReject] = null;\n        reject(err);\n      }\n\n      iterator[kError] = err;\n      return;\n    }\n\n    var resolve = iterator[kLastResolve];\n\n    if (resolve !== null) {\n      iterator[kLastPromise] = null;\n      iterator[kLastResolve] = null;\n      iterator[kLastReject] = null;\n      resolve(createIterResult(undefined, true));\n    }\n\n    iterator[kEnded] = true;\n  });\n  stream.on('readable', onReadable.bind(null, iterator));\n  return iterator;\n};\n\nmodule.exports = createReadableStreamAsyncIterator;\n\n//# sourceURL=webpack:///../node_modules/readable-stream/lib/internal/streams/async_iterator.js?");

/***/ }),

/***/ "../node_modules/readable-stream/lib/internal/streams/buffer_list.js":
/*!***************************************************************************!*\
  !*** ../node_modules/readable-stream/lib/internal/streams/buffer_list.js ***!
  \***************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nfunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }\n\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(Object(source), true).forEach(function (key) { _defineProperty(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\nvar _require = __webpack_require__(/*! buffer */ \"?462a\"),\n    Buffer = _require.Buffer;\n\nvar _require2 = __webpack_require__(/*! util */ \"?432f\"),\n    inspect = _require2.inspect;\n\nvar custom = inspect && inspect.custom || 'inspect';\n\nfunction copyBuffer(src, target, offset) {\n  Buffer.prototype.copy.call(src, target, offset);\n}\n\nmodule.exports =\n/*#__PURE__*/\nfunction () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  _createClass(BufferList, [{\n    key: \"push\",\n    value: function push(v) {\n      var entry = {\n        data: v,\n        next: null\n      };\n      if (this.length > 0) this.tail.next = entry;else this.head = entry;\n      this.tail = entry;\n      ++this.length;\n    }\n  }, {\n    key: \"unshift\",\n    value: function unshift(v) {\n      var entry = {\n        data: v,\n        next: this.head\n      };\n      if (this.length === 0) this.tail = entry;\n      this.head = entry;\n      ++this.length;\n    }\n  }, {\n    key: \"shift\",\n    value: function shift() {\n      if (this.length === 0) return;\n      var ret = this.head.data;\n      if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n      --this.length;\n      return ret;\n    }\n  }, {\n    key: \"clear\",\n    value: function clear() {\n      this.head = this.tail = null;\n      this.length = 0;\n    }\n  }, {\n    key: \"join\",\n    value: function join(s) {\n      if (this.length === 0) return '';\n      var p = this.head;\n      var ret = '' + p.data;\n\n      while (p = p.next) {\n        ret += s + p.data;\n      }\n\n      return ret;\n    }\n  }, {\n    key: \"concat\",\n    value: function concat(n) {\n      if (this.length === 0) return Buffer.alloc(0);\n      var ret = Buffer.allocUnsafe(n >>> 0);\n      var p = this.head;\n      var i = 0;\n\n      while (p) {\n        copyBuffer(p.data, ret, i);\n        i += p.data.length;\n        p = p.next;\n      }\n\n      return ret;\n    } // Consumes a specified amount of bytes or characters from the buffered data.\n\n  }, {\n    key: \"consume\",\n    value: function consume(n, hasStrings) {\n      var ret;\n\n      if (n < this.head.data.length) {\n        // `slice` is the same for buffers and strings.\n        ret = this.head.data.slice(0, n);\n        this.head.data = this.head.data.slice(n);\n      } else if (n === this.head.data.length) {\n        // First chunk is a perfect match.\n        ret = this.shift();\n      } else {\n        // Result spans more than one buffer.\n        ret = hasStrings ? this._getString(n) : this._getBuffer(n);\n      }\n\n      return ret;\n    }\n  }, {\n    key: \"first\",\n    value: function first() {\n      return this.head.data;\n    } // Consumes a specified amount of characters from the buffered data.\n\n  }, {\n    key: \"_getString\",\n    value: function _getString(n) {\n      var p = this.head;\n      var c = 1;\n      var ret = p.data;\n      n -= ret.length;\n\n      while (p = p.next) {\n        var str = p.data;\n        var nb = n > str.length ? str.length : n;\n        if (nb === str.length) ret += str;else ret += str.slice(0, n);\n        n -= nb;\n\n        if (n === 0) {\n          if (nb === str.length) {\n            ++c;\n            if (p.next) this.head = p.next;else this.head = this.tail = null;\n          } else {\n            this.head = p;\n            p.data = str.slice(nb);\n          }\n\n          break;\n        }\n\n        ++c;\n      }\n\n      this.length -= c;\n      return ret;\n    } // Consumes a specified amount of bytes from the buffered data.\n\n  }, {\n    key: \"_getBuffer\",\n    value: function _getBuffer(n) {\n      var ret = Buffer.allocUnsafe(n);\n      var p = this.head;\n      var c = 1;\n      p.data.copy(ret);\n      n -= p.data.length;\n\n      while (p = p.next) {\n        var buf = p.data;\n        var nb = n > buf.length ? buf.length : n;\n        buf.copy(ret, ret.length - n, 0, nb);\n        n -= nb;\n\n        if (n === 0) {\n          if (nb === buf.length) {\n            ++c;\n            if (p.next) this.head = p.next;else this.head = this.tail = null;\n          } else {\n            this.head = p;\n            p.data = buf.slice(nb);\n          }\n\n          break;\n        }\n\n        ++c;\n      }\n\n      this.length -= c;\n      return ret;\n    } // Make sure the linked list only shows the minimal necessary information.\n\n  }, {\n    key: custom,\n    value: function value(_, options) {\n      return inspect(this, _objectSpread({}, options, {\n        // Only inspect one level.\n        depth: 0,\n        // It should not recurse.\n        customInspect: false\n      }));\n    }\n  }]);\n\n  return BufferList;\n}();\n\n//# sourceURL=webpack:///../node_modules/readable-stream/lib/internal/streams/buffer_list.js?");

/***/ }),

/***/ "../node_modules/readable-stream/lib/internal/streams/destroy.js":
/*!***********************************************************************!*\
  !*** ../node_modules/readable-stream/lib/internal/streams/destroy.js ***!
  \***********************************************************************/
/***/ ((module) => {

"use strict";
eval(" // undocumented cb() API, needed for core, not for public API\n\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err) {\n      if (!this._writableState) {\n        process.nextTick(emitErrorNT, this, err);\n      } else if (!this._writableState.errorEmitted) {\n        this._writableState.errorEmitted = true;\n        process.nextTick(emitErrorNT, this, err);\n      }\n    }\n\n    return this;\n  } // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  } // if this is a duplex stream mark the writable part as destroyed as well\n\n\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      if (!_this._writableState) {\n        process.nextTick(emitErrorAndCloseNT, _this, err);\n      } else if (!_this._writableState.errorEmitted) {\n        _this._writableState.errorEmitted = true;\n        process.nextTick(emitErrorAndCloseNT, _this, err);\n      } else {\n        process.nextTick(emitCloseNT, _this);\n      }\n    } else if (cb) {\n      process.nextTick(emitCloseNT, _this);\n      cb(err);\n    } else {\n      process.nextTick(emitCloseNT, _this);\n    }\n  });\n\n  return this;\n}\n\nfunction emitErrorAndCloseNT(self, err) {\n  emitErrorNT(self, err);\n  emitCloseNT(self);\n}\n\nfunction emitCloseNT(self) {\n  if (self._writableState && !self._writableState.emitClose) return;\n  if (self._readableState && !self._readableState.emitClose) return;\n  self.emit('close');\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finalCalled = false;\n    this._writableState.prefinished = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nfunction errorOrDestroy(stream, err) {\n  // We have tests that rely on errors being emitted\n  // in the same tick, so changing this is semver major.\n  // For now when you opt-in to autoDestroy we allow\n  // the error to be emitted nextTick. In a future\n  // semver major update we should change the default to this.\n  var rState = stream._readableState;\n  var wState = stream._writableState;\n  if (rState && rState.autoDestroy || wState && wState.autoDestroy) stream.destroy(err);else stream.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy,\n  errorOrDestroy: errorOrDestroy\n};\n\n//# sourceURL=webpack:///../node_modules/readable-stream/lib/internal/streams/destroy.js?");

/***/ }),

/***/ "../node_modules/readable-stream/lib/internal/streams/end-of-stream.js":
/*!*****************************************************************************!*\
  !*** ../node_modules/readable-stream/lib/internal/streams/end-of-stream.js ***!
  \*****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Ported from https://github.com/mafintosh/end-of-stream with\n// permission from the author, Mathias Buus (@mafintosh).\n\n\nvar ERR_STREAM_PREMATURE_CLOSE = __webpack_require__(/*! ../../../errors */ \"../node_modules/readable-stream/errors-browser.js\").codes.ERR_STREAM_PREMATURE_CLOSE;\n\nfunction once(callback) {\n  var called = false;\n  return function () {\n    if (called) return;\n    called = true;\n\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n\n    callback.apply(this, args);\n  };\n}\n\nfunction noop() {}\n\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function';\n}\n\nfunction eos(stream, opts, callback) {\n  if (typeof opts === 'function') return eos(stream, null, opts);\n  if (!opts) opts = {};\n  callback = once(callback || noop);\n  var readable = opts.readable || opts.readable !== false && stream.readable;\n  var writable = opts.writable || opts.writable !== false && stream.writable;\n\n  var onlegacyfinish = function onlegacyfinish() {\n    if (!stream.writable) onfinish();\n  };\n\n  var writableEnded = stream._writableState && stream._writableState.finished;\n\n  var onfinish = function onfinish() {\n    writable = false;\n    writableEnded = true;\n    if (!readable) callback.call(stream);\n  };\n\n  var readableEnded = stream._readableState && stream._readableState.endEmitted;\n\n  var onend = function onend() {\n    readable = false;\n    readableEnded = true;\n    if (!writable) callback.call(stream);\n  };\n\n  var onerror = function onerror(err) {\n    callback.call(stream, err);\n  };\n\n  var onclose = function onclose() {\n    var err;\n\n    if (readable && !readableEnded) {\n      if (!stream._readableState || !stream._readableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n\n    if (writable && !writableEnded) {\n      if (!stream._writableState || !stream._writableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n  };\n\n  var onrequest = function onrequest() {\n    stream.req.on('finish', onfinish);\n  };\n\n  if (isRequest(stream)) {\n    stream.on('complete', onfinish);\n    stream.on('abort', onclose);\n    if (stream.req) onrequest();else stream.on('request', onrequest);\n  } else if (writable && !stream._writableState) {\n    // legacy streams\n    stream.on('end', onlegacyfinish);\n    stream.on('close', onlegacyfinish);\n  }\n\n  stream.on('end', onend);\n  stream.on('finish', onfinish);\n  if (opts.error !== false) stream.on('error', onerror);\n  stream.on('close', onclose);\n  return function () {\n    stream.removeListener('complete', onfinish);\n    stream.removeListener('abort', onclose);\n    stream.removeListener('request', onrequest);\n    if (stream.req) stream.req.removeListener('finish', onfinish);\n    stream.removeListener('end', onlegacyfinish);\n    stream.removeListener('close', onlegacyfinish);\n    stream.removeListener('finish', onfinish);\n    stream.removeListener('end', onend);\n    stream.removeListener('error', onerror);\n    stream.removeListener('close', onclose);\n  };\n}\n\nmodule.exports = eos;\n\n//# sourceURL=webpack:///../node_modules/readable-stream/lib/internal/streams/end-of-stream.js?");

/***/ }),

/***/ "../node_modules/readable-stream/lib/internal/streams/from-browser.js":
/*!****************************************************************************!*\
  !*** ../node_modules/readable-stream/lib/internal/streams/from-browser.js ***!
  \****************************************************************************/
/***/ ((module) => {

eval("module.exports = function () {\n  throw new Error('Readable.from is not available in the browser')\n};\n\n\n//# sourceURL=webpack:///../node_modules/readable-stream/lib/internal/streams/from-browser.js?");

/***/ }),

/***/ "../node_modules/readable-stream/lib/internal/streams/pipeline.js":
/*!************************************************************************!*\
  !*** ../node_modules/readable-stream/lib/internal/streams/pipeline.js ***!
  \************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Ported from https://github.com/mafintosh/pump with\n// permission from the author, Mathias Buus (@mafintosh).\n\n\nvar eos;\n\nfunction once(callback) {\n  var called = false;\n  return function () {\n    if (called) return;\n    called = true;\n    callback.apply(void 0, arguments);\n  };\n}\n\nvar _require$codes = __webpack_require__(/*! ../../../errors */ \"../node_modules/readable-stream/errors-browser.js\").codes,\n    ERR_MISSING_ARGS = _require$codes.ERR_MISSING_ARGS,\n    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED;\n\nfunction noop(err) {\n  // Rethrow the error if it exists to avoid swallowing it\n  if (err) throw err;\n}\n\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function';\n}\n\nfunction destroyer(stream, reading, writing, callback) {\n  callback = once(callback);\n  var closed = false;\n  stream.on('close', function () {\n    closed = true;\n  });\n  if (eos === undefined) eos = __webpack_require__(/*! ./end-of-stream */ \"../node_modules/readable-stream/lib/internal/streams/end-of-stream.js\");\n  eos(stream, {\n    readable: reading,\n    writable: writing\n  }, function (err) {\n    if (err) return callback(err);\n    closed = true;\n    callback();\n  });\n  var destroyed = false;\n  return function (err) {\n    if (closed) return;\n    if (destroyed) return;\n    destroyed = true; // request.destroy just do .end - .abort is what we want\n\n    if (isRequest(stream)) return stream.abort();\n    if (typeof stream.destroy === 'function') return stream.destroy();\n    callback(err || new ERR_STREAM_DESTROYED('pipe'));\n  };\n}\n\nfunction call(fn) {\n  fn();\n}\n\nfunction pipe(from, to) {\n  return from.pipe(to);\n}\n\nfunction popCallback(streams) {\n  if (!streams.length) return noop;\n  if (typeof streams[streams.length - 1] !== 'function') return noop;\n  return streams.pop();\n}\n\nfunction pipeline() {\n  for (var _len = arguments.length, streams = new Array(_len), _key = 0; _key < _len; _key++) {\n    streams[_key] = arguments[_key];\n  }\n\n  var callback = popCallback(streams);\n  if (Array.isArray(streams[0])) streams = streams[0];\n\n  if (streams.length < 2) {\n    throw new ERR_MISSING_ARGS('streams');\n  }\n\n  var error;\n  var destroys = streams.map(function (stream, i) {\n    var reading = i < streams.length - 1;\n    var writing = i > 0;\n    return destroyer(stream, reading, writing, function (err) {\n      if (!error) error = err;\n      if (err) destroys.forEach(call);\n      if (reading) return;\n      destroys.forEach(call);\n      callback(error);\n    });\n  });\n  return streams.reduce(pipe);\n}\n\nmodule.exports = pipeline;\n\n//# sourceURL=webpack:///../node_modules/readable-stream/lib/internal/streams/pipeline.js?");

/***/ }),

/***/ "../node_modules/readable-stream/lib/internal/streams/state.js":
/*!*********************************************************************!*\
  !*** ../node_modules/readable-stream/lib/internal/streams/state.js ***!
  \*********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar ERR_INVALID_OPT_VALUE = __webpack_require__(/*! ../../../errors */ \"../node_modules/readable-stream/errors-browser.js\").codes.ERR_INVALID_OPT_VALUE;\n\nfunction highWaterMarkFrom(options, isDuplex, duplexKey) {\n  return options.highWaterMark != null ? options.highWaterMark : isDuplex ? options[duplexKey] : null;\n}\n\nfunction getHighWaterMark(state, options, duplexKey, isDuplex) {\n  var hwm = highWaterMarkFrom(options, isDuplex, duplexKey);\n\n  if (hwm != null) {\n    if (!(isFinite(hwm) && Math.floor(hwm) === hwm) || hwm < 0) {\n      var name = isDuplex ? duplexKey : 'highWaterMark';\n      throw new ERR_INVALID_OPT_VALUE(name, hwm);\n    }\n\n    return Math.floor(hwm);\n  } // Default value\n\n\n  return state.objectMode ? 16 : 16 * 1024;\n}\n\nmodule.exports = {\n  getHighWaterMark: getHighWaterMark\n};\n\n//# sourceURL=webpack:///../node_modules/readable-stream/lib/internal/streams/state.js?");

/***/ }),

/***/ "../node_modules/readable-stream/lib/internal/streams/stream-browser.js":
/*!******************************************************************************!*\
  !*** ../node_modules/readable-stream/lib/internal/streams/stream-browser.js ***!
  \******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("module.exports = __webpack_require__(/*! events */ \"../node_modules/events/events.js\").EventEmitter;\n\n\n//# sourceURL=webpack:///../node_modules/readable-stream/lib/internal/streams/stream-browser.js?");

/***/ }),

/***/ "../node_modules/readable-stream/readable-browser.js":
/*!***********************************************************!*\
  !*** ../node_modules/readable-stream/readable-browser.js ***!
  \***********************************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("exports = module.exports = __webpack_require__(/*! ./lib/_stream_readable.js */ \"../node_modules/readable-stream/lib/_stream_readable.js\");\nexports.Stream = exports;\nexports.Readable = exports;\nexports.Writable = __webpack_require__(/*! ./lib/_stream_writable.js */ \"../node_modules/readable-stream/lib/_stream_writable.js\");\nexports.Duplex = __webpack_require__(/*! ./lib/_stream_duplex.js */ \"../node_modules/readable-stream/lib/_stream_duplex.js\");\nexports.Transform = __webpack_require__(/*! ./lib/_stream_transform.js */ \"../node_modules/readable-stream/lib/_stream_transform.js\");\nexports.PassThrough = __webpack_require__(/*! ./lib/_stream_passthrough.js */ \"../node_modules/readable-stream/lib/_stream_passthrough.js\");\nexports.finished = __webpack_require__(/*! ./lib/internal/streams/end-of-stream.js */ \"../node_modules/readable-stream/lib/internal/streams/end-of-stream.js\");\nexports.pipeline = __webpack_require__(/*! ./lib/internal/streams/pipeline.js */ \"../node_modules/readable-stream/lib/internal/streams/pipeline.js\");\n\n\n//# sourceURL=webpack:///../node_modules/readable-stream/readable-browser.js?");

/***/ }),

/***/ "../node_modules/safe-buffer/index.js":
/*!********************************************!*\
  !*** ../node_modules/safe-buffer/index.js ***!
  \********************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("/*! safe-buffer. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */\n/* eslint-disable node/no-deprecated-api */\nvar buffer = __webpack_require__(/*! buffer */ \"?09a9\")\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.prototype = Object.create(Buffer.prototype)\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n\n\n//# sourceURL=webpack:///../node_modules/safe-buffer/index.js?");

/***/ }),

/***/ "../node_modules/string_decoder/lib/string_decoder.js":
/*!************************************************************!*\
  !*** ../node_modules/string_decoder/lib/string_decoder.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n/*<replacement>*/\n\nvar Buffer = __webpack_require__(/*! safe-buffer */ \"../node_modules/safe-buffer/index.js\").Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}\n\n//# sourceURL=webpack:///../node_modules/string_decoder/lib/string_decoder.js?");

/***/ }),

/***/ "../node_modules/threads/dist/common.js":
/*!**********************************************!*\
  !*** ../node_modules/threads/dist/common.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.serialize = exports.deserialize = exports.registerSerializer = void 0;\nconst serializers_1 = __webpack_require__(/*! ./serializers */ \"../node_modules/threads/dist/serializers.js\");\nlet registeredSerializer = serializers_1.DefaultSerializer;\nfunction registerSerializer(serializer) {\n    registeredSerializer = serializers_1.extendSerializer(registeredSerializer, serializer);\n}\nexports.registerSerializer = registerSerializer;\nfunction deserialize(message) {\n    return registeredSerializer.deserialize(message);\n}\nexports.deserialize = deserialize;\nfunction serialize(input) {\n    return registeredSerializer.serialize(input);\n}\nexports.serialize = serialize;\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/common.js?");

/***/ }),

/***/ "../node_modules/threads/dist/index.js":
/*!*********************************************!*\
  !*** ../node_modules/threads/dist/index.js ***!
  \*********************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Transfer = exports.DefaultSerializer = exports.expose = exports.registerSerializer = void 0;\nvar common_1 = __webpack_require__(/*! ./common */ \"../node_modules/threads/dist/common.js\");\nObject.defineProperty(exports, \"registerSerializer\", ({ enumerable: true, get: function () { return common_1.registerSerializer; } }));\n__exportStar(__webpack_require__(/*! ./master/index */ \"../node_modules/threads/dist/master/index.js\"), exports);\nvar index_1 = __webpack_require__(/*! ./worker/index */ \"../node_modules/threads/dist/worker/index.js\");\nObject.defineProperty(exports, \"expose\", ({ enumerable: true, get: function () { return index_1.expose; } }));\nvar serializers_1 = __webpack_require__(/*! ./serializers */ \"../node_modules/threads/dist/serializers.js\");\nObject.defineProperty(exports, \"DefaultSerializer\", ({ enumerable: true, get: function () { return serializers_1.DefaultSerializer; } }));\nvar transferable_1 = __webpack_require__(/*! ./transferable */ \"../node_modules/threads/dist/transferable.js\");\nObject.defineProperty(exports, \"Transfer\", ({ enumerable: true, get: function () { return transferable_1.Transfer; } }));\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/index.js?");

/***/ }),

/***/ "../node_modules/threads/dist/master/get-bundle-url.browser.js":
/*!*********************************************************************!*\
  !*** ../node_modules/threads/dist/master/get-bundle-url.browser.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Source: <https://github.com/parcel-bundler/parcel/blob/master/packages/core/parcel-bundler/src/builtins/bundle-url.js>\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.getBundleURL = exports.getBaseURL = void 0;\nlet bundleURL;\nfunction getBundleURLCached() {\n    if (!bundleURL) {\n        bundleURL = getBundleURL();\n    }\n    return bundleURL;\n}\nexports.getBundleURL = getBundleURLCached;\nfunction getBundleURL() {\n    // Attempt to find the URL of the current script and use that as the base URL\n    try {\n        throw new Error;\n    }\n    catch (err) {\n        const matches = (\"\" + err.stack).match(/(https?|file|ftp|chrome-extension|moz-extension):\\/\\/[^)\\n]+/g);\n        if (matches) {\n            return getBaseURL(matches[0]);\n        }\n    }\n    return \"/\";\n}\nfunction getBaseURL(url) {\n    return (\"\" + url).replace(/^((?:https?|file|ftp|chrome-extension|moz-extension):\\/\\/.+)?\\/[^/]+(?:\\?.*)?$/, '$1') + '/';\n}\nexports.getBaseURL = getBaseURL;\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/master/get-bundle-url.browser.js?");

/***/ }),

/***/ "../node_modules/threads/dist/master/implementation.browser.js":
/*!*********************************************************************!*\
  !*** ../node_modules/threads/dist/master/implementation.browser.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// tslint:disable max-classes-per-file\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.isWorkerRuntime = exports.getWorkerImplementation = exports.defaultPoolSize = void 0;\nconst get_bundle_url_browser_1 = __webpack_require__(/*! ./get-bundle-url.browser */ \"../node_modules/threads/dist/master/get-bundle-url.browser.js\");\nexports.defaultPoolSize = typeof navigator !== \"undefined\" && navigator.hardwareConcurrency\n    ? navigator.hardwareConcurrency\n    : 4;\nconst isAbsoluteURL = (value) => /^[a-zA-Z][a-zA-Z\\d+\\-.]*:/.test(value);\nfunction createSourceBlobURL(code) {\n    const blob = new Blob([code], { type: \"application/javascript\" });\n    return URL.createObjectURL(blob);\n}\nfunction selectWorkerImplementation() {\n    if (typeof Worker === \"undefined\") {\n        // Might happen on Safari, for instance\n        // The idea is to only fail if the constructor is actually used\n        return class NoWebWorker {\n            constructor() {\n                throw Error(\"No web worker implementation available. You might have tried to spawn a worker within a worker in a browser that doesn't support workers in workers.\");\n            }\n        };\n    }\n    class WebWorker extends Worker {\n        constructor(url, options) {\n            var _a, _b;\n            if (typeof url === \"string\" && options && options._baseURL) {\n                url = new URL(url, options._baseURL);\n            }\n            else if (typeof url === \"string\" && !isAbsoluteURL(url) && get_bundle_url_browser_1.getBundleURL().match(/^file:\\/\\//i)) {\n                url = new URL(url, get_bundle_url_browser_1.getBundleURL().replace(/\\/[^\\/]+$/, \"/\"));\n                if ((_a = options === null || options === void 0 ? void 0 : options.CORSWorkaround) !== null && _a !== void 0 ? _a : true) {\n                    url = createSourceBlobURL(`importScripts(${JSON.stringify(url)});`);\n                }\n            }\n            if (typeof url === \"string\" && isAbsoluteURL(url)) {\n                // Create source code blob loading JS file via `importScripts()`\n                // to circumvent worker CORS restrictions\n                if ((_b = options === null || options === void 0 ? void 0 : options.CORSWorkaround) !== null && _b !== void 0 ? _b : true) {\n                    url = createSourceBlobURL(`importScripts(${JSON.stringify(url)});`);\n                }\n            }\n            super(url, options);\n        }\n    }\n    class BlobWorker extends WebWorker {\n        constructor(blob, options) {\n            const url = window.URL.createObjectURL(blob);\n            super(url, options);\n        }\n        static fromText(source, options) {\n            const blob = new window.Blob([source], { type: \"text/javascript\" });\n            return new BlobWorker(blob, options);\n        }\n    }\n    return {\n        blob: BlobWorker,\n        default: WebWorker\n    };\n}\nlet implementation;\nfunction getWorkerImplementation() {\n    if (!implementation) {\n        implementation = selectWorkerImplementation();\n    }\n    return implementation;\n}\nexports.getWorkerImplementation = getWorkerImplementation;\nfunction isWorkerRuntime() {\n    const isWindowContext = typeof self !== \"undefined\" && typeof Window !== \"undefined\" && self instanceof Window;\n    return typeof self !== \"undefined\" && self.postMessage && !isWindowContext ? true : false;\n}\nexports.isWorkerRuntime = isWorkerRuntime;\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/master/implementation.browser.js?");

/***/ }),

/***/ "../node_modules/threads/dist/master/index.js":
/*!****************************************************!*\
  !*** ../node_modules/threads/dist/master/index.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Worker = exports.BlobWorker = exports.isWorkerRuntime = exports.Thread = exports.spawn = exports.Pool = void 0;\nconst implementation_1 = __webpack_require__(/*! ./implementation */ \"../node_modules/threads/dist/master/implementation.browser.js\");\nObject.defineProperty(exports, \"isWorkerRuntime\", ({ enumerable: true, get: function () { return implementation_1.isWorkerRuntime; } }));\nvar pool_1 = __webpack_require__(/*! ./pool */ \"../node_modules/threads/dist/master/pool.js\");\nObject.defineProperty(exports, \"Pool\", ({ enumerable: true, get: function () { return pool_1.Pool; } }));\nvar spawn_1 = __webpack_require__(/*! ./spawn */ \"../node_modules/threads/dist/master/spawn.js\");\nObject.defineProperty(exports, \"spawn\", ({ enumerable: true, get: function () { return spawn_1.spawn; } }));\nvar thread_1 = __webpack_require__(/*! ./thread */ \"../node_modules/threads/dist/master/thread.js\");\nObject.defineProperty(exports, \"Thread\", ({ enumerable: true, get: function () { return thread_1.Thread; } }));\n/** Separate class to spawn workers from source code blobs or strings. */\nexports.BlobWorker = implementation_1.getWorkerImplementation().blob;\n/** Worker implementation. Either web worker or a node.js Worker class. */\nexports.Worker = implementation_1.getWorkerImplementation().default;\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/master/index.js?");

/***/ }),

/***/ "../node_modules/threads/dist/master/invocation-proxy.js":
/*!***************************************************************!*\
  !*** ../node_modules/threads/dist/master/invocation-proxy.js ***!
  \***************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\n/*\n * This source file contains the code for proxying calls in the master thread to calls in the workers\n * by `.postMessage()`-ing.\n *\n * Keep in mind that this code can make or break the program's performance! Need to optimize more\n */\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.createProxyModule = exports.createProxyFunction = void 0;\nconst debug_1 = __importDefault(__webpack_require__(/*! debug */ \"../node_modules/debug/src/browser.js\"));\nconst observable_fns_1 = __webpack_require__(/*! observable-fns */ \"../node_modules/observable-fns/dist.esm/index.js\");\nconst common_1 = __webpack_require__(/*! ../common */ \"../node_modules/threads/dist/common.js\");\nconst observable_promise_1 = __webpack_require__(/*! ../observable-promise */ \"../node_modules/threads/dist/observable-promise.js\");\nconst transferable_1 = __webpack_require__(/*! ../transferable */ \"../node_modules/threads/dist/transferable.js\");\nconst messages_1 = __webpack_require__(/*! ../types/messages */ \"../node_modules/threads/dist/types/messages.js\");\nconst debugMessages = debug_1.default(\"threads:master:messages\");\nlet nextJobUID = 1;\nconst dedupe = (array) => Array.from(new Set(array));\nconst isJobErrorMessage = (data) => data && data.type === messages_1.WorkerMessageType.error;\nconst isJobResultMessage = (data) => data && data.type === messages_1.WorkerMessageType.result;\nconst isJobStartMessage = (data) => data && data.type === messages_1.WorkerMessageType.running;\nfunction createObservableForJob(worker, jobUID) {\n    return new observable_fns_1.Observable(observer => {\n        let asyncType;\n        const messageHandler = ((event) => {\n            debugMessages(\"Message from worker:\", event.data);\n            if (!event.data || event.data.uid !== jobUID)\n                return;\n            if (isJobStartMessage(event.data)) {\n                asyncType = event.data.resultType;\n            }\n            else if (isJobResultMessage(event.data)) {\n                if (asyncType === \"promise\") {\n                    if (typeof event.data.payload !== \"undefined\") {\n                        observer.next(common_1.deserialize(event.data.payload));\n                    }\n                    observer.complete();\n                    worker.removeEventListener(\"message\", messageHandler);\n                }\n                else {\n                    if (event.data.payload) {\n                        observer.next(common_1.deserialize(event.data.payload));\n                    }\n                    if (event.data.complete) {\n                        observer.complete();\n                        worker.removeEventListener(\"message\", messageHandler);\n                    }\n                }\n            }\n            else if (isJobErrorMessage(event.data)) {\n                const error = common_1.deserialize(event.data.error);\n                if (asyncType === \"promise\" || !asyncType) {\n                    observer.error(error);\n                }\n                else {\n                    observer.error(error);\n                }\n                worker.removeEventListener(\"message\", messageHandler);\n            }\n        });\n        worker.addEventListener(\"message\", messageHandler);\n        return () => {\n            if (asyncType === \"observable\" || !asyncType) {\n                const cancelMessage = {\n                    type: messages_1.MasterMessageType.cancel,\n                    uid: jobUID\n                };\n                worker.postMessage(cancelMessage);\n            }\n            worker.removeEventListener(\"message\", messageHandler);\n        };\n    });\n}\nfunction prepareArguments(rawArgs) {\n    if (rawArgs.length === 0) {\n        // Exit early if possible\n        return {\n            args: [],\n            transferables: []\n        };\n    }\n    const args = [];\n    const transferables = [];\n    for (const arg of rawArgs) {\n        if (transferable_1.isTransferDescriptor(arg)) {\n            args.push(common_1.serialize(arg.send));\n            transferables.push(...arg.transferables);\n        }\n        else {\n            args.push(common_1.serialize(arg));\n        }\n    }\n    return {\n        args,\n        transferables: transferables.length === 0 ? transferables : dedupe(transferables)\n    };\n}\nfunction createProxyFunction(worker, method) {\n    return ((...rawArgs) => {\n        const uid = nextJobUID++;\n        const { args, transferables } = prepareArguments(rawArgs);\n        const runMessage = {\n            type: messages_1.MasterMessageType.run,\n            uid,\n            method,\n            args\n        };\n        debugMessages(\"Sending command to run function to worker:\", runMessage);\n        try {\n            worker.postMessage(runMessage, transferables);\n        }\n        catch (error) {\n            return observable_promise_1.ObservablePromise.from(Promise.reject(error));\n        }\n        return observable_promise_1.ObservablePromise.from(observable_fns_1.multicast(createObservableForJob(worker, uid)));\n    });\n}\nexports.createProxyFunction = createProxyFunction;\nfunction createProxyModule(worker, methodNames) {\n    const proxy = {};\n    for (const methodName of methodNames) {\n        proxy[methodName] = createProxyFunction(worker, methodName);\n    }\n    return proxy;\n}\nexports.createProxyModule = createProxyModule;\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/master/invocation-proxy.js?");

/***/ }),

/***/ "../node_modules/threads/dist/master/pool-types.js":
/*!*********************************************************!*\
  !*** ../node_modules/threads/dist/master/pool-types.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.PoolEventType = void 0;\n/** Pool event type. Specifies the type of each `PoolEvent`. */\nvar PoolEventType;\n(function (PoolEventType) {\n    PoolEventType[\"initialized\"] = \"initialized\";\n    PoolEventType[\"taskCanceled\"] = \"taskCanceled\";\n    PoolEventType[\"taskCompleted\"] = \"taskCompleted\";\n    PoolEventType[\"taskFailed\"] = \"taskFailed\";\n    PoolEventType[\"taskQueued\"] = \"taskQueued\";\n    PoolEventType[\"taskQueueDrained\"] = \"taskQueueDrained\";\n    PoolEventType[\"taskStart\"] = \"taskStart\";\n    PoolEventType[\"terminated\"] = \"terminated\";\n})(PoolEventType = exports.PoolEventType || (exports.PoolEventType = {}));\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/master/pool-types.js?");

/***/ }),

/***/ "../node_modules/threads/dist/master/pool.js":
/*!***************************************************!*\
  !*** ../node_modules/threads/dist/master/pool.js ***!
  \***************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Pool = exports.Thread = exports.PoolEventType = void 0;\nconst debug_1 = __importDefault(__webpack_require__(/*! debug */ \"../node_modules/debug/src/browser.js\"));\nconst observable_fns_1 = __webpack_require__(/*! observable-fns */ \"../node_modules/observable-fns/dist.esm/index.js\");\nconst ponyfills_1 = __webpack_require__(/*! ../ponyfills */ \"../node_modules/threads/dist/ponyfills.js\");\nconst implementation_1 = __webpack_require__(/*! ./implementation */ \"../node_modules/threads/dist/master/implementation.browser.js\");\nconst pool_types_1 = __webpack_require__(/*! ./pool-types */ \"../node_modules/threads/dist/master/pool-types.js\");\nObject.defineProperty(exports, \"PoolEventType\", ({ enumerable: true, get: function () { return pool_types_1.PoolEventType; } }));\nconst thread_1 = __webpack_require__(/*! ./thread */ \"../node_modules/threads/dist/master/thread.js\");\nObject.defineProperty(exports, \"Thread\", ({ enumerable: true, get: function () { return thread_1.Thread; } }));\nlet nextPoolID = 1;\nfunction createArray(size) {\n    const array = [];\n    for (let index = 0; index < size; index++) {\n        array.push(index);\n    }\n    return array;\n}\nfunction delay(ms) {\n    return new Promise(resolve => setTimeout(resolve, ms));\n}\nfunction flatMap(array, mapper) {\n    return array.reduce((flattened, element) => [...flattened, ...mapper(element)], []);\n}\nfunction slugify(text) {\n    return text.replace(/\\W/g, \" \").trim().replace(/\\s+/g, \"-\");\n}\nfunction spawnWorkers(spawnWorker, count) {\n    return createArray(count).map(() => ({\n        init: spawnWorker(),\n        runningTasks: []\n    }));\n}\nclass WorkerPool {\n    constructor(spawnWorker, optionsOrSize) {\n        this.eventSubject = new observable_fns_1.Subject();\n        this.initErrors = [];\n        this.isClosing = false;\n        this.nextTaskID = 1;\n        this.taskQueue = [];\n        const options = typeof optionsOrSize === \"number\"\n            ? { size: optionsOrSize }\n            : optionsOrSize || {};\n        const { size = implementation_1.defaultPoolSize } = options;\n        this.debug = debug_1.default(`threads:pool:${slugify(options.name || String(nextPoolID++))}`);\n        this.options = options;\n        this.workers = spawnWorkers(spawnWorker, size);\n        this.eventObservable = observable_fns_1.multicast(observable_fns_1.Observable.from(this.eventSubject));\n        Promise.all(this.workers.map(worker => worker.init)).then(() => this.eventSubject.next({\n            type: pool_types_1.PoolEventType.initialized,\n            size: this.workers.length\n        }), error => {\n            this.debug(\"Error while initializing pool worker:\", error);\n            this.eventSubject.error(error);\n            this.initErrors.push(error);\n        });\n    }\n    findIdlingWorker() {\n        const { concurrency = 1 } = this.options;\n        return this.workers.find(worker => worker.runningTasks.length < concurrency);\n    }\n    runPoolTask(worker, task) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const workerID = this.workers.indexOf(worker) + 1;\n            this.debug(`Running task #${task.id} on worker #${workerID}...`);\n            this.eventSubject.next({\n                type: pool_types_1.PoolEventType.taskStart,\n                taskID: task.id,\n                workerID\n            });\n            try {\n                const returnValue = yield task.run(yield worker.init);\n                this.debug(`Task #${task.id} completed successfully`);\n                this.eventSubject.next({\n                    type: pool_types_1.PoolEventType.taskCompleted,\n                    returnValue,\n                    taskID: task.id,\n                    workerID\n                });\n            }\n            catch (error) {\n                this.debug(`Task #${task.id} failed`);\n                this.eventSubject.next({\n                    type: pool_types_1.PoolEventType.taskFailed,\n                    taskID: task.id,\n                    error,\n                    workerID\n                });\n            }\n        });\n    }\n    run(worker, task) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const runPromise = (() => __awaiter(this, void 0, void 0, function* () {\n                const removeTaskFromWorkersRunningTasks = () => {\n                    worker.runningTasks = worker.runningTasks.filter(someRunPromise => someRunPromise !== runPromise);\n                };\n                // Defer task execution by one tick to give handlers time to subscribe\n                yield delay(0);\n                try {\n                    yield this.runPoolTask(worker, task);\n                }\n                finally {\n                    removeTaskFromWorkersRunningTasks();\n                    if (!this.isClosing) {\n                        this.scheduleWork();\n                    }\n                }\n            }))();\n            worker.runningTasks.push(runPromise);\n        });\n    }\n    scheduleWork() {\n        this.debug(`Attempt de-queueing a task in order to run it...`);\n        const availableWorker = this.findIdlingWorker();\n        if (!availableWorker)\n            return;\n        const nextTask = this.taskQueue.shift();\n        if (!nextTask) {\n            this.debug(`Task queue is empty`);\n            this.eventSubject.next({ type: pool_types_1.PoolEventType.taskQueueDrained });\n            return;\n        }\n        this.run(availableWorker, nextTask);\n    }\n    taskCompletion(taskID) {\n        return new Promise((resolve, reject) => {\n            const eventSubscription = this.events().subscribe(event => {\n                if (event.type === pool_types_1.PoolEventType.taskCompleted && event.taskID === taskID) {\n                    eventSubscription.unsubscribe();\n                    resolve(event.returnValue);\n                }\n                else if (event.type === pool_types_1.PoolEventType.taskFailed && event.taskID === taskID) {\n                    eventSubscription.unsubscribe();\n                    reject(event.error);\n                }\n                else if (event.type === pool_types_1.PoolEventType.terminated) {\n                    eventSubscription.unsubscribe();\n                    reject(Error(\"Pool has been terminated before task was run.\"));\n                }\n            });\n        });\n    }\n    settled(allowResolvingImmediately = false) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const getCurrentlyRunningTasks = () => flatMap(this.workers, worker => worker.runningTasks);\n            const taskFailures = [];\n            const failureSubscription = this.eventObservable.subscribe(event => {\n                if (event.type === pool_types_1.PoolEventType.taskFailed) {\n                    taskFailures.push(event.error);\n                }\n            });\n            if (this.initErrors.length > 0) {\n                return Promise.reject(this.initErrors[0]);\n            }\n            if (allowResolvingImmediately && this.taskQueue.length === 0) {\n                yield ponyfills_1.allSettled(getCurrentlyRunningTasks());\n                return taskFailures;\n            }\n            yield new Promise((resolve, reject) => {\n                const subscription = this.eventObservable.subscribe({\n                    next(event) {\n                        if (event.type === pool_types_1.PoolEventType.taskQueueDrained) {\n                            subscription.unsubscribe();\n                            resolve(void 0);\n                        }\n                    },\n                    error: reject // make a pool-wide error reject the completed() result promise\n                });\n            });\n            yield ponyfills_1.allSettled(getCurrentlyRunningTasks());\n            failureSubscription.unsubscribe();\n            return taskFailures;\n        });\n    }\n    completed(allowResolvingImmediately = false) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const settlementPromise = this.settled(allowResolvingImmediately);\n            const earlyExitPromise = new Promise((resolve, reject) => {\n                const subscription = this.eventObservable.subscribe({\n                    next(event) {\n                        if (event.type === pool_types_1.PoolEventType.taskQueueDrained) {\n                            subscription.unsubscribe();\n                            resolve(settlementPromise);\n                        }\n                        else if (event.type === pool_types_1.PoolEventType.taskFailed) {\n                            subscription.unsubscribe();\n                            reject(event.error);\n                        }\n                    },\n                    error: reject // make a pool-wide error reject the completed() result promise\n                });\n            });\n            const errors = yield Promise.race([\n                settlementPromise,\n                earlyExitPromise\n            ]);\n            if (errors.length > 0) {\n                throw errors[0];\n            }\n        });\n    }\n    events() {\n        return this.eventObservable;\n    }\n    queue(taskFunction) {\n        const { maxQueuedJobs = Infinity } = this.options;\n        if (this.isClosing) {\n            throw Error(`Cannot schedule pool tasks after terminate() has been called.`);\n        }\n        if (this.initErrors.length > 0) {\n            throw this.initErrors[0];\n        }\n        const taskID = this.nextTaskID++;\n        const taskCompletion = this.taskCompletion(taskID);\n        taskCompletion.catch((error) => {\n            // Prevent unhandled rejections here as we assume the user will use\n            // `pool.completed()`, `pool.settled()` or `task.catch()` to handle errors\n            this.debug(`Task #${taskID} errored:`, error);\n        });\n        const task = {\n            id: taskID,\n            run: taskFunction,\n            cancel: () => {\n                if (this.taskQueue.indexOf(task) === -1)\n                    return;\n                this.taskQueue = this.taskQueue.filter(someTask => someTask !== task);\n                this.eventSubject.next({\n                    type: pool_types_1.PoolEventType.taskCanceled,\n                    taskID: task.id\n                });\n            },\n            then: taskCompletion.then.bind(taskCompletion)\n        };\n        if (this.taskQueue.length >= maxQueuedJobs) {\n            throw Error(\"Maximum number of pool tasks queued. Refusing to queue another one.\\n\" +\n                \"This usually happens for one of two reasons: We are either at peak \" +\n                \"workload right now or some tasks just won't finish, thus blocking the pool.\");\n        }\n        this.debug(`Queueing task #${task.id}...`);\n        this.taskQueue.push(task);\n        this.eventSubject.next({\n            type: pool_types_1.PoolEventType.taskQueued,\n            taskID: task.id\n        });\n        this.scheduleWork();\n        return task;\n    }\n    terminate(force) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.isClosing = true;\n            if (!force) {\n                yield this.completed(true);\n            }\n            this.eventSubject.next({\n                type: pool_types_1.PoolEventType.terminated,\n                remainingQueue: [...this.taskQueue]\n            });\n            this.eventSubject.complete();\n            yield Promise.all(this.workers.map((worker) => __awaiter(this, void 0, void 0, function* () { return thread_1.Thread.terminate(yield worker.init); })));\n        });\n    }\n}\nWorkerPool.EventType = pool_types_1.PoolEventType;\n/**\n * Thread pool constructor. Creates a new pool and spawns its worker threads.\n */\nfunction PoolConstructor(spawnWorker, optionsOrSize) {\n    // The function exists only so we don't need to use `new` to create a pool (we still can, though).\n    // If the Pool is a class or not is an implementation detail that should not concern the user.\n    return new WorkerPool(spawnWorker, optionsOrSize);\n}\nPoolConstructor.EventType = pool_types_1.PoolEventType;\n/**\n * Thread pool constructor. Creates a new pool and spawns its worker threads.\n */\nexports.Pool = PoolConstructor;\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/master/pool.js?");

/***/ }),

/***/ "../node_modules/threads/dist/master/spawn.js":
/*!****************************************************!*\
  !*** ../node_modules/threads/dist/master/spawn.js ***!
  \****************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.spawn = void 0;\nconst debug_1 = __importDefault(__webpack_require__(/*! debug */ \"../node_modules/debug/src/browser.js\"));\nconst observable_fns_1 = __webpack_require__(/*! observable-fns */ \"../node_modules/observable-fns/dist.esm/index.js\");\nconst common_1 = __webpack_require__(/*! ../common */ \"../node_modules/threads/dist/common.js\");\nconst promise_1 = __webpack_require__(/*! ../promise */ \"../node_modules/threads/dist/promise.js\");\nconst symbols_1 = __webpack_require__(/*! ../symbols */ \"../node_modules/threads/dist/symbols.js\");\nconst master_1 = __webpack_require__(/*! ../types/master */ \"../node_modules/threads/dist/types/master.js\");\nconst invocation_proxy_1 = __webpack_require__(/*! ./invocation-proxy */ \"../node_modules/threads/dist/master/invocation-proxy.js\");\nconst debugMessages = debug_1.default(\"threads:master:messages\");\nconst debugSpawn = debug_1.default(\"threads:master:spawn\");\nconst debugThreadUtils = debug_1.default(\"threads:master:thread-utils\");\nconst isInitMessage = (data) => data && data.type === \"init\";\nconst isUncaughtErrorMessage = (data) => data && data.type === \"uncaughtError\";\nconst initMessageTimeout = typeof process !== \"undefined\" && process.env.THREADS_WORKER_INIT_TIMEOUT\n    ? Number.parseInt(process.env.THREADS_WORKER_INIT_TIMEOUT, 10)\n    : 10000;\nfunction withTimeout(promise, timeoutInMs, errorMessage) {\n    return __awaiter(this, void 0, void 0, function* () {\n        let timeoutHandle;\n        const timeout = new Promise((resolve, reject) => {\n            timeoutHandle = setTimeout(() => reject(Error(errorMessage)), timeoutInMs);\n        });\n        const result = yield Promise.race([\n            promise,\n            timeout\n        ]);\n        clearTimeout(timeoutHandle);\n        return result;\n    });\n}\nfunction receiveInitMessage(worker) {\n    return new Promise((resolve, reject) => {\n        const messageHandler = ((event) => {\n            debugMessages(\"Message from worker before finishing initialization:\", event.data);\n            if (isInitMessage(event.data)) {\n                worker.removeEventListener(\"message\", messageHandler);\n                resolve(event.data);\n            }\n            else if (isUncaughtErrorMessage(event.data)) {\n                worker.removeEventListener(\"message\", messageHandler);\n                reject(common_1.deserialize(event.data.error));\n            }\n        });\n        worker.addEventListener(\"message\", messageHandler);\n    });\n}\nfunction createEventObservable(worker, workerTermination) {\n    return new observable_fns_1.Observable(observer => {\n        const messageHandler = ((messageEvent) => {\n            const workerEvent = {\n                type: master_1.WorkerEventType.message,\n                data: messageEvent.data\n            };\n            observer.next(workerEvent);\n        });\n        const rejectionHandler = ((errorEvent) => {\n            debugThreadUtils(\"Unhandled promise rejection event in thread:\", errorEvent);\n            const workerEvent = {\n                type: master_1.WorkerEventType.internalError,\n                error: Error(errorEvent.reason)\n            };\n            observer.next(workerEvent);\n        });\n        worker.addEventListener(\"message\", messageHandler);\n        worker.addEventListener(\"unhandledrejection\", rejectionHandler);\n        workerTermination.then(() => {\n            const terminationEvent = {\n                type: master_1.WorkerEventType.termination\n            };\n            worker.removeEventListener(\"message\", messageHandler);\n            worker.removeEventListener(\"unhandledrejection\", rejectionHandler);\n            observer.next(terminationEvent);\n            observer.complete();\n        });\n    });\n}\nfunction createTerminator(worker) {\n    const [termination, resolver] = promise_1.createPromiseWithResolver();\n    const terminate = () => __awaiter(this, void 0, void 0, function* () {\n        debugThreadUtils(\"Terminating worker\");\n        // Newer versions of worker_threads workers return a promise\n        yield worker.terminate();\n        resolver();\n    });\n    return { terminate, termination };\n}\nfunction setPrivateThreadProps(raw, worker, workerEvents, terminate) {\n    const workerErrors = workerEvents\n        .filter(event => event.type === master_1.WorkerEventType.internalError)\n        .map(errorEvent => errorEvent.error);\n    // tslint:disable-next-line prefer-object-spread\n    return Object.assign(raw, {\n        [symbols_1.$errors]: workerErrors,\n        [symbols_1.$events]: workerEvents,\n        [symbols_1.$terminate]: terminate,\n        [symbols_1.$worker]: worker\n    });\n}\n/**\n * Spawn a new thread. Takes a fresh worker instance, wraps it in a thin\n * abstraction layer to provide the transparent API and verifies that\n * the worker has initialized successfully.\n *\n * @param worker Instance of `Worker`. Either a web worker, `worker_threads` worker or `tiny-worker` worker.\n * @param [options]\n * @param [options.timeout] Init message timeout. Default: 10000 or set by environment variable.\n */\nfunction spawn(worker, options) {\n    return __awaiter(this, void 0, void 0, function* () {\n        debugSpawn(\"Initializing new thread\");\n        const timeout = options && options.timeout ? options.timeout : initMessageTimeout;\n        const initMessage = yield withTimeout(receiveInitMessage(worker), timeout, `Timeout: Did not receive an init message from worker after ${timeout}ms. Make sure the worker calls expose().`);\n        const exposed = initMessage.exposed;\n        const { termination, terminate } = createTerminator(worker);\n        const events = createEventObservable(worker, termination);\n        if (exposed.type === \"function\") {\n            const proxy = invocation_proxy_1.createProxyFunction(worker);\n            return setPrivateThreadProps(proxy, worker, events, terminate);\n        }\n        else if (exposed.type === \"module\") {\n            const proxy = invocation_proxy_1.createProxyModule(worker, exposed.methods);\n            return setPrivateThreadProps(proxy, worker, events, terminate);\n        }\n        else {\n            const type = exposed.type;\n            throw Error(`Worker init message states unexpected type of expose(): ${type}`);\n        }\n    });\n}\nexports.spawn = spawn;\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/master/spawn.js?");

/***/ }),

/***/ "../node_modules/threads/dist/master/thread.js":
/*!*****************************************************!*\
  !*** ../node_modules/threads/dist/master/thread.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Thread = void 0;\nconst symbols_1 = __webpack_require__(/*! ../symbols */ \"../node_modules/threads/dist/symbols.js\");\nfunction fail(message) {\n    throw Error(message);\n}\n/** Thread utility functions. Use them to manage or inspect a `spawn()`-ed thread. */\nexports.Thread = {\n    /** Return an observable that can be used to subscribe to all errors happening in the thread. */\n    errors(thread) {\n        return thread[symbols_1.$errors] || fail(\"Error observable not found. Make sure to pass a thread instance as returned by the spawn() promise.\");\n    },\n    /** Return an observable that can be used to subscribe to internal events happening in the thread. Useful for debugging. */\n    events(thread) {\n        return thread[symbols_1.$events] || fail(\"Events observable not found. Make sure to pass a thread instance as returned by the spawn() promise.\");\n    },\n    /** Terminate a thread. Remember to terminate every thread when you are done using it. */\n    terminate(thread) {\n        return thread[symbols_1.$terminate]();\n    }\n};\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/master/thread.js?");

/***/ }),

/***/ "../node_modules/threads/dist/observable-promise.js":
/*!**********************************************************!*\
  !*** ../node_modules/threads/dist/observable-promise.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ObservablePromise = void 0;\nconst observable_fns_1 = __webpack_require__(/*! observable-fns */ \"../node_modules/observable-fns/dist.esm/index.js\");\nconst doNothing = () => undefined;\nconst returnInput = (input) => input;\nconst runDeferred = (fn) => Promise.resolve().then(fn);\nfunction fail(error) {\n    throw error;\n}\nfunction isThenable(thing) {\n    return thing && typeof thing.then === \"function\";\n}\n/**\n * Creates a hybrid, combining the APIs of an Observable and a Promise.\n *\n * It is used to proxy async process states when we are initially not sure\n * if that async process will yield values once (-> Promise) or multiple\n * times (-> Observable).\n *\n * Note that the observable promise inherits some of the observable's characteristics:\n * The `init` function will be called *once for every time anyone subscribes to it*.\n *\n * If this is undesired, derive a hot observable from it using `makeHot()` and\n * subscribe to that.\n */\nclass ObservablePromise extends observable_fns_1.Observable {\n    constructor(init) {\n        super((originalObserver) => {\n            // tslint:disable-next-line no-this-assignment\n            const self = this;\n            const observer = Object.assign(Object.assign({}, originalObserver), { complete() {\n                    originalObserver.complete();\n                    self.onCompletion();\n                }, error(error) {\n                    originalObserver.error(error);\n                    self.onError(error);\n                },\n                next(value) {\n                    originalObserver.next(value);\n                    self.onNext(value);\n                } });\n            try {\n                this.initHasRun = true;\n                return init(observer);\n            }\n            catch (error) {\n                observer.error(error);\n            }\n        });\n        this.initHasRun = false;\n        this.fulfillmentCallbacks = [];\n        this.rejectionCallbacks = [];\n        this.firstValueSet = false;\n        this.state = \"pending\";\n    }\n    onNext(value) {\n        if (!this.firstValueSet) {\n            this.firstValue = value;\n            this.firstValueSet = true;\n        }\n    }\n    onError(error) {\n        this.state = \"rejected\";\n        this.rejection = error;\n        for (const onRejected of this.rejectionCallbacks) {\n            // Promisifying the call to turn errors into unhandled promise rejections\n            // instead of them failing sync and cancelling the iteration\n            runDeferred(() => onRejected(error));\n        }\n    }\n    onCompletion() {\n        this.state = \"fulfilled\";\n        for (const onFulfilled of this.fulfillmentCallbacks) {\n            // Promisifying the call to turn errors into unhandled promise rejections\n            // instead of them failing sync and cancelling the iteration\n            runDeferred(() => onFulfilled(this.firstValue));\n        }\n    }\n    then(onFulfilledRaw, onRejectedRaw) {\n        const onFulfilled = onFulfilledRaw || returnInput;\n        const onRejected = onRejectedRaw || fail;\n        let onRejectedCalled = false;\n        return new Promise((resolve, reject) => {\n            const rejectionCallback = (error) => {\n                if (onRejectedCalled)\n                    return;\n                onRejectedCalled = true;\n                try {\n                    resolve(onRejected(error));\n                }\n                catch (anotherError) {\n                    reject(anotherError);\n                }\n            };\n            const fulfillmentCallback = (value) => {\n                try {\n                    resolve(onFulfilled(value));\n                }\n                catch (error) {\n                    rejectionCallback(error);\n                }\n            };\n            if (!this.initHasRun) {\n                this.subscribe({ error: rejectionCallback });\n            }\n            if (this.state === \"fulfilled\") {\n                return resolve(onFulfilled(this.firstValue));\n            }\n            if (this.state === \"rejected\") {\n                onRejectedCalled = true;\n                return resolve(onRejected(this.rejection));\n            }\n            this.fulfillmentCallbacks.push(fulfillmentCallback);\n            this.rejectionCallbacks.push(rejectionCallback);\n        });\n    }\n    catch(onRejected) {\n        return this.then(undefined, onRejected);\n    }\n    finally(onCompleted) {\n        const handler = onCompleted || doNothing;\n        return this.then((value) => {\n            handler();\n            return value;\n        }, () => handler());\n    }\n    static from(thing) {\n        if (isThenable(thing)) {\n            return new ObservablePromise(observer => {\n                const onFulfilled = (value) => {\n                    observer.next(value);\n                    observer.complete();\n                };\n                const onRejected = (error) => {\n                    observer.error(error);\n                };\n                thing.then(onFulfilled, onRejected);\n            });\n        }\n        else {\n            return super.from(thing);\n        }\n    }\n}\nexports.ObservablePromise = ObservablePromise;\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/observable-promise.js?");

/***/ }),

/***/ "../node_modules/threads/dist/ponyfills.js":
/*!*************************************************!*\
  !*** ../node_modules/threads/dist/ponyfills.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.allSettled = void 0;\n// Based on <https://github.com/es-shims/Promise.allSettled/blob/master/implementation.js>\nfunction allSettled(values) {\n    return Promise.all(values.map(item => {\n        const onFulfill = (value) => {\n            return { status: 'fulfilled', value };\n        };\n        const onReject = (reason) => {\n            return { status: 'rejected', reason };\n        };\n        const itemPromise = Promise.resolve(item);\n        try {\n            return itemPromise.then(onFulfill, onReject);\n        }\n        catch (error) {\n            return Promise.reject(error);\n        }\n    }));\n}\nexports.allSettled = allSettled;\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/ponyfills.js?");

/***/ }),

/***/ "../node_modules/threads/dist/promise.js":
/*!***********************************************!*\
  !*** ../node_modules/threads/dist/promise.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.createPromiseWithResolver = void 0;\nconst doNothing = () => undefined;\n/**\n * Creates a new promise and exposes its resolver function.\n * Use with care!\n */\nfunction createPromiseWithResolver() {\n    let alreadyResolved = false;\n    let resolvedTo;\n    let resolver = doNothing;\n    const promise = new Promise(resolve => {\n        if (alreadyResolved) {\n            resolve(resolvedTo);\n        }\n        else {\n            resolver = resolve;\n        }\n    });\n    const exposedResolver = (value) => {\n        alreadyResolved = true;\n        resolvedTo = value;\n        resolver(resolvedTo);\n    };\n    return [promise, exposedResolver];\n}\nexports.createPromiseWithResolver = createPromiseWithResolver;\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/promise.js?");

/***/ }),

/***/ "../node_modules/threads/dist/serializers.js":
/*!***************************************************!*\
  !*** ../node_modules/threads/dist/serializers.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DefaultSerializer = exports.extendSerializer = void 0;\nfunction extendSerializer(extend, implementation) {\n    const fallbackDeserializer = extend.deserialize.bind(extend);\n    const fallbackSerializer = extend.serialize.bind(extend);\n    return {\n        deserialize(message) {\n            return implementation.deserialize(message, fallbackDeserializer);\n        },\n        serialize(input) {\n            return implementation.serialize(input, fallbackSerializer);\n        }\n    };\n}\nexports.extendSerializer = extendSerializer;\nconst DefaultErrorSerializer = {\n    deserialize(message) {\n        return Object.assign(Error(message.message), {\n            name: message.name,\n            stack: message.stack\n        });\n    },\n    serialize(error) {\n        return {\n            __error_marker: \"$$error\",\n            message: error.message,\n            name: error.name,\n            stack: error.stack\n        };\n    }\n};\nconst isSerializedError = (thing) => thing && typeof thing === \"object\" && \"__error_marker\" in thing && thing.__error_marker === \"$$error\";\nexports.DefaultSerializer = {\n    deserialize(message) {\n        if (isSerializedError(message)) {\n            return DefaultErrorSerializer.deserialize(message);\n        }\n        else {\n            return message;\n        }\n    },\n    serialize(input) {\n        if (input instanceof Error) {\n            return DefaultErrorSerializer.serialize(input);\n        }\n        else {\n            return input;\n        }\n    }\n};\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/serializers.js?");

/***/ }),

/***/ "../node_modules/threads/dist/symbols.js":
/*!***********************************************!*\
  !*** ../node_modules/threads/dist/symbols.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.$worker = exports.$transferable = exports.$terminate = exports.$events = exports.$errors = void 0;\nexports.$errors = Symbol(\"thread.errors\");\nexports.$events = Symbol(\"thread.events\");\nexports.$terminate = Symbol(\"thread.terminate\");\nexports.$transferable = Symbol(\"thread.transferable\");\nexports.$worker = Symbol(\"thread.worker\");\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/symbols.js?");

/***/ }),

/***/ "../node_modules/threads/dist/transferable.js":
/*!****************************************************!*\
  !*** ../node_modules/threads/dist/transferable.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Transfer = exports.isTransferDescriptor = void 0;\nconst symbols_1 = __webpack_require__(/*! ./symbols */ \"../node_modules/threads/dist/symbols.js\");\nfunction isTransferable(thing) {\n    if (!thing || typeof thing !== \"object\")\n        return false;\n    // Don't check too thoroughly, since the list of transferable things in JS might grow over time\n    return true;\n}\nfunction isTransferDescriptor(thing) {\n    return thing && typeof thing === \"object\" && thing[symbols_1.$transferable];\n}\nexports.isTransferDescriptor = isTransferDescriptor;\nfunction Transfer(payload, transferables) {\n    if (!transferables) {\n        if (!isTransferable(payload))\n            throw Error();\n        transferables = [payload];\n    }\n    return {\n        [symbols_1.$transferable]: true,\n        send: payload,\n        transferables\n    };\n}\nexports.Transfer = Transfer;\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/transferable.js?");

/***/ }),

/***/ "../node_modules/threads/dist/types/master.js":
/*!****************************************************!*\
  !*** ../node_modules/threads/dist/types/master.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n/// <reference lib=\"dom\" />\n// tslint:disable max-classes-per-file\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WorkerEventType = void 0;\nconst symbols_1 = __webpack_require__(/*! ../symbols */ \"../node_modules/threads/dist/symbols.js\");\n/** Event as emitted by worker thread. Subscribe to using `Thread.events(thread)`. */\nvar WorkerEventType;\n(function (WorkerEventType) {\n    WorkerEventType[\"internalError\"] = \"internalError\";\n    WorkerEventType[\"message\"] = \"message\";\n    WorkerEventType[\"termination\"] = \"termination\";\n})(WorkerEventType = exports.WorkerEventType || (exports.WorkerEventType = {}));\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/types/master.js?");

/***/ }),

/***/ "../node_modules/threads/dist/types/messages.js":
/*!******************************************************!*\
  !*** ../node_modules/threads/dist/types/messages.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WorkerMessageType = exports.MasterMessageType = void 0;\n/////////////////////////////\n// Messages sent by master:\nvar MasterMessageType;\n(function (MasterMessageType) {\n    MasterMessageType[\"cancel\"] = \"cancel\";\n    MasterMessageType[\"run\"] = \"run\";\n})(MasterMessageType = exports.MasterMessageType || (exports.MasterMessageType = {}));\n////////////////////////////\n// Messages sent by worker:\nvar WorkerMessageType;\n(function (WorkerMessageType) {\n    WorkerMessageType[\"error\"] = \"error\";\n    WorkerMessageType[\"init\"] = \"init\";\n    WorkerMessageType[\"result\"] = \"result\";\n    WorkerMessageType[\"running\"] = \"running\";\n    WorkerMessageType[\"uncaughtError\"] = \"uncaughtError\";\n})(WorkerMessageType = exports.WorkerMessageType || (exports.WorkerMessageType = {}));\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/types/messages.js?");

/***/ }),

/***/ "../node_modules/threads/dist/worker/implementation.browser.js":
/*!*********************************************************************!*\
  !*** ../node_modules/threads/dist/worker/implementation.browser.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n/// <reference lib=\"dom\" />\n// tslint:disable no-shadowed-variable\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst isWorkerRuntime = function isWorkerRuntime() {\n    const isWindowContext = typeof self !== \"undefined\" && typeof Window !== \"undefined\" && self instanceof Window;\n    return typeof self !== \"undefined\" && self.postMessage && !isWindowContext ? true : false;\n};\nconst postMessageToMaster = function postMessageToMaster(data, transferList) {\n    self.postMessage(data, transferList);\n};\nconst subscribeToMasterMessages = function subscribeToMasterMessages(onMessage) {\n    const messageHandler = (messageEvent) => {\n        onMessage(messageEvent.data);\n    };\n    const unsubscribe = () => {\n        self.removeEventListener(\"message\", messageHandler);\n    };\n    self.addEventListener(\"message\", messageHandler);\n    return unsubscribe;\n};\nexports.default = {\n    isWorkerRuntime,\n    postMessageToMaster,\n    subscribeToMasterMessages\n};\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/worker/implementation.browser.js?");

/***/ }),

/***/ "../node_modules/threads/dist/worker/index.js":
/*!****************************************************!*\
  !*** ../node_modules/threads/dist/worker/index.js ***!
  \****************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.expose = exports.isWorkerRuntime = exports.Transfer = exports.registerSerializer = void 0;\nconst is_observable_1 = __importDefault(__webpack_require__(/*! is-observable */ \"../node_modules/is-observable/index.js\"));\nconst common_1 = __webpack_require__(/*! ../common */ \"../node_modules/threads/dist/common.js\");\nconst transferable_1 = __webpack_require__(/*! ../transferable */ \"../node_modules/threads/dist/transferable.js\");\nconst messages_1 = __webpack_require__(/*! ../types/messages */ \"../node_modules/threads/dist/types/messages.js\");\nconst implementation_1 = __importDefault(__webpack_require__(/*! ./implementation */ \"../node_modules/threads/dist/worker/implementation.browser.js\"));\nvar common_2 = __webpack_require__(/*! ../common */ \"../node_modules/threads/dist/common.js\");\nObject.defineProperty(exports, \"registerSerializer\", ({ enumerable: true, get: function () { return common_2.registerSerializer; } }));\nvar transferable_2 = __webpack_require__(/*! ../transferable */ \"../node_modules/threads/dist/transferable.js\");\nObject.defineProperty(exports, \"Transfer\", ({ enumerable: true, get: function () { return transferable_2.Transfer; } }));\n/** Returns `true` if this code is currently running in a worker. */\nexports.isWorkerRuntime = implementation_1.default.isWorkerRuntime;\nlet exposeCalled = false;\nconst activeSubscriptions = new Map();\nconst isMasterJobCancelMessage = (thing) => thing && thing.type === messages_1.MasterMessageType.cancel;\nconst isMasterJobRunMessage = (thing) => thing && thing.type === messages_1.MasterMessageType.run;\n/**\n * There are issues with `is-observable` not recognizing zen-observable's instances.\n * We are using `observable-fns`, but it's based on zen-observable, too.\n */\nconst isObservable = (thing) => is_observable_1.default(thing) || isZenObservable(thing);\nfunction isZenObservable(thing) {\n    return thing && typeof thing === \"object\" && typeof thing.subscribe === \"function\";\n}\nfunction deconstructTransfer(thing) {\n    return transferable_1.isTransferDescriptor(thing)\n        ? { payload: thing.send, transferables: thing.transferables }\n        : { payload: thing, transferables: undefined };\n}\nfunction postFunctionInitMessage() {\n    const initMessage = {\n        type: messages_1.WorkerMessageType.init,\n        exposed: {\n            type: \"function\"\n        }\n    };\n    implementation_1.default.postMessageToMaster(initMessage);\n}\nfunction postModuleInitMessage(methodNames) {\n    const initMessage = {\n        type: messages_1.WorkerMessageType.init,\n        exposed: {\n            type: \"module\",\n            methods: methodNames\n        }\n    };\n    implementation_1.default.postMessageToMaster(initMessage);\n}\nfunction postJobErrorMessage(uid, rawError) {\n    const { payload: error, transferables } = deconstructTransfer(rawError);\n    const errorMessage = {\n        type: messages_1.WorkerMessageType.error,\n        uid,\n        error: common_1.serialize(error)\n    };\n    implementation_1.default.postMessageToMaster(errorMessage, transferables);\n}\nfunction postJobResultMessage(uid, completed, resultValue) {\n    const { payload, transferables } = deconstructTransfer(resultValue);\n    const resultMessage = {\n        type: messages_1.WorkerMessageType.result,\n        uid,\n        complete: completed ? true : undefined,\n        payload\n    };\n    implementation_1.default.postMessageToMaster(resultMessage, transferables);\n}\nfunction postJobStartMessage(uid, resultType) {\n    const startMessage = {\n        type: messages_1.WorkerMessageType.running,\n        uid,\n        resultType\n    };\n    implementation_1.default.postMessageToMaster(startMessage);\n}\nfunction postUncaughtErrorMessage(error) {\n    try {\n        const errorMessage = {\n            type: messages_1.WorkerMessageType.uncaughtError,\n            error: common_1.serialize(error)\n        };\n        implementation_1.default.postMessageToMaster(errorMessage);\n    }\n    catch (subError) {\n        // tslint:disable-next-line no-console\n        console.error(\"Not reporting uncaught error back to master thread as it \" +\n            \"occured while reporting an uncaught error already.\" +\n            \"\\nLatest error:\", subError, \"\\nOriginal error:\", error);\n    }\n}\nfunction runFunction(jobUID, fn, args) {\n    return __awaiter(this, void 0, void 0, function* () {\n        let syncResult;\n        try {\n            syncResult = fn(...args);\n        }\n        catch (error) {\n            return postJobErrorMessage(jobUID, error);\n        }\n        const resultType = isObservable(syncResult) ? \"observable\" : \"promise\";\n        postJobStartMessage(jobUID, resultType);\n        if (isObservable(syncResult)) {\n            const subscription = syncResult.subscribe(value => postJobResultMessage(jobUID, false, common_1.serialize(value)), error => {\n                postJobErrorMessage(jobUID, common_1.serialize(error));\n                activeSubscriptions.delete(jobUID);\n            }, () => {\n                postJobResultMessage(jobUID, true);\n                activeSubscriptions.delete(jobUID);\n            });\n            activeSubscriptions.set(jobUID, subscription);\n        }\n        else {\n            try {\n                const result = yield syncResult;\n                postJobResultMessage(jobUID, true, common_1.serialize(result));\n            }\n            catch (error) {\n                postJobErrorMessage(jobUID, common_1.serialize(error));\n            }\n        }\n    });\n}\n/**\n * Expose a function or a module (an object whose values are functions)\n * to the main thread. Must be called exactly once in every worker thread\n * to signal its API to the main thread.\n *\n * @param exposed Function or object whose values are functions\n */\nfunction expose(exposed) {\n    if (!implementation_1.default.isWorkerRuntime()) {\n        throw Error(\"expose() called in the master thread.\");\n    }\n    if (exposeCalled) {\n        throw Error(\"expose() called more than once. This is not possible. Pass an object to expose() if you want to expose multiple functions.\");\n    }\n    exposeCalled = true;\n    if (typeof exposed === \"function\") {\n        implementation_1.default.subscribeToMasterMessages(messageData => {\n            if (isMasterJobRunMessage(messageData) && !messageData.method) {\n                runFunction(messageData.uid, exposed, messageData.args.map(common_1.deserialize));\n            }\n        });\n        postFunctionInitMessage();\n    }\n    else if (typeof exposed === \"object\" && exposed) {\n        implementation_1.default.subscribeToMasterMessages(messageData => {\n            if (isMasterJobRunMessage(messageData) && messageData.method) {\n                runFunction(messageData.uid, exposed[messageData.method], messageData.args.map(common_1.deserialize));\n            }\n        });\n        const methodNames = Object.keys(exposed).filter(key => typeof exposed[key] === \"function\");\n        postModuleInitMessage(methodNames);\n    }\n    else {\n        throw Error(`Invalid argument passed to expose(). Expected a function or an object, got: ${exposed}`);\n    }\n    implementation_1.default.subscribeToMasterMessages(messageData => {\n        if (isMasterJobCancelMessage(messageData)) {\n            const jobUID = messageData.uid;\n            const subscription = activeSubscriptions.get(jobUID);\n            if (subscription) {\n                subscription.unsubscribe();\n                activeSubscriptions.delete(jobUID);\n            }\n        }\n    });\n}\nexports.expose = expose;\nif (typeof self !== \"undefined\" && typeof self.addEventListener === \"function\" && implementation_1.default.isWorkerRuntime()) {\n    self.addEventListener(\"error\", event => {\n        // Post with some delay, so the master had some time to subscribe to messages\n        setTimeout(() => postUncaughtErrorMessage(event.error || event), 250);\n    });\n    self.addEventListener(\"unhandledrejection\", event => {\n        const error = event.reason;\n        if (error && typeof error.message === \"string\") {\n            // Post with some delay, so the master had some time to subscribe to messages\n            setTimeout(() => postUncaughtErrorMessage(error), 250);\n        }\n    });\n}\nif (typeof process !== \"undefined\" && typeof process.on === \"function\" && implementation_1.default.isWorkerRuntime()) {\n    process.on(\"uncaughtException\", (error) => {\n        // Post with some delay, so the master had some time to subscribe to messages\n        setTimeout(() => postUncaughtErrorMessage(error), 250);\n    });\n    process.on(\"unhandledRejection\", (error) => {\n        if (error && typeof error.message === \"string\") {\n            // Post with some delay, so the master had some time to subscribe to messages\n            setTimeout(() => postUncaughtErrorMessage(error), 250);\n        }\n    });\n}\n\n\n//# sourceURL=webpack:///../node_modules/threads/dist/worker/index.js?");

/***/ }),

/***/ "../node_modules/through2/through2.js":
/*!********************************************!*\
  !*** ../node_modules/through2/through2.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var Transform = __webpack_require__(/*! readable-stream */ \"../node_modules/readable-stream/readable-browser.js\").Transform\n  , inherits  = __webpack_require__(/*! inherits */ \"../node_modules/inherits/inherits_browser.js\")\n\nfunction DestroyableTransform(opts) {\n  Transform.call(this, opts)\n  this._destroyed = false\n}\n\ninherits(DestroyableTransform, Transform)\n\nDestroyableTransform.prototype.destroy = function(err) {\n  if (this._destroyed) return\n  this._destroyed = true\n  \n  var self = this\n  process.nextTick(function() {\n    if (err)\n      self.emit('error', err)\n    self.emit('close')\n  })\n}\n\n// a noop _transform function\nfunction noop (chunk, enc, callback) {\n  callback(null, chunk)\n}\n\n\n// create a new export function, used by both the main export and\n// the .ctor export, contains common logic for dealing with arguments\nfunction through2 (construct) {\n  return function (options, transform, flush) {\n    if (typeof options == 'function') {\n      flush     = transform\n      transform = options\n      options   = {}\n    }\n\n    if (typeof transform != 'function')\n      transform = noop\n\n    if (typeof flush != 'function')\n      flush = null\n\n    return construct(options, transform, flush)\n  }\n}\n\n\n// main export, just make me a transform stream!\nmodule.exports = through2(function (options, transform, flush) {\n  var t2 = new DestroyableTransform(options)\n\n  t2._transform = transform\n\n  if (flush)\n    t2._flush = flush\n\n  return t2\n})\n\n\n// make me a reusable prototype that I can `new`, or implicitly `new`\n// with a constructor call\nmodule.exports.ctor = through2(function (options, transform, flush) {\n  function Through2 (override) {\n    if (!(this instanceof Through2))\n      return new Through2(override)\n\n    this.options = Object.assign({}, options, override)\n\n    DestroyableTransform.call(this, this.options)\n  }\n\n  inherits(Through2, DestroyableTransform)\n\n  Through2.prototype._transform = transform\n\n  if (flush)\n    Through2.prototype._flush = flush\n\n  return Through2\n})\n\n\nmodule.exports.obj = through2(function (options, transform, flush) {\n  var t2 = new DestroyableTransform(Object.assign({ objectMode: true, highWaterMark: 16 }, options))\n\n  t2._transform = transform\n\n  if (flush)\n    t2._flush = flush\n\n  return t2\n})\n\n\n//# sourceURL=webpack:///../node_modules/through2/through2.js?");

/***/ }),

/***/ "../node_modules/txml/tXml.js":
/*!************************************!*\
  !*** ../node_modules/txml/tXml.js ***!
  \************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// ==ClosureCompiler==\n// @output_file_name default.js\n// @compilation_level SIMPLE_OPTIMIZATIONS\n// ==/ClosureCompiler==\n\n/**\n * @author: Tobias Nickel\n * @created: 06.04.2015\n * I needed a small xmlparser chat can be used in a worker.\n */\n\n/**\n * @typedef tNode \n * @property {string} tagName \n * @property {object} attributes\n * @property {tNode|string|number[]} children \n **/\n\n/**\n * parseXML / html into a DOM Object. with no validation and some failur tolerance\n * @param {string} S your XML to parse\n * @param options {object} all other options:\n * searchId {string} the id of a single element, that should be returned. using this will increase the speed rapidly\n * filter {function} filter method, as you know it from Array.filter. but is goes throw the DOM.\n\n * @return {tNode[]}\n */\nfunction tXml(S, options) {\n    \"use strict\";\n    options = options || {};\n\n    var pos = options.pos || 0;\n\n    var openBracket = \"<\";\n    var openBracketCC = \"<\".charCodeAt(0);\n    var closeBracket = \">\";\n    var closeBracketCC = \">\".charCodeAt(0);\n    var minus = \"-\";\n    var minusCC = \"-\".charCodeAt(0);\n    var slash = \"/\";\n    var slashCC = \"/\".charCodeAt(0);\n    var exclamation = '!';\n    var exclamationCC = '!'.charCodeAt(0);\n    var singleQuote = \"'\";\n    var singleQuoteCC = \"'\".charCodeAt(0);\n    var doubleQuote = '\"';\n    var doubleQuoteCC = '\"'.charCodeAt(0);\n    var openCornerBracket = '[';\n    var openCornerBracketCC = '['.charCodeAt(0);\n    var closeCornerBracket = ']';\n    var closeCornerBracketCC = ']'.charCodeAt(0);\n    \n\n    /**\n     * parsing a list of entries\n     */\n    function parseChildren() {\n        var children = [];\n        while (S[pos]) {\n            if (S.charCodeAt(pos) == openBracketCC) {\n                if (S.charCodeAt(pos + 1) === slashCC) {\n                    pos = S.indexOf(closeBracket, pos);\n                    if (pos + 1) pos += 1\n                    return children;\n                } else if (S.charCodeAt(pos + 1) === exclamationCC) {\n                    if (S.charCodeAt(pos + 2) == minusCC) {\n                        //comment support\n                        while (pos !== -1 && !(S.charCodeAt(pos) === closeBracketCC && S.charCodeAt(pos - 1) == minusCC && S.charCodeAt(pos - 2) == minusCC && pos != -1)) {\n                            pos = S.indexOf(closeBracket, pos + 1);\n                        }\n                        if (pos === -1) {\n                            pos = S.length\n                        }\n                    }else if(\n                        S.charCodeAt(pos + 2) === openCornerBracketCC\n                        && S.charCodeAt(pos + 8) === openCornerBracketCC\n                        && S.substr(pos+3, 5).toLowerCase() === 'cdata'\n                    ){\n                        // cdata\n                        var cdataEndIndex = S.indexOf(']]>',pos)\n                        if (cdataEndIndex==-1) {\n                            children.push(S.substr(pos+8));\n                            pos=S.length;\n                        } else {\n                            children.push(S.substring(pos+9, cdataEndIndex));\n                            pos = cdataEndIndex + 3;\n                        }\n                        continue\n                    } else {\n                        // doctypesupport\n                        pos += 2;\n                        while (S.charCodeAt(pos) !== closeBracketCC && S[pos]) {\n                            pos++;\n                        }\n                    }\n                    pos++;\n                    continue;\n                }\n                var node = parseNode();\n                children.push(node);\n            } else {\n                var text = parseText()\n                if (text.trim().length > 0)\n                    children.push(text);\n                pos++;\n            }\n        }\n        return children;\n    }\n\n    /**\n     *    returns the text outside of texts until the first '<'\n     */\n    function parseText() {\n        var start = pos;\n        pos = S.indexOf(openBracket, pos) - 1;\n        if (pos === -2)\n            pos = S.length;\n        return S.slice(start, pos + 1);\n    }\n    /**\n     *    returns text until the first nonAlphebetic letter\n     */\n    var nameSpacer = '\\r\\n\\t>/= ';\n\n    function parseName() {\n        var start = pos;\n        while (nameSpacer.indexOf(S[pos]) === -1 && S[pos]) {\n            pos++;\n        }\n        return S.slice(start, pos);\n    }\n    /**\n     *    is parsing a node, including tagName, Attributes and its children,\n     * to parse children it uses the parseChildren again, that makes the parsing recursive\n     */\n    var NoChildNodes = options.noChildNodes || ['img', 'br', 'input', 'meta', 'link'];\n\n    function parseNode() {\n        pos++;\n        const tagName = parseName();\n        const attributes = {};\n        let children = [];\n\n        // parsing attributes\n        while (S.charCodeAt(pos) !== closeBracketCC && S[pos]) {\n            var c = S.charCodeAt(pos);\n            if ((c > 64 && c < 91) || (c > 96 && c < 123)) {\n                //if('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.indexOf(S[pos])!==-1 ){\n                var name = parseName();\n                // search beginning of the string\n                var code = S.charCodeAt(pos);\n                while (code && code !== singleQuoteCC && code !== doubleQuoteCC && !((code > 64 && code < 91) || (code > 96 && code < 123)) && code !== closeBracketCC) {\n                    pos++;\n                    code = S.charCodeAt(pos);\n                }\n                if (code === singleQuoteCC || code === doubleQuoteCC) {\n                    var value = parseString();\n                    if (pos === -1) {\n                        return {\n                            tagName,\n                            attributes,\n                            children,\n                        };\n                    }\n                } else {\n                    value = null;\n                    pos--;\n                }\n                attributes[name] = value;\n            }\n            pos++;\n        }\n        // optional parsing of children\n        if (S.charCodeAt(pos - 1) !== slashCC) {\n            if (tagName == \"script\") {\n                var start = pos + 1;\n                pos = S.indexOf('</script>', pos);\n                children = [S.slice(start, pos)];\n                pos += 9;\n            } else if (tagName == \"style\") {\n                var start = pos + 1;\n                pos = S.indexOf('</style>', pos);\n                children = [S.slice(start, pos)];\n                pos += 8;\n            } else if (NoChildNodes.indexOf(tagName) == -1) {\n                pos++;\n                children = parseChildren(name);\n            }\n        } else {\n            pos++;\n        }\n        return {\n            tagName,\n            attributes,\n            children,\n        };\n    }\n\n    /**\n     *    is parsing a string, that starts with a char and with the same usually  ' or \"\n     */\n\n    function parseString() {\n        var startChar = S[pos];\n        var startpos = pos+1;\n        pos = S.indexOf(startChar, startpos)\n        return S.slice(startpos, pos);\n    }\n\n    /**\n     *\n     */\n    function findElements() {\n        var r = new RegExp('\\\\s' + options.attrName + '\\\\s*=[\\'\"]' + options.attrValue + '[\\'\"]').exec(S)\n        if (r) {\n            return r.index;\n        } else {\n            return -1;\n        }\n    }\n\n    var out = null;\n    if (options.attrValue !== undefined) {\n        options.attrName = options.attrName || 'id';\n        var out = [];\n\n        while ((pos = findElements()) !== -1) {\n            pos = S.lastIndexOf('<', pos);\n            if (pos !== -1) {\n                out.push(parseNode());\n            }\n            S = S.substr(pos);\n            pos = 0;\n        }\n    } else if (options.parseNode) {\n        out = parseNode()\n    } else {\n        out = parseChildren();\n    }\n\n    if (options.filter) {\n        out = tXml.filter(out, options.filter);\n    }\n\n    if (options.setPos) {\n        out.pos = pos;\n    }\n\n    return out;\n}\n\n/**\n * transform the DomObject to an object that is like the object of PHP`s simple_xmp_load_*() methods.\n * this format helps you to write that is more likely to keep your program working, even if there a small changes in the XML schema.\n * be aware, that it is not possible to reproduce the original xml from a simplified version, because the order of elements is not saved.\n * therefore your program will be more flexible and easier to read.\n *\n * @param {tNode[]} children the childrenList\n */\ntXml.simplify = function simplify(children) {\n    var out = {};\n    if (!children.length) {\n        return '';\n    }\n\n    if (children.length === 1 && typeof children[0] == 'string') {\n        return children[0];\n    }\n    // map each object\n    children.forEach(function(child) {\n        if (typeof child !== 'object') {\n            return;\n        }\n        if (!out[child.tagName])\n            out[child.tagName] = [];\n        var kids = tXml.simplify(child.children);\n        out[child.tagName].push(kids);\n        if (Object.keys(child.attributes).length) {\n            kids._attributes = child.attributes;\n        }\n    });\n\n    for (var i in out) {\n        if (out[i].length == 1) {\n            out[i] = out[i][0];\n        }\n    }\n\n    return out;\n};\n\n\n/**\n * similar to simplify, but lost less\n *\n * @param {tNode[]} children the childrenList\n */ \ntXml.simplifyLostLess = function simplify(children, parentAttributes={}) {\n    var out = {};\n    if (!children.length) {\n        return '';\n    }\n\n    if (children.length === 1 && typeof children[0] == 'string') {\n        return Object.keys(parentAttributes).length ? {\n            _attributes: parentAttributes,\n            value: children[0]\n        } :children[0];\n    }\n    // map each object\n    children.forEach(function(child) {\n        if (typeof child !== 'object') {\n            return;\n        }\n        if (!out[child.tagName])\n            out[child.tagName] = [];\n        var kids = tXml.simplifyLostLess(child.children||[], child.attributes);\n        out[child.tagName].push(kids);\n        if (Object.keys(child.attributes).length) {\n            kids._attributes = child.attributes;\n        }\n    });\n\n    return out;\n};\n\n/**\n * behaves the same way as Array.filter, if the filter method return true, the element is in the resultList\n * @params children{Array} the children of a node\n * @param f{function} the filter method\n */\ntXml.filter = function(children, f, dept=0,path='') {\n    var out = [];\n    children.forEach(function(child, i) {\n        if (typeof(child) === 'object' && f(child, i, dept, path)) out.push(child);\n        if (child.children) {\n            var kids = tXml.filter(child.children, f, dept+1, (path?path+'.':'')+i+'.'+child.tagName);\n            out = out.concat(kids);\n        }\n    });\n    return out;\n};\n\n/**\n * stringify a previously parsed string object.\n * this is useful,\n *  1. to remove whitespace\n * 2. to recreate xml data, with some changed data.\n * @param {tNode} O the object to Stringify\n */\ntXml.stringify = function stringify(O) {\n    var out = '';\n\n    function writeChildren(O) {\n        if (O)\n            for (var i = 0; i < O.length; i++) {\n                if (typeof O[i] == 'string') {\n                    out += O[i].trim();\n                } else {\n                    writeNode(O[i]);\n                }\n            }\n    }\n\n    function writeNode(N) {\n        out += \"<\" + N.tagName;\n        for (var i in N.attributes) {\n            if (N.attributes[i] === null) {\n                out += ' ' + i;\n            } else if (N.attributes[i].indexOf('\"') === -1) {\n                out += ' ' + i + '=\"' + N.attributes[i].trim() + '\"';\n            } else {\n                out += ' ' + i + \"='\" + N.attributes[i].trim() + \"'\";\n            }\n        }\n        out += '>';\n        writeChildren(N.children);\n        out += '</' + N.tagName + '>';\n    }\n    writeChildren(O);\n\n    return out;\n};\n\n\n/**\n * use this method to read the text content, of some node.\n * It is great if you have mixed content like:\n * this text has some <b>big</b> text and a <a href=''>link</a>\n * @return {string}\n */\ntXml.toContentString = function(tDom) {\n    if (Array.isArray(tDom)) {\n        var out = '';\n        tDom.forEach(function(e) {\n            out += ' ' + tXml.toContentString(e);\n            out = out.trim();\n        });\n        return out;\n    } else if (typeof tDom === 'object') {\n        return tXml.toContentString(tDom.children)\n    } else {\n        return ' ' + tDom;\n    }\n};\n\ntXml.getElementById = function(S, id, simplified) {\n    var out = tXml(S, {\n        attrValue: id\n    });\n    return simplified ? tXml.simplify(out) : out[0];\n};\n\ntXml.getElementsByClassName = function(S, classname, simplified) {\n    const out = tXml(S, {\n        attrName: 'class',\n        attrValue: '[a-zA-Z0-9- ]*' + classname + '[a-zA-Z0-9- ]*'\n    });\n    return simplified ? tXml.simplify(out) : out;\n};\n\ntXml.parseStream = function(stream, offset) {\n    if (typeof offset === 'string') {\n        offset = offset.length + 2;\n    }\n    if (typeof stream === 'string') {\n        var fs = __webpack_require__(/*! fs */ \"?a314\");\n        stream = fs.createReadStream(stream, { start: offset });\n        offset = 0;\n    }\n\n    var position = offset;\n    var data = '';\n    stream.on('data', function(chunk) {\n        data += chunk;\n        var lastPos = 0;\n        do {\n            position = data.indexOf('<', position) + 1;\n            if(!position) {\n                position = lastPos;\n                return;\n            }\n            if (data[position + 1] === '/') {\n                position = position + 1;\n                lastPos = pos;\n                continue;\n            }\n            var res = tXml(data, { pos: position-1, parseNode: true, setPos: true });\n            position = res.pos;\n            if (position > (data.length - 1) || position < lastPos) {\n                data = data.slice(lastPos);\n                position = 0;\n                lastPos = 0;\n                return;\n            } else {\n                stream.emit('xml', res);\n                lastPos = position;\n            }\n        } while (1);\n    });\n    // stream.on('end', function() {\n    //     console.log('end')\n    // });\n    return stream;\n}\n\ntXml.transformStream = function (offset) {\n    // require through here, so it will not get added to webpack/browserify\n    const through2 = __webpack_require__(/*! through2 */ \"../node_modules/through2/through2.js\");\n    if (typeof offset === 'string') {\n        offset = offset.length + 2;\n    }\n\n    var position = offset || 0;\n    var data = '';\n    const stream = through2({ readableObjectMode: true }, function (chunk, enc, callback) {\n        data += chunk;\n        var lastPos = 0;\n        do {\n            position = data.indexOf('<', position) + 1;\n            if (!position) {\n                position = lastPos;\n                return callback();;\n            }\n            if (data[position + 1] === '/') {\n                position = position + 1;\n                lastPos = pos;\n                continue;\n            }\n            var res = tXml(data, { pos: position - 1, parseNode: true, setPos: true });\n            position = res.pos;\n            if (position > (data.length - 1) || position < lastPos) {\n                data = data.slice(lastPos);\n                position = 0;\n                return callback();;\n            } else {\n                this.push(res);\n                lastPos = position;\n            }\n        } while (1);\n        callback();\n    });\n\n    return stream;\n}\n\nif (true) {\n    module.exports = tXml;\n    tXml.xml = tXml;\n}\n//console.clear();\n//console.log('here:',tXml.getElementById('<some><xml id=\"test\">dada</xml><that id=\"test\">value</that></some>','test'));\n//console.log('here:',tXml.getElementsByClassName('<some><xml id=\"test\" class=\"sdf test jsalf\">dada</xml><that id=\"test\">value</that></some>','test'));\n\n/*\nconsole.clear();\ntXml(d,'content');\n //some testCode\nvar s = document.body.innerHTML.toLowerCase();\nvar start = new Date().getTime();\nvar o = tXml(s,'content');\nvar end = new Date().getTime();\n//console.log(JSON.stringify(o,undefined,'\\t'));\nconsole.log(\"MILLISECONDS\",end-start);\nvar nodeCount=document.querySelectorAll('*').length;\nconsole.log('node count',nodeCount);\nconsole.log(\"speed:\",(1000/(end-start))*nodeCount,'Nodes / second')\n//console.log(JSON.stringify(tXml('<html><head><title>testPage</title></head><body><h1>TestPage</h1><p>this is a <b>test</b>page</p></body></html>'),undefined,'\\t'));\nvar p = new DOMParser();\nvar s2='<body>'+s+'</body>'\nvar start2= new Date().getTime();\nvar o2 = p.parseFromString(s2,'text/html').querySelector('#content')\nvar end2=new Date().getTime();\nconsole.log(\"MILLISECONDS\",end2-start2);\n// */\n\n\n//# sourceURL=webpack:///../node_modules/txml/tXml.js?");

/***/ }),

/***/ "../node_modules/util-deprecate/browser.js":
/*!*************************************************!*\
  !*** ../node_modules/util-deprecate/browser.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("\n/**\n * Module exports.\n */\n\nmodule.exports = deprecate;\n\n/**\n * Mark that a method should not be used.\n * Returns a modified function which warns once by default.\n *\n * If `localStorage.noDeprecation = true` is set, then it is a no-op.\n *\n * If `localStorage.throwDeprecation = true` is set, then deprecated functions\n * will throw an Error when invoked.\n *\n * If `localStorage.traceDeprecation = true` is set, then deprecated functions\n * will invoke `console.trace()` instead of `console.error()`.\n *\n * @param {Function} fn - the function to deprecate\n * @param {String} msg - the string to print to the console when `fn` is invoked\n * @returns {Function} a new \"deprecated\" version of `fn`\n * @api public\n */\n\nfunction deprecate (fn, msg) {\n  if (config('noDeprecation')) {\n    return fn;\n  }\n\n  var warned = false;\n  function deprecated() {\n    if (!warned) {\n      if (config('throwDeprecation')) {\n        throw new Error(msg);\n      } else if (config('traceDeprecation')) {\n        console.trace(msg);\n      } else {\n        console.warn(msg);\n      }\n      warned = true;\n    }\n    return fn.apply(this, arguments);\n  }\n\n  return deprecated;\n}\n\n/**\n * Checks `localStorage` for boolean values for the given `name`.\n *\n * @param {String} name\n * @returns {Boolean}\n * @api private\n */\n\nfunction config (name) {\n  // accessing global.localStorage can trigger a DOMException in sandboxed iframes\n  try {\n    if (!__webpack_require__.g.localStorage) return false;\n  } catch (_) {\n    return false;\n  }\n  var val = __webpack_require__.g.localStorage[name];\n  if (null == val) return false;\n  return String(val).toLowerCase() === 'true';\n}\n\n\n//# sourceURL=webpack:///../node_modules/util-deprecate/browser.js?");

/***/ }),

/***/ "../node_modules/yallist/iterator.js":
/*!*******************************************!*\
  !*** ../node_modules/yallist/iterator.js ***!
  \*******************************************/
/***/ ((module) => {

"use strict";
eval("\nmodule.exports = function (Yallist) {\n  Yallist.prototype[Symbol.iterator] = function* () {\n    for (let walker = this.head; walker; walker = walker.next) {\n      yield walker.value\n    }\n  }\n}\n\n\n//# sourceURL=webpack:///../node_modules/yallist/iterator.js?");

/***/ }),

/***/ "../node_modules/yallist/yallist.js":
/*!******************************************!*\
  !*** ../node_modules/yallist/yallist.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nmodule.exports = Yallist\n\nYallist.Node = Node\nYallist.create = Yallist\n\nfunction Yallist (list) {\n  var self = this\n  if (!(self instanceof Yallist)) {\n    self = new Yallist()\n  }\n\n  self.tail = null\n  self.head = null\n  self.length = 0\n\n  if (list && typeof list.forEach === 'function') {\n    list.forEach(function (item) {\n      self.push(item)\n    })\n  } else if (arguments.length > 0) {\n    for (var i = 0, l = arguments.length; i < l; i++) {\n      self.push(arguments[i])\n    }\n  }\n\n  return self\n}\n\nYallist.prototype.removeNode = function (node) {\n  if (node.list !== this) {\n    throw new Error('removing node which does not belong to this list')\n  }\n\n  var next = node.next\n  var prev = node.prev\n\n  if (next) {\n    next.prev = prev\n  }\n\n  if (prev) {\n    prev.next = next\n  }\n\n  if (node === this.head) {\n    this.head = next\n  }\n  if (node === this.tail) {\n    this.tail = prev\n  }\n\n  node.list.length--\n  node.next = null\n  node.prev = null\n  node.list = null\n\n  return next\n}\n\nYallist.prototype.unshiftNode = function (node) {\n  if (node === this.head) {\n    return\n  }\n\n  if (node.list) {\n    node.list.removeNode(node)\n  }\n\n  var head = this.head\n  node.list = this\n  node.next = head\n  if (head) {\n    head.prev = node\n  }\n\n  this.head = node\n  if (!this.tail) {\n    this.tail = node\n  }\n  this.length++\n}\n\nYallist.prototype.pushNode = function (node) {\n  if (node === this.tail) {\n    return\n  }\n\n  if (node.list) {\n    node.list.removeNode(node)\n  }\n\n  var tail = this.tail\n  node.list = this\n  node.prev = tail\n  if (tail) {\n    tail.next = node\n  }\n\n  this.tail = node\n  if (!this.head) {\n    this.head = node\n  }\n  this.length++\n}\n\nYallist.prototype.push = function () {\n  for (var i = 0, l = arguments.length; i < l; i++) {\n    push(this, arguments[i])\n  }\n  return this.length\n}\n\nYallist.prototype.unshift = function () {\n  for (var i = 0, l = arguments.length; i < l; i++) {\n    unshift(this, arguments[i])\n  }\n  return this.length\n}\n\nYallist.prototype.pop = function () {\n  if (!this.tail) {\n    return undefined\n  }\n\n  var res = this.tail.value\n  this.tail = this.tail.prev\n  if (this.tail) {\n    this.tail.next = null\n  } else {\n    this.head = null\n  }\n  this.length--\n  return res\n}\n\nYallist.prototype.shift = function () {\n  if (!this.head) {\n    return undefined\n  }\n\n  var res = this.head.value\n  this.head = this.head.next\n  if (this.head) {\n    this.head.prev = null\n  } else {\n    this.tail = null\n  }\n  this.length--\n  return res\n}\n\nYallist.prototype.forEach = function (fn, thisp) {\n  thisp = thisp || this\n  for (var walker = this.head, i = 0; walker !== null; i++) {\n    fn.call(thisp, walker.value, i, this)\n    walker = walker.next\n  }\n}\n\nYallist.prototype.forEachReverse = function (fn, thisp) {\n  thisp = thisp || this\n  for (var walker = this.tail, i = this.length - 1; walker !== null; i--) {\n    fn.call(thisp, walker.value, i, this)\n    walker = walker.prev\n  }\n}\n\nYallist.prototype.get = function (n) {\n  for (var i = 0, walker = this.head; walker !== null && i < n; i++) {\n    // abort out of the list early if we hit a cycle\n    walker = walker.next\n  }\n  if (i === n && walker !== null) {\n    return walker.value\n  }\n}\n\nYallist.prototype.getReverse = function (n) {\n  for (var i = 0, walker = this.tail; walker !== null && i < n; i++) {\n    // abort out of the list early if we hit a cycle\n    walker = walker.prev\n  }\n  if (i === n && walker !== null) {\n    return walker.value\n  }\n}\n\nYallist.prototype.map = function (fn, thisp) {\n  thisp = thisp || this\n  var res = new Yallist()\n  for (var walker = this.head; walker !== null;) {\n    res.push(fn.call(thisp, walker.value, this))\n    walker = walker.next\n  }\n  return res\n}\n\nYallist.prototype.mapReverse = function (fn, thisp) {\n  thisp = thisp || this\n  var res = new Yallist()\n  for (var walker = this.tail; walker !== null;) {\n    res.push(fn.call(thisp, walker.value, this))\n    walker = walker.prev\n  }\n  return res\n}\n\nYallist.prototype.reduce = function (fn, initial) {\n  var acc\n  var walker = this.head\n  if (arguments.length > 1) {\n    acc = initial\n  } else if (this.head) {\n    walker = this.head.next\n    acc = this.head.value\n  } else {\n    throw new TypeError('Reduce of empty list with no initial value')\n  }\n\n  for (var i = 0; walker !== null; i++) {\n    acc = fn(acc, walker.value, i)\n    walker = walker.next\n  }\n\n  return acc\n}\n\nYallist.prototype.reduceReverse = function (fn, initial) {\n  var acc\n  var walker = this.tail\n  if (arguments.length > 1) {\n    acc = initial\n  } else if (this.tail) {\n    walker = this.tail.prev\n    acc = this.tail.value\n  } else {\n    throw new TypeError('Reduce of empty list with no initial value')\n  }\n\n  for (var i = this.length - 1; walker !== null; i--) {\n    acc = fn(acc, walker.value, i)\n    walker = walker.prev\n  }\n\n  return acc\n}\n\nYallist.prototype.toArray = function () {\n  var arr = new Array(this.length)\n  for (var i = 0, walker = this.head; walker !== null; i++) {\n    arr[i] = walker.value\n    walker = walker.next\n  }\n  return arr\n}\n\nYallist.prototype.toArrayReverse = function () {\n  var arr = new Array(this.length)\n  for (var i = 0, walker = this.tail; walker !== null; i++) {\n    arr[i] = walker.value\n    walker = walker.prev\n  }\n  return arr\n}\n\nYallist.prototype.slice = function (from, to) {\n  to = to || this.length\n  if (to < 0) {\n    to += this.length\n  }\n  from = from || 0\n  if (from < 0) {\n    from += this.length\n  }\n  var ret = new Yallist()\n  if (to < from || to < 0) {\n    return ret\n  }\n  if (from < 0) {\n    from = 0\n  }\n  if (to > this.length) {\n    to = this.length\n  }\n  for (var i = 0, walker = this.head; walker !== null && i < from; i++) {\n    walker = walker.next\n  }\n  for (; walker !== null && i < to; i++, walker = walker.next) {\n    ret.push(walker.value)\n  }\n  return ret\n}\n\nYallist.prototype.sliceReverse = function (from, to) {\n  to = to || this.length\n  if (to < 0) {\n    to += this.length\n  }\n  from = from || 0\n  if (from < 0) {\n    from += this.length\n  }\n  var ret = new Yallist()\n  if (to < from || to < 0) {\n    return ret\n  }\n  if (from < 0) {\n    from = 0\n  }\n  if (to > this.length) {\n    to = this.length\n  }\n  for (var i = this.length, walker = this.tail; walker !== null && i > to; i--) {\n    walker = walker.prev\n  }\n  for (; walker !== null && i > from; i--, walker = walker.prev) {\n    ret.push(walker.value)\n  }\n  return ret\n}\n\nYallist.prototype.splice = function (start, deleteCount, ...nodes) {\n  if (start > this.length) {\n    start = this.length - 1\n  }\n  if (start < 0) {\n    start = this.length + start;\n  }\n\n  for (var i = 0, walker = this.head; walker !== null && i < start; i++) {\n    walker = walker.next\n  }\n\n  var ret = []\n  for (var i = 0; walker && i < deleteCount; i++) {\n    ret.push(walker.value)\n    walker = this.removeNode(walker)\n  }\n  if (walker === null) {\n    walker = this.tail\n  }\n\n  if (walker !== this.head && walker !== this.tail) {\n    walker = walker.prev\n  }\n\n  for (var i = 0; i < nodes.length; i++) {\n    walker = insert(this, walker, nodes[i])\n  }\n  return ret;\n}\n\nYallist.prototype.reverse = function () {\n  var head = this.head\n  var tail = this.tail\n  for (var walker = head; walker !== null; walker = walker.prev) {\n    var p = walker.prev\n    walker.prev = walker.next\n    walker.next = p\n  }\n  this.head = tail\n  this.tail = head\n  return this\n}\n\nfunction insert (self, node, value) {\n  var inserted = node === self.head ?\n    new Node(value, null, node, self) :\n    new Node(value, node, node.next, self)\n\n  if (inserted.next === null) {\n    self.tail = inserted\n  }\n  if (inserted.prev === null) {\n    self.head = inserted\n  }\n\n  self.length++\n\n  return inserted\n}\n\nfunction push (self, item) {\n  self.tail = new Node(item, self.tail, null, self)\n  if (!self.head) {\n    self.head = self.tail\n  }\n  self.length++\n}\n\nfunction unshift (self, item) {\n  self.head = new Node(item, null, self.head, self)\n  if (!self.tail) {\n    self.tail = self.head\n  }\n  self.length++\n}\n\nfunction Node (value, prev, next, list) {\n  if (!(this instanceof Node)) {\n    return new Node(value, prev, next, list)\n  }\n\n  this.list = list\n  this.value = value\n\n  if (prev) {\n    prev.next = this\n    this.prev = prev\n  } else {\n    this.prev = null\n  }\n\n  if (next) {\n    next.prev = this\n    this.next = next\n  } else {\n    this.next = null\n  }\n}\n\ntry {\n  // add if support for Symbol.iterator is present\n  __webpack_require__(/*! ./iterator.js */ \"../node_modules/yallist/iterator.js\")(Yallist)\n} catch (er) {}\n\n\n//# sourceURL=webpack:///../node_modules/yallist/yallist.js?");

/***/ }),

/***/ "./worker.js":
/*!*******************!*\
  !*** ./worker.js ***!
  \*******************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var geotiff__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! geotiff */ \"../node_modules/geotiff/src/geotiff.js\");\n\n\nonmessage = (e) => {\n    const tiff = geotiff__WEBPACK_IMPORTED_MODULE_0__.fromArrayBuffer(e.data).then(tiff => {\n        tiff.readRasters({interleave: true}).then(rasters => {\n            let uint8 = new Uint8Array(rasters);\n            postMessage(uint8.buffer, [uint8.buffer]);\n        });\n    });\n}\n\n//# sourceURL=webpack:///./worker.js?");

/***/ }),

/***/ "?3701":
/*!**********************!*\
  !*** http (ignored) ***!
  \**********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///http_(ignored)?");

/***/ }),

/***/ "?9079":
/*!***********************!*\
  !*** https (ignored) ***!
  \***********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///https_(ignored)?");

/***/ }),

/***/ "?c08e":
/*!*********************!*\
  !*** url (ignored) ***!
  \*********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///url_(ignored)?");

/***/ }),

/***/ "?462a":
/*!************************!*\
  !*** buffer (ignored) ***!
  \************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///buffer_(ignored)?");

/***/ }),

/***/ "?432f":
/*!**********************!*\
  !*** util (ignored) ***!
  \**********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///util_(ignored)?");

/***/ }),

/***/ "?5f0e":
/*!************************!*\
  !*** buffer (ignored) ***!
  \************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///buffer_(ignored)?");

/***/ }),

/***/ "?af24":
/*!**********************!*\
  !*** util (ignored) ***!
  \**********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///util_(ignored)?");

/***/ }),

/***/ "?09a9":
/*!************************!*\
  !*** buffer (ignored) ***!
  \************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///buffer_(ignored)?");

/***/ }),

/***/ "?a314":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///fs_(ignored)?");

/***/ }),

/***/ "../node_modules/lodash-es/_Symbol.js":
/*!********************************************!*\
  !*** ../node_modules/lodash-es/_Symbol.js ***!
  \********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _root_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./_root.js */ \"../node_modules/lodash-es/_root.js\");\n\n\n/** Built-in value references. */\nvar Symbol = _root_js__WEBPACK_IMPORTED_MODULE_0__.default.Symbol;\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Symbol);\n\n\n//# sourceURL=webpack:///../node_modules/lodash-es/_Symbol.js?");

/***/ }),

/***/ "../node_modules/lodash-es/_baseGetTag.js":
/*!************************************************!*\
  !*** ../node_modules/lodash-es/_baseGetTag.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _Symbol_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./_Symbol.js */ \"../node_modules/lodash-es/_Symbol.js\");\n/* harmony import */ var _getRawTag_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./_getRawTag.js */ \"../node_modules/lodash-es/_getRawTag.js\");\n/* harmony import */ var _objectToString_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./_objectToString.js */ \"../node_modules/lodash-es/_objectToString.js\");\n\n\n\n\n/** `Object#toString` result references. */\nvar nullTag = '[object Null]',\n    undefinedTag = '[object Undefined]';\n\n/** Built-in value references. */\nvar symToStringTag = _Symbol_js__WEBPACK_IMPORTED_MODULE_0__.default ? _Symbol_js__WEBPACK_IMPORTED_MODULE_0__.default.toStringTag : undefined;\n\n/**\n * The base implementation of `getTag` without fallbacks for buggy environments.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the `toStringTag`.\n */\nfunction baseGetTag(value) {\n  if (value == null) {\n    return value === undefined ? undefinedTag : nullTag;\n  }\n  return (symToStringTag && symToStringTag in Object(value))\n    ? (0,_getRawTag_js__WEBPACK_IMPORTED_MODULE_1__.default)(value)\n    : (0,_objectToString_js__WEBPACK_IMPORTED_MODULE_2__.default)(value);\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (baseGetTag);\n\n\n//# sourceURL=webpack:///../node_modules/lodash-es/_baseGetTag.js?");

/***/ }),

/***/ "../node_modules/lodash-es/_baseIsArrayBuffer.js":
/*!*******************************************************!*\
  !*** ../node_modules/lodash-es/_baseIsArrayBuffer.js ***!
  \*******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _baseGetTag_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./_baseGetTag.js */ \"../node_modules/lodash-es/_baseGetTag.js\");\n/* harmony import */ var _isObjectLike_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./isObjectLike.js */ \"../node_modules/lodash-es/isObjectLike.js\");\n\n\n\nvar arrayBufferTag = '[object ArrayBuffer]';\n\n/**\n * The base implementation of `_.isArrayBuffer` without Node.js optimizations.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array buffer, else `false`.\n */\nfunction baseIsArrayBuffer(value) {\n  return (0,_isObjectLike_js__WEBPACK_IMPORTED_MODULE_0__.default)(value) && (0,_baseGetTag_js__WEBPACK_IMPORTED_MODULE_1__.default)(value) == arrayBufferTag;\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (baseIsArrayBuffer);\n\n\n//# sourceURL=webpack:///../node_modules/lodash-es/_baseIsArrayBuffer.js?");

/***/ }),

/***/ "../node_modules/lodash-es/_baseUnary.js":
/*!***********************************************!*\
  !*** ../node_modules/lodash-es/_baseUnary.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/**\n * The base implementation of `_.unary` without support for storing metadata.\n *\n * @private\n * @param {Function} func The function to cap arguments for.\n * @returns {Function} Returns the new capped function.\n */\nfunction baseUnary(func) {\n  return function(value) {\n    return func(value);\n  };\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (baseUnary);\n\n\n//# sourceURL=webpack:///../node_modules/lodash-es/_baseUnary.js?");

/***/ }),

/***/ "../node_modules/lodash-es/_freeGlobal.js":
/*!************************************************!*\
  !*** ../node_modules/lodash-es/_freeGlobal.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/** Detect free variable `global` from Node.js. */\nvar freeGlobal = typeof global == 'object' && global && global.Object === Object && global;\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (freeGlobal);\n\n\n//# sourceURL=webpack:///../node_modules/lodash-es/_freeGlobal.js?");

/***/ }),

/***/ "../node_modules/lodash-es/_getRawTag.js":
/*!***********************************************!*\
  !*** ../node_modules/lodash-es/_getRawTag.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _Symbol_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./_Symbol.js */ \"../node_modules/lodash-es/_Symbol.js\");\n\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar nativeObjectToString = objectProto.toString;\n\n/** Built-in value references. */\nvar symToStringTag = _Symbol_js__WEBPACK_IMPORTED_MODULE_0__.default ? _Symbol_js__WEBPACK_IMPORTED_MODULE_0__.default.toStringTag : undefined;\n\n/**\n * A specialized version of `baseGetTag` which ignores `Symbol.toStringTag` values.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the raw `toStringTag`.\n */\nfunction getRawTag(value) {\n  var isOwn = hasOwnProperty.call(value, symToStringTag),\n      tag = value[symToStringTag];\n\n  try {\n    value[symToStringTag] = undefined;\n    var unmasked = true;\n  } catch (e) {}\n\n  var result = nativeObjectToString.call(value);\n  if (unmasked) {\n    if (isOwn) {\n      value[symToStringTag] = tag;\n    } else {\n      delete value[symToStringTag];\n    }\n  }\n  return result;\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (getRawTag);\n\n\n//# sourceURL=webpack:///../node_modules/lodash-es/_getRawTag.js?");

/***/ }),

/***/ "../node_modules/lodash-es/_nodeUtil.js":
/*!**********************************************!*\
  !*** ../node_modules/lodash-es/_nodeUtil.js ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _freeGlobal_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./_freeGlobal.js */ \"../node_modules/lodash-es/_freeGlobal.js\");\n\n\n/** Detect free variable `exports`. */\nvar freeExports = typeof exports == 'object' && exports && !exports.nodeType && exports;\n\n/** Detect free variable `module`. */\nvar freeModule = freeExports && typeof module == 'object' && module && !module.nodeType && module;\n\n/** Detect the popular CommonJS extension `module.exports`. */\nvar moduleExports = freeModule && freeModule.exports === freeExports;\n\n/** Detect free variable `process` from Node.js. */\nvar freeProcess = moduleExports && _freeGlobal_js__WEBPACK_IMPORTED_MODULE_0__.default.process;\n\n/** Used to access faster Node.js helpers. */\nvar nodeUtil = (function() {\n  try {\n    // Use `util.types` for Node.js 10+.\n    var types = freeModule && freeModule.require && freeModule.require('util').types;\n\n    if (types) {\n      return types;\n    }\n\n    // Legacy `process.binding('util')` for Node.js < 10.\n    return freeProcess && freeProcess.binding && freeProcess.binding('util');\n  } catch (e) {}\n}());\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (nodeUtil);\n\n\n//# sourceURL=webpack:///../node_modules/lodash-es/_nodeUtil.js?");

/***/ }),

/***/ "../node_modules/lodash-es/_objectToString.js":
/*!****************************************************!*\
  !*** ../node_modules/lodash-es/_objectToString.js ***!
  \****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar nativeObjectToString = objectProto.toString;\n\n/**\n * Converts `value` to a string using `Object.prototype.toString`.\n *\n * @private\n * @param {*} value The value to convert.\n * @returns {string} Returns the converted string.\n */\nfunction objectToString(value) {\n  return nativeObjectToString.call(value);\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (objectToString);\n\n\n//# sourceURL=webpack:///../node_modules/lodash-es/_objectToString.js?");

/***/ }),

/***/ "../node_modules/lodash-es/_root.js":
/*!******************************************!*\
  !*** ../node_modules/lodash-es/_root.js ***!
  \******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _freeGlobal_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./_freeGlobal.js */ \"../node_modules/lodash-es/_freeGlobal.js\");\n\n\n/** Detect free variable `self`. */\nvar freeSelf = typeof self == 'object' && self && self.Object === Object && self;\n\n/** Used as a reference to the global object. */\nvar root = _freeGlobal_js__WEBPACK_IMPORTED_MODULE_0__.default || freeSelf || Function('return this')();\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (root);\n\n\n//# sourceURL=webpack:///../node_modules/lodash-es/_root.js?");

/***/ }),

/***/ "../node_modules/lodash-es/isArrayBuffer.js":
/*!**************************************************!*\
  !*** ../node_modules/lodash-es/isArrayBuffer.js ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _baseIsArrayBuffer_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./_baseIsArrayBuffer.js */ \"../node_modules/lodash-es/_baseIsArrayBuffer.js\");\n/* harmony import */ var _baseUnary_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./_baseUnary.js */ \"../node_modules/lodash-es/_baseUnary.js\");\n/* harmony import */ var _nodeUtil_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./_nodeUtil.js */ \"../node_modules/lodash-es/_nodeUtil.js\");\n\n\n\n\n/* Node.js helper references. */\nvar nodeIsArrayBuffer = _nodeUtil_js__WEBPACK_IMPORTED_MODULE_0__.default && _nodeUtil_js__WEBPACK_IMPORTED_MODULE_0__.default.isArrayBuffer;\n\n/**\n * Checks if `value` is classified as an `ArrayBuffer` object.\n *\n * @static\n * @memberOf _\n * @since 4.3.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array buffer, else `false`.\n * @example\n *\n * _.isArrayBuffer(new ArrayBuffer(2));\n * // => true\n *\n * _.isArrayBuffer(new Array(2));\n * // => false\n */\nvar isArrayBuffer = nodeIsArrayBuffer ? (0,_baseUnary_js__WEBPACK_IMPORTED_MODULE_1__.default)(nodeIsArrayBuffer) : _baseIsArrayBuffer_js__WEBPACK_IMPORTED_MODULE_2__.default;\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (isArrayBuffer);\n\n\n//# sourceURL=webpack:///../node_modules/lodash-es/isArrayBuffer.js?");

/***/ }),

/***/ "../node_modules/lodash-es/isObjectLike.js":
/*!*************************************************!*\
  !*** ../node_modules/lodash-es/isObjectLike.js ***!
  \*************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/**\n * Checks if `value` is object-like. A value is object-like if it's not `null`\n * and has a `typeof` result of \"object\".\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is object-like, else `false`.\n * @example\n *\n * _.isObjectLike({});\n * // => true\n *\n * _.isObjectLike([1, 2, 3]);\n * // => true\n *\n * _.isObjectLike(_.noop);\n * // => false\n *\n * _.isObjectLike(null);\n * // => false\n */\nfunction isObjectLike(value) {\n  return value != null && typeof value == 'object';\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (isObjectLike);\n\n\n//# sourceURL=webpack:///../node_modules/lodash-es/isObjectLike.js?");

/***/ }),

/***/ "../node_modules/threads/index.mjs":
/*!*****************************************!*\
  !*** ../node_modules/threads/index.mjs ***!
  \*****************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"registerSerializer\": () => (/* binding */ registerSerializer),\n/* harmony export */   \"spawn\": () => (/* binding */ spawn),\n/* harmony export */   \"DefaultSerializer\": () => (/* binding */ DefaultSerializer),\n/* harmony export */   \"Pool\": () => (/* binding */ Pool),\n/* harmony export */   \"Thread\": () => (/* binding */ Thread),\n/* harmony export */   \"Transfer\": () => (/* binding */ Transfer),\n/* harmony export */   \"Worker\": () => (/* binding */ Worker)\n/* harmony export */ });\n/* harmony import */ var _dist_index_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./dist/index.js */ \"../node_modules/threads/dist/index.js\");\n\n\nconst registerSerializer = _dist_index_js__WEBPACK_IMPORTED_MODULE_0__.registerSerializer\nconst spawn = _dist_index_js__WEBPACK_IMPORTED_MODULE_0__.spawn\nconst DefaultSerializer = _dist_index_js__WEBPACK_IMPORTED_MODULE_0__.DefaultSerializer\nconst Pool = _dist_index_js__WEBPACK_IMPORTED_MODULE_0__.Pool\nconst Thread = _dist_index_js__WEBPACK_IMPORTED_MODULE_0__.Thread\nconst Transfer = _dist_index_js__WEBPACK_IMPORTED_MODULE_0__.Transfer\nconst Worker = _dist_index_js__WEBPACK_IMPORTED_MODULE_0__.Worker\n\n\n//# sourceURL=webpack:///../node_modules/threads/index.mjs?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/global */
/******/ 	(() => {
/******/ 		__webpack_require__.g = (function() {
/******/ 			if (typeof globalThis === 'object') return globalThis;
/******/ 			try {
/******/ 				return this || new Function('return this')();
/******/ 			} catch (e) {
/******/ 				if (typeof window === 'object') return window;
/******/ 			}
/******/ 		})();
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./worker.js");
/******/ 	
/******/ })()
;